\documentclass[10pt,a4paper,oneside]{book}
\usepackage[a4paper,includeheadfoot,top=10mm,bottom=10mm,left=10mm,right=10mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath,amsthm,amssymb,amscd,array}
\usepackage{latexsym}
\usepackage{multicol} % нумерция в нескольких колонках
\usepackage{graphicx} 
%\usepackage{pdfsync}
\usepackage{pgf}
\usepackage{tikz}
\usepackage{tikz-cd}
\usetikzlibrary{arrows,backgrounds,patterns,matrix,shapes,fit,calc,shadows,plotmarks}
\usepackage{hyperref} % гиперссылки
\usepackage{cmap}       % Поддержка поиска русских слов в PDF (pdflatex)
\usepackage{indentfirst}% Красная строка в первом абзаце
\usepackage{misccorr}
\usepackage{arydshln} % штрихованые линии в массивах
\usepackage{mathtools} % выравнивание в матрицах
\usepackage{ccaption}
\usepackage{fancyhdr}
\usepackage{comment}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={blue!50!black},
    citecolor={blue!50!black},
    urlcolor={red!80!black}
}
% цвета для ссылок

\newtheorem{upr}{Упражнение}
\newtheorem{predl}{Предложение}
\newtheorem{komment}{Комментарий}
\newtheorem{conj}{Гипотеза}
\newtheorem{notation}{Обозначение}


\theoremstyle{definition}
\newtheorem{kit}{Кит}
\newtheorem*{rem}{Замечание}
\newtheorem{zad}{Задача}
\newtheorem{defn}{Определение}
\newtheorem*{fact}{Факт}
\newtheorem{thm}{Теорема}
\newtheorem*{thmm}{Теорема}
\newtheorem{lem}{Лемма}
\newtheorem{cor}{Следствие}



\renewcommand{\proofname}{Доказательство}
\renewcommand{\mod}{\,\operatorname{mod}\,}
\newcommand{\mf}[1]{\mathfrak{#1}}
\newcommand{\mcal}[1]{\mathcal{#1}}
\newcommand{\mb}[1]{\mathbb{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\tbf}[1]{\textbf{#1}}
\newcommand{\ovl}{\overline}
\newcommand{\Spec}{\operatorname{Spec}}
\newcommand{\K}{\operatorname{K_0}}
\newcommand{\witt}{\operatorname{W}}
\newcommand{\gw}{\operatorname{GW}}
\newcommand{\coh}{\operatorname{H}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\cl}{\operatorname{Cl}}
\newcommand{\Vol}{\operatorname{Vol}}
\newcommand\tgg{\mathop{\rm tg}\nolimits}
\newcommand\ccup{\mathop{\cup}}
\newcommand{\id}{\operatorname{Id}}
\newcommand{\lcm}{\operatorname{lcm}}
\newcommand{\chr}{\operatorname{char}}
\newcommand{\rank}{\operatorname{rank}}
\DeclareMathOperator{\Coker}{Coker}
\DeclareMathOperator{\Ker}{Ker}
\newcommand{\im}{\operatorname{Im}}
\renewcommand{\Im}{\operatorname{Im}}
\newcommand{\Tr}{\operatorname{Tr}}
\newcommand{\re}{\operatorname{Re}}
\newcommand{\tr}{\operatorname{Tr}}
\newcommand{\ord}{\operatorname{ord}}
\newcommand{\Stab}{\operatorname{Stab}}
\newcommand{\orb}{\operatorname{\mathcal O}}
\newcommand{\Fix}{\operatorname{Fix}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\End}{\operatorname{End}}
\newcommand{\Aut}{\operatorname{Aut}}
\newcommand{\Inn}{\operatorname{Inn}}
\newcommand{\Out}{\operatorname{Out}}
\newcommand{\GL}{\operatorname{GL}}
\newcommand{\SL}{\operatorname{SL}}
\newcommand{\SO}{\operatorname{SO}}
\newcommand{\Sym}{\operatorname{Sym}}
\newcommand{\Adj}{\operatorname{Adj}}


\newcommand{\di}{\mathop{\,\scalebox{0.85}{\raisebox{-1.2pt}[0.5\height]{\vdots}}\,}}

\newcommand{\ndi}{\mathop{\not\scalebox{0.85}{\raisebox{-1.2pt}[0.5\height]{\vdots}}\,}}
\newcommand{\nequiv}{\not \equiv}
\newcommand{\Nod}{\operatorname{\text{НОД}}}
\newcommand{\Nok}{\operatorname{\text{НОК}}}
\newcommand{\sgn}{\operatorname{sgn}}


\def\llq{\textquotedblleft} 
\def\rrq{\textquotedblright} 
\def\exm{\noindent {\bf Примеры:}}


\def\Cb{\ovl{C}}
\def\ffi{\varphi}
\def\pa{\partial}
\def\V{\bf V}
\def\La{\Lambda}
\def\eps{\varepsilon}
\def\del{\delta}
\def\Del{\Delta}
\def\A{\EuScript{A}}
\def\lan{\left\langle }
\def\ran{\right\rangle}
\def\bar{\begin{array}}
\def\ear{\end{array}}
\def\beq{\begin{equation}}
\def\eeq{\end{equation}}
\def\thrm{\begin{thm}}
\def\ethrm{\end{thm}}
\def\dfn{\begin{defn}}
\def\edfn{\end{defn}}
\def\lm{\begin{lem}}
\def\elm{\end{lem}}
\def\zd{\begin{zad}}
\def\ezd{\end{zad}}
\def\prdl{\begin{predl}}
\def\eprdl{\end{predl}}
\def\crl{\begin{cor}}
\def\ecrl{\end{cor}}
\def\rm{\begin{rem}}
\def\erm{\end{rem}}
\def\fct{\begin{fact}}
\def\efct{\end{fact}}
\def\enm{\begin{enumerate}}
\def\eenm{\end{enumerate}}
\def\pmat{\begin{pmatrix}}
\def\epmat{\end{pmatrix}}

\frenchspacing
\righthyphenmin=2
%\usepackage{floatflt}
\captiondelim{. }





\begin{document}

\title{Конспект по алгебре, 2 семестр, весна 2018}
\date{}
\author{}
\maketitle
\tableofcontents

\setcounter{chapter}{1}

\chapter{Теория колец: кое-что о многочленах и рядах}

\section{Комплексные числа}
\rm Гомоморфизм из поля всегда инъективен. Следовательно, если есть гомоморфизм из поля $K\to L$, то не умаляя общности (и если этот гомоморфизм нельзя перепутать с каким-нибудь другим гомоморфизмом $K\to L$), то можно считать, что $K\subseteq L$.
\erm

\dfn Если $K\subseteq L$, то будем говорить, что $L$ есть расширение поля $K$, а $K$ -- подполе поля $L$.
\edfn
Покажем, что расширений полей достаточно много.
\thrm[У любого многочлена в каком-то расширении есть все корни] Пусть $f(x)\in K[x]$. Тогда существует расширение $L$ поля $K$, такое, что в $L$ многочлен $f$ раскладывается на линейные множители.  
\ethrm
\proof Индукция по степени $f(x)$. Разложим $f(x)$ на неприводимые множители. Рассмотрим один из этих множителей $p(x)$. Тогда в поле $L=K[x]/p(x)$ у $p(x)$ и, следовательно, у $f(x)$ есть корень $\lambda$. Поделим $g(x)=\frac{f(x)}{x-\lambda}$ в $L[x]$. Получился многочлен меньшей степени, но в $L[x]$. Это нам подходит. Существует $L'$ раcширение $L$, где  $g(x)$ и, следовательно у $f(x)=g(x)(x-\lambda)$ раскладывается на линейные множители.
\endproof

\dfn[Комплексные числа] Поле $\mb R[x]/(x^2 + 1)$ называется полем комплексных чисел. Будем обозначать это расширение полей как $\mb C$.
\edfn

Разберёмся, как устроено умножение в $\mb C$. Прежде всего вспомним, что любой элемент представляется однозначно как класс многочлена вида $a+bx$. Складываются такие представители, как мы помним, покомпонентно. Посмотрим, что происходит при произведении. Рассмотрим два элемента $a+bx$ и $c+dx$. Тогда
$$(a+bx)(c+dx)=ac+(ad+bc)x+bdx^2\equiv ac-bd + (ad+bc)x \mod x^2+1.$$

Так как наша конструкция очень специальная то введём обозначение $i$ для класса элемента $x$. Элемент $i$ по самому определению $\mb C$ удовлетворяет соотношению $i^2=-1$. Благодаря нашему соглашению любой элемент $z$ в $\mb C$ однозначно записывается в виде суммы $z=a+bi$, где $a,b\in \mb R$. Такая форма записи для комплексного числа будет для нас стандартной. В такой форме видно, что любому комплексному числу соответствует точка на плоскости с координатами $(a,b)$. Число $a$ называется вещественной частью числа $z$ и обозначается $a=\re z$, число $b$ --- мнимой частью и обозначается $\im z$. Если говорить на языке пар, то произведению пар $(a,b)$ и $(c,d)$ соответствует пара $(ac-bd,ad+bc)$.
 
\dfn[Комплексное сопряжение] У поля $\mb C$ есть автоморфизм, который задан правилом $z=a+bi \to a-bi=\ovl{z}$. Такой автоморфизм называется комплексным сопряжением.
\edfn

\rm Это действительно автоморфизм. Более того, он оставляет на месте подполе $\mb R$.
\proof 
\endproof
\erm
 
\dfn[Модуль комплексного числа] Рассмотрим комплексное число $z=a+bi\in \mb C$. Тогда модулем комплексного числа $z$ назовём выражение
$$|z|=\sqrt{a^2+b^2}=\sqrt{z\ovl{z}}.$$
\edfn

\lm[Формула для обратного] Пусть $z\in \mb C$, $z\neq 0$. Тогда
$$ z^{-1} =\frac{\ovl{z}}{|z|^2}= \frac{a}{a^2+b^2}-\frac{b}{a^2+b^2}.$$
\elm

Однако наряду со стандартной формой записи есть и другой способ представления комплексного числа.

\dfn[Тригонометрическая форма записи] Рассмотрим ненулевое комплексное число $z= a+bi\in\mb C$. Поделим число $z$ на его модуль. Число
$\frac{z}{|z|}$ лежит на окружности $|z| = 1$. Точки такой окружности имеют вид $\cos\varphi +i\sin\varphi$ для единственного $0 \leq \varphi < 2\pi$. Обозначим выражение $\cos\varphi+i\sin\varphi$ за $e^{i\varphi}$. Тогда $z=|z|e^{i\varphi}$.
Такая запись называется тригонометрической записью комплексного числа. Угол $\varphi$ обозначают $\arg z$ и называют
аргументом комплексного числа.
\edfn


Почему $e^{i\varphi}$ естественно определить как $\cos\varphi+i\sin \varphi$ ? Основная мотивация для этого есть тождество для рядов  (пока мы не говорим про сходимость, то для формальных степенных рядов).
$$\exp(ix) = \sum_{n=0}^{\infty} \frac{(ix)^n}{n!}=\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{2n!} + i\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}= \cos(x) + i\sin(x).$$
Возможность подставлять в ряды различные значения вместо формальной переменной вы будете долго обсуждать в рамках курса математического анализа. В частности во все указанные ряды можно будет подставить любое комплексное число. Так же, если для рядов было выполнено некоторое тождество, то оно будет верно и для функций, которые они задают.
Нас на текущий момент гораздо больше  интересует то обстоятельство, что экспонента сумму переводит в произведение. Так как никаких особенных средств матанализа у нас в распоряжении нет, то постараемся показать это свойство в нашем конкретном случае руками, а заодно посмотреть геометрически, что же происходит.


Вопрос: что происходит при домножении на комплексное число $\cos \varphi + i \sin \varphi$? Для того, чтобы классифицировать,
что происходит, необходимо небольшое знание геометрии.
\dfn[Расстояние] Расстоянием между комплексными числами $z_1$ и $z_2$ положим равным $|z_1-z_2 |$.
\edfn

\rm Это просто обычное расстояние на плоскости.
\erm

Отображение плоскости, сохраняющее расстояние называется движением или изометрией плоскости. Множество всех изометрий плоскости образует группу относительно композиции. Верен следующий:
\begin{fact} Поворот вокруг точки на некоторый угол есть изометрия плоскости. Изометрия плоскости, имеющая ровно
одну неподвижную точку является поворотом вокруг этой точки.
\end{fact}

\thrm[Геометрическая интерпретация] Пусть $z\in \mb C$ число по модулю равное единице. Тогда $\mb C \to \mb C$ отображение заданное правилом $ x\to zx$   является поворотом вокруг точки 0 на угол $\arg z$.
\ethrm
\proof Пусть $z\neq 1$ (случай $z=1$ соответствует тождественному отображению). Проверим, что домножение на $z$ имеет ровно одну неподвижную точку 0. Действительно, пусть $z_1z=z_1$. Тогда, если $z_1\neq 0$, то получаем $z=1$. Очевидно, домножение на $z$ сохраняет расстояние $$|zz_1-zz_2|=|z(z_1-z_2)|=|z||(z_1-z_2)|=|(z_1-z_2)|.$$
Получается, что домножение на $|z|$ есть поворот. Как узнать угол? Для этого достаточно посмотреть, куда переходит какая-нибудь точка. Например 1. Единица переходит в $z$, то есть точку под углом $\arg z$ к исходной.
\endproof

\crl Пусть $z_1, z_2\in \mb C$  и $z_1,z_2\neq 0$. Тогда $\arg z_1z_2 = \arg z_1 + \arg z_2$ , $|z_1z_2| = |z_1 ||z_2 |$.
\ecrl

\crl[Формула Муавра] Пусть $z\in \mb C$ имеет тригонометрическую запись $z=re^{i\varphi}$. Тогда
$$z^{n}=r^{n}(\cos \varphi +i\sin \varphi )^{n}=r^{n}(\cos n\varphi +i\sin n\varphi ).$$
Эту формулу можно воспринимать, как выражение для косинусов и синусов кратного угла.
\ecrl

То, что тригонометрическая запись числа существует и ведёт себя предсказуемым образом при произведении, позволяет позволяет нам более или менее явно построить решения для уравнений некоторого специального вида.

\thrm[Извлечение корней] Пусть $z\in \mb C$, $z=re^{i\varphi}$, $r>0$ . Тогда у уравнения $x^n=z$ есть ровно $n$ различных
решений в $\mb C$, которые задаются формулой
$$ x_k =\sqrt[n]{r} e^{i\frac{\varphi + 2\pi k}{n}} ,\,\, k\in \ovl{0,n-1}.$$
\ethrm
\proof
Прямой проверкой можно установить, что указанные $x_k$ являются корнями. Необходимо доказать, что они различные. Рассмотрим частное $x_k$ и $x_l$. Это $e^{i\frac{ 2\pi k- 2\pi l}{n}}$. Так как $\frac{k-l}{n}$ не есть целое число, то их отношение не равно единице.
\endproof

\rm Числа вида $e^{i\frac{2\pi k}{n}}$ являются корнями степени $n$ из единицы. Число $e^{i\frac{2\pi }{n}}$ является первообразным корнем степени $n$ из единицы.
\erm

Иногда в жизни бывает необходимо посчитать какую-то странную сумму. Часто это невозможно сделать, но иногда компактный ответ можно найти. Приведём пример, как комплексные числа могут помочь в подсчёте сумм.
Рассмотрим сумму $1+ \cos x + \cos 2x + \dots + \cos nx$, где $x > 1$. Вопрос состоит в том, чему она равна в зависимости от $n$. Основной трюк здесь --- заменить непонятные вещественные числа, на их улучшенную комплексную версию. Например, $$\cos x = \frac{e^{ix}+e^{-ix}}{2}, \sin x = \frac{e^{ix}-e^{-ix}}{2i}.$$ 
В данном случае, проще заметить, что $\cos x=\re e^{ix}$. Тогда
$$1 + \cos x+ \dots + \cos nx = \re(1+ e^{ix} + \dots + e^{inx}) = \re \frac{e^{i(n+1)x}-1}{e^{ix}-1}$$
Теперь необходимо привести выражение к виду, не содержащему комплексных чисел.
$$\re \frac{e^{i(n+1)x}-1}{e^{ix}-1} = \re e^{i\tfrac{n+1}{2}x}\cdot e^{-i\tfrac{x}{2}}\frac{\sin \tfrac{n+1}{2}x}{\sin\tfrac{x}{2}}= \frac{\cos \tfrac{nx}{2} \sin \tfrac{n+1}{2}x}{\sin\tfrac{x}{2}}$$


При решении задачи очень часто бывает, что сам факт существования того, о чём идёт речь вообще говоря является не очевидным. Например, далеко не каждая функция имеет на отрезке минимум и следовательно задача поиска минимального значения функции может быть просто не корректна. Поэтому важно заранее знать, что предмет исследования есть. Мы уже поняли, чтобы у каждого многочлена в каком-то поле есть корень. Можно немного поднапрячься и понять, что в некотором поле у многочлена есть все корни (то есть число корней с учётом кратности равно степени многочлена). Однако можно спросить, а бывает ли так, что есть поле, такое что каждый многочлен с коэффициентами из этого поля имеет корень?

Ответ — да, такое поле есть. Первый и основной такой пример --- это поле комплексных чисел.
\dfn[Алгебраическая замкнутость] Поле $K$ называется алгебраически замкнутым, если у любого многочлена  $f(x)\in K[x]$, отличного от константы, есть корень в $K$.
\edfn

\thrm[Основная теорема алгебры] Поле $\mb C$ алгебраически замкнуто.
\proof Пусть $f$ — многочлен степени $n\geq 1$ в $\mb C[x]$. Будем считать, что старший коэффициент $f$ равен единице. Пусть у этого многочлена нет корней. Рассмотрим функцию $|f|\colon \mb C \to \mb R$. Эта функция непрерывна и не принимает значения 0. Так как $f$ --- многочлен степени $n$, то на бесконечности $|f|$ растёт. Разберёмся точнее. Пусть
$c = |f(z_0)| > 0$ в некоторой точке $z_0$. Я утверждаю, что вне некоторого круга радиуса $R$ с центом в 0 функция
$|f|$ принимает значения строго больше чем $c$. Действительно возьмём $R= M \max(2,c)$, где $M$ --- сумма модулей всех коэффициентов многочлена $f$. Двойка здесь играет роль числа строго большего единицы.
Тогда для поиска инфимума $|f|$ достаточно ограничиться кругом радиуса $R$. Но круг радиуса $R$ --- компактное множество и непрерывная функция $|f|$ достигает на нём минимальное значение в точке $x_0$. Пусть $a_0 =f(x_0)$ Разложим
$f$ по степеням $(x-x_0)$. Тогда имеем
$$f(x) = a_0 + a_k (x-x_0)^k + \dots + a_n(x -x_0 )^n.$$
Здесь $a_k$ --- первый ненулевой коэффициент после $a_0$. Такой есть потому что иначе $f$ --- это константа. Теперь наша
задача понять, что мы можем немного сдвинуться от точки $x_0$ , так, чтобы значение $|f|$ уменьшилось. В районе точки
$x_0$ самое большое слагаемое в разложении $f$ это $a_0 + a_k (x-x_0)^k$ и оно практически полностью определяет поведение $f$.
У этого многочлена есть корень. Обозначим его за $y_0$. Будем двигаться из $x_0$ в направлении $y_0$ и смотреть, что происходит.
Рассмотрим $x_{\eps} = x_0 + \eps(y_0 -x_0 ), \,\eps < 1$. Тогда $x_{\eps} -x_0 = \eps(y_0 -x_0 )$. Тогда
$$|f(x_{\eps})| = |(1 - \eps^k)a_0 + \eps^{k+1} a_{k+1} (y_0 -x_0)^{k+1} + \dots+ \eps^n(y_0-x_0 )^n | \leq (1- \eps^k )|f(x_0)| + \eps^{k+1}N,$$
где $N$ — это некоторая константа не зависящая от $\eps$. Например, можно взять $N = \sum_{i=k+1}^n |a_i||y_0 -x_0 |^i$. Для достаточно
маленьких $\eps$ выражение $ -\eps^k |f(x_0)| + \eps^{k+1}N$ отрицательно. Тогда для всех достаточно маленьких $\eps>0$ выполнено неравенство $|f(x_{\eps})| < |f(x_0)|$.
Противоречие с минимальностью $|f(x_0)|$. \endproof
\ethrm

\crl Любой неприводимый многочлен над $\mb R$ либо линеен, либо является многочленом второй степени с отрицательным дискриминантом.
\ecrl

\dfn[Алгебраическое замыкание] Пусть $K$ --- поле. Тогда $L$ --- расширение $K$ называется алгебраическим замыканием $K$, если \\
1) $L$ алгебраически замкнуто.\\
2) Для любого $ \lambda \in L$ существует $0\neq p(x)\in K[x]$, что $p(\lambda)=0$.
\edfn

\thrm У любого поля есть алгебраическое замыкание и оно единственно с точностью до изоморфизма.
\ethrm
\proof[Мы не будем доказывать теорему] Отмечу только, что процесс построения алгебраического замыкания более-менее нагляден. А именно надо взять все неприводимые многочлены в $K[x]$, и шаг за шагом увеличивать расширение, добавляя всё новые корни. Завершив этот процесс можно обнаружить, что добавились новые многочлены, которых раньше не было. Значит надо повторить процедуру ещё раз. И ещё раз ... В общем счётное число раз.

Формализовать такое рассуждение можно с помощью аксиомы выбора. 
\endproof

\zd Классифицируйте, чему может быть изоморфно $\mb R[x]/(x^2 + bx +c)$ в зависимости от $b,c$.
\ezd












\section{Производная}
Со школы вам наверняка известно, что кратность корня многочлена ловится с помощью производной. Попробуем в абстрактном
контексте ввести понятие производной многочлена. Для удобства и по причине наличия общих свойств проделаем все выкладки для степенных рядов затем сосредоточившись на применениях к многочленам.


Прежде чем говорить про производную в нашем контексте, вспомним, что многие вычисления производной основаны на умении вычислять производную композиции. Если для многочленов мы знаем, что такое композиция, то для формальных степенных рядов мы этого ещё не определяли.

\dfn Пусть $f(x)=a_0+ a_1x\dots\in K[[x]]$ и $g(x)= b_1x+b_2x^2+\dots \in xK[[x]]$. Тогда определим 
$$f(g)_n= \sum_{k=0}^n a_k\sum_{j_1+\dots+j_k=n} b_{j_1}\dots b_{j_k}.$$
\edfn

Эта формула получилась, если формально подставить $g$ в $f$. От неё мало проку, кроме факта её существования и того, что если $f(x)$ многочлен, то она совпадает с формулой подстановки (которая в этом случае определена). Воспользуемся этим и докажем

\lm Пусть $g\in xK[[x]]$. Тогда отображение $f \to f(g(x))$ является гомоморфизмом колец $K[[x]]\to K[[x]]$.
\elm
\proof Пусть $f_1, f_2 \in K[[x]]$. Хотим показать, что $(f_1f_2)(g)=f_1(g)f_2(g)$. Для этого необходимо проверить равенство коэффициентов в правой и левой части. Проверим для $n$-ого. Пусть $f(x)= a_0+a_1x+\dots+a_nx^n+a_{n+1}x^{n+1}+\dots$. Тогда обозначим многочлен 
$$f_{\leq n}(x)=a_0+\dots+a_nx^n.$$
Тогда заметим, что $n$-ый коэффициент $f_1f_2$ равен $n$-ому коэффициенту $f_{1,\leq n}f_{2,\leq n}$. Так же заметим, что $n$-ый коэффициент в $f(g)$ равен $n$-ому в $f_{\leq n}(g)$. Это означает, что теперь необходимо проверить равенство $n$-ых коэффициентов у $(f_{1,\leq n}f_{2,\leq n})(g)$ и $f_{1,\leq n}(g)f_{2,\leq n}(g)$, но эти два ряда просто равны, потому что подстановка в многочлен --- гомоморфизм. \endproof 

\dfn[Формальная производная] Пусть $R$ --- кольцо. Рассмотрим кольцо формальных степенных рядов $R[[x]]$. Формальной производной назовём отображение
$\frac{d}{dx}\colon R[[x]]\to R[[x]]$, заданное по правилу
$$\frac{d}{dx}(a_0+a_1x+a_2x^2+\dots+a_nx^n+\dots) = a_1+2a_2x+3a_3x^2+\dots+na_nx^{n-1}+\dots.$$
Применение производной к ряду $f$ будем так же обозначать как $f'$.
\edfn



Производная обладает обычными свойствами
\lm[Тождество Лейбница и прочее] Пусть $R$ --- кольцо. Тогда отображение взятия производной обладает свойствами:\\
1) Для любых $f,g\in R[[x]]$ выполнено $(f+g)' = f'+g'$.\\
2) Для любых $f\in R[[x]]$ и $a\in R$ справедливо $(af)' = af'$.\\
3) Для любого $a\in R$ верно  $a'= 0$.\\
4) Для любых $f,g\in R[[x]]$ имеет место $(fg)' = f'g+fg'$.\\
5) Для любых $f\in R[[x]]$ и $n\in \mb N$ верно $ (f^n)' = nf'f^{n-1}$.\\
6) Для любых $f\in R[[x]]$, $g\in xR[[x]]$ верно $f(g(x))' = g'(x)f'(g(x))$.\\
7) Для любого $f\in R[[x]]^*$ верно $(f^{-1})'=-\frac{f'}{f^2}$.
\elm
\proof Свойства 1),2),3) очевидны. Теперь будем доказывать оставшиеся свойства следующим образом: докажем их для многочленов, а потом покажем, что так как равенство для рядов достаточно проверять  покоэффициентно, то ряд можно заменить на свой начальный кусок, который является многочленом.\\
Итак докажем 4). Пусть $f$ и $g$ --- многочлены. Заметим, что правая и левая часть линейны по $f$ и $g$. Таким образом достаточно доказать только для степеней. Распишем $(x^{n+m})'=(n+m)x^{n+m-1}=nx^{n-1}x^{m}+mx^{m-1}x^n=(x^n)'x^m+(x^{m})'x^n$.

Теперь заметим, что если $f$ и $g$ ряды, то коэффициенты при $x^n$ справа и слева не зависят от коэффициентов при степенях больше $n+1$ в $f$ и $g$. \\
5) Докажем индукцией по $n$. $(f^n)'=(f\cdot f^{n-1})'=f'f^{n-1}+f(n-1)f'f^{n-2}=nf'f^{n-1}$.\\
6) Прежде всего коэффициент $n$-ой степени справа и слева не меняется если $f$ заменить на $f_{\leq n+1}$. Заменим. Теперь заметим, что обе части линейны по $f$ и поэтому можно проверять только для $f=x^n$. Это пункт 5).\\
7) Рассмотрим тождество $ff^{-1}=1$ и продифференцируем его. Перенеся одно слагаемое направо получим $(f^{-1})'f=-f'f^{-1}$. Осталось поделить на $f$. 
\endproof

Итак, оставим в памяти, что производная определена для любых рядов и перекинемся на многочлены. Кажется сейчас у нас появится первое утверждение, которое зависит от характеристики кольца.

\thrm Если многочлен $f(x) \in K[x]$ делится на $p(x)^l$ то $f'(x) \di p(x)^{l-1}$. Более того, если $p(x)$ неприводим, $\chr K > \deg f$ или $\chr K=0$,а $l$ -- наибольшая степень, что $f(x) \di p(x)$, то $f'(x)\ndi p(x)^{l}$. 
\proof Пусть $f(x)=p(x)^lg(x)$. Тогда $$f'(x)=lp(x)^{l-1}p'(x)g(x)+p(x)^lg'(x)=p(x)^{l-1}(lp'(x)g(x)+p(x)g'(x)) \di p(x)^{l-1}.$$
Пусть теперь $g(x)$ и $p(x)$ взаимно просты, $p(x)$ неприводим, а $\chr K > \deg f$ или $\chr K=0$. Наша задача доказать, что последний сомножитель взаимнопрост с $p(x)$ в указанных условиях. Вопрос сводится к взаимной простоте $lp'(x)$ и $p(x)$. Заметим, что если $lp'(x)$ не 0, то он действительно взаимнопрост с $p(x)$ так как $p(x)$ неприводим. Понятно, что в условиях теоремы $l\neq 0$. Следовательно надо рассмотреть ситуацию, когда $p'(x)=0$. 
\lm Пусть $\chr K=p$, $f(x)\in K[x]$. Тогда $f'(x)=0$ в том и только том случае, когда $f(x)=h(x^p)$.
\elm
\proof
Заметим, что коэффициенты $f'(x)$ имеют вид $c_{i-1}=ia_{i}$. Следовательно, $a_{i}$ может не равняться нулю только тогда, когда $i\di p$. Тогда возьмём $h(x)=\sum_{i=0}^{\deg f/p} a_{ip}x^i$.
\endproof
Таким образом, если предположить, что $p'(x)=0$, то степень $p'(x)$ должна быть заведомо больше характеристики, что мы исключили по условию. Видно, что в формулировке теоремы можно ещё много уточнить. Сделайте это сами.
\endproof
\ethrm



\noindent {\bf Пример:} Вот пример многочлена, у которого проблемы с кратностью корня у производной: $x^{p}$ в $\mb Z/p$.

Обсудим ещё одно важное свойство производной. Для этого нам потребуется доказать некоторую лемму.

\lm[О разложении по основанию] Пусть $p$ -- многочлен из $K[x]$, $\alpha\in \mb N$, а $h$ многочлен c $\deg h< \alpha \deg p$. Тогда существуют единственный $h_0, \dots, h_{\alpha-1} \in K[x]$, что $\deg h_i< \deg p $ и 
$$h=\sum_{i=0}^{\alpha-1} h_i p^i.$$
\elm
\proof Индукция по $\alpha$. $\alpha=1$ --- тогда $h=h_0$. Теперь $\alpha>1$.  Пусть $h=qp+h_0$. $q$ раскладывается как $\sum_{i=1}^{\alpha-2} q_i p^i$. Ясно, что получили разложение. С другой стороны, очевидно, что в любом разложении $h_0$ это остаток от деления, а $\sum_{i=1}^{\alpha-1} h_ip^{i-1}$ --- это неполное частное.  По индукции мы знаем, что разложение неполного частного по основанию единственно. 
\endproof

Рассмотрим простейший неприводимый многочлен $x-a \in K(x)$. Тогда многочлены в формуле из предыдущей теоремы есть просто элементы поля $K$. Вопрос состоит в том, как найти эти коэффициенты в разложении по степеням $x-a$?

\thrm[Формула Тейлора для многочленов]
Пусть $h$ элемент $K(x)$, $\chr K =0$, и $\deg h=n$. Тогда имеет место формула
 $$h(x)= h(a)+h'(a)(x-a)+\frac{h''(a)}{2}(x-a)^2+
 \dots + \frac{h^{(n)}(a)}{n!}(x-a)^n.$$
\proof По предыдущей теореме у нас есть разложение 
$$h(x)=a_0+a_1(x-a)+\dots+a_n(x-a)^n.$$
Возьмём $k$-ую производную от обеих частей равенства. Получим
$$ h^{(k)}(x)=k!a_k+(k+1)!a_{k+1}(x-a)+\dots+\frac{n!}{k!}a_n(x-a)^{n-k}.$$
Осталось подставить $x=a$.
\endproof
\ethrm


\section{Интерполяция}

Довольно часто требуется решить следующую задачу: пусть $K$ --- некоторое поле. Пусть дан набор различных точек
$x_1,\dots, x_n \in K$ и дан набор значений $a_1,\dots,a_n\in K$. Требуется построить многочлен $f\in K[x]$, такой что $f(x_i)=a_i$.
Прежде всего заметим, что у нас есть некоторая свобода выбора. А именно, рассмотрим многочлен $\phi(x)=(x-x_1)\dots(x-x_n)$. Тогда можно к любому решению интерполяционной задачи прибавить кратное многочлена $\phi(x)$ и снова получить решение интерполяционной задачи. Таким образом можно любое решение заменить на остаток от деления на многочлен $\phi(x)$. В частности, если есть какое-то решение, то есть решение степени строго меньше $n$.

\dfn[Задача интерполяции] Пусть дан набор различных точек $x_1,\dots,x_n\in K$ и дан набор значений
$a_1,\dots, a_n\in K$. Требуется построить многочлен $f\in K[x]$, такой что $f(x_i)=a_i$ и $\deg f < n$.
\edfn

\thrm Задача интерполяции разрешима и притом единственным образом. Более того, справедлива формула
$$f(x)=\sum_{i=1}^n \frac{a_i\phi(x)}{\phi'(x_i)(x-x_i)},$$
где $\phi(x)=(x-x_1)\dots(x-x_n)$.
\ethrm

\proof Заметим, что $\phi'(x_i)=\prod_{j\neq i}(x_i-x_j)$. Теперь очевидно, что указанная формула даёт решение нужной степени. Единственность очевидна из теоремы о многочленах, совпадающих в достаточном числе точек.
\endproof

Последняя формула называется интерполяционной формулой Лагранжа. Так же есть способ Ньютона для решения интерполяционной задачи.
Он позволяет добавлять точки постепенно.


Рассмотрим более общий вариант интерполяционной задачи. А именно попробуем решить задачу следующего вида.
Пусть задан набор точек $x_1,\dots, x_n$ и для каждой точки $x_i$ задан набор чисел $a_{i,0}, a_{i,1},\dots , a_{i,k_i}$ . Интерполяционная задача состоит в следующем: найти $f$ такой, что $j$-тая производная $f^{(j)}(x_i)=a_{i,j}$. Заметим, что решение можно свободно поменять на кратное многочлена
$$\phi(x)=\prod_{i=1}^n (x-x_i)^{k_i} ,$$
следовательно, степень решения $f$ можно ограничить $\deg f < \sum_{i=1}^n k_i$. Такая задача интерполяции называется задачей интерполяции по Эрмиту.



\thrm Пусть $K$ --- поле характеристики 0 (или достаточно большой положительной характеристики). Решение задачи интерполяции по Эрмиту существует и единственно среди многочленов степени меньше $\sum_{i=1}^n k_i$.
\ethrm
\proof Сведём задачу к китайской теореме об остатках. А именно пусть $f(x)$ многочлен. Тогда значения его производных в точке $x_i$ равны $a_{i,j}$ $j\in \ovl{0,k_i-1}$ тогда и только тогда, когда 
$$f(x)\equiv a_{i,0}+a_{i,1}(x-x_i)+a_{i,2}\tfrac{(x-x_i)^2}{2!}+\dots+ a_{i,k_i}\tfrac{(x-x_i)^{k_i-1}}{(k_i-1)!}\,\, (\mod (x-x_i)^{k_i}).$$
Идеалы $(x-x_i)^{k_i}$ взаимно простые.
\endproof

\rm Вообще для  задачи интерполяции по Эрмиту тоже есть формула, но она не сильно хороша (см. Кострикин, Сборник задач по алгебре, стр 93, задача 30.14 ).\erm


Давайте представим себе, что мы хотим перемножить два многочлена. Если действовать по определению, то понадобится $O(n^2)$ операций сложения и умножения. С другой стороны мы знаем, что оба многочлена и их произведение однозначно определяются своими значениями в точках $\lambda_1,\dots, \lambda_n$ для достаточно большого $n$. Однако перемножить значения гораздо проще! Таким образом, если мы научимся быстро конвертировать многочлен в набор значений в $\lambda_1,\dots, \lambda_n$ и обратно, то мы сможем быстро перемножать многочлены. При этом у нас есть свобода выбора $\lambda_1,\dots, \lambda_n$. 

Оказывается, что если взять $\lambda_i=\omega^i$, где $\omega$ --- первообразный корень степени $n$ из единицы  то есть быстрый алгоритм, для восстановления многочлена по его значениям. Этот алгоритм называется быстрым преобразованием Фурье. 

Пусть $n\in \mb N$ некоторое натуральное число, а $R$ --- кольцо, такое что $n\in R^*$ и $R$ содержит $\omega$ --- некоторый первообразный корень  степени $n$ из единицы, причём $1-\omega^i$ не делитель нуля при $i\nequiv 0(\mod n)$.

Рассмотрим упорядоченную $n$-ку $x=(a_0,\dots,a_{n-1})\in R^n$. Рассмотрим следующий набор $F(x)=(b_0,\dots,b_{n-1})\in R^n$ 
$$b_i=\sum_{j=0}^{n-1} a_j \omega^{ij}.$$

Отображение $x \to F(x)$ из $ R^n \to R^n$ называется дискретным преобразованием Фурье. Где находится связь между этим преобразованием и задачей интерполяции? Давайте посмотрим на строку $(a_0,\dots,a_{n-1})$ как на коэффициенты многочлена $f$ из $R[x]$. Тогда элемент $b_i=f(\omega^i)$.

Оказывается, что обратное отображение имеет очень простой вид: 

\lm $F^{-1}(b)_i=\frac{1}{n}\sum_{j=0}^{n-1} b_j \omega^{-ij}$
\elm 
\proof Достаточно доказать, что $F^{-1}(F(a))=a$. Подставим.
$$F^{-1}(F(a))_i=\frac{1}{n}\sum_{j=0}^{n-1} \sum_{k=0}^{n-1} a_k \omega^{jk} \omega^{-ij}=\sum_{k=0}^{n-1} a_k \cdot \frac{1}{n}\sum_{j=0}^{n-1} \omega^{j(k-i)}.$$

Заметим, что при $k=i$ коэффициент будет равен $\frac{1}{n}\sum_{j=0}^{n-1} \omega^{0}=1$. Вспомним, что по условию если  $k-i\neq 0$, то  $1-\omega^{k-i}$ не делитель нуля. Тогда заметим, что 
$$\sum_{j=0}^{n-1}\omega^{j(k-i)}=\omega^{k-i}\sum_{j=0}^{n-1} \omega^{(j-1)(k-i)}=\omega^{k-i}\sum_{s=0}^{n-1} \omega^{s(k-i)}=\omega^{k-i}\sum_{j=0}^{n-1} \omega^{j(k-i)}.$$
Теперь видно, что $\sum_{j=0}^{n-1}\omega^{j(k-i)}=0$.
\endproof

\thrm Пусть $n=2^k$. Тогда преобразование Фурье можно провести за $O(n\log n)$ операций.
\ethrm
\proof Приведём пример соответствующего алгоритма. Вспомним, что если дан многочлен $f(x)$, то посчитать его значение в точке $a$ это тоже самое, что посчитать остаток от деления $f$ на $x-a$. Нам нужно посчитать остатки от деления на $x-\omega^i$ по всем $0\leq i\leq n-1$. Заметим, что  
$$x^{2^k}-1=(x^{2^{k-1}}-1)(x^{2^{k-1}}+1)=(x^{2^{k-1}}-\omega^0)(x^{2^{k-1}}-\omega^{2^{k-1}}).$$

Более общо $x^{2^i}-\omega^{2j}=(x^{2^{i-1}}-\omega^j)(x^{2^{i-1}}-\omega^{j+\frac{n}{2}})$. В частности, применив указанное соображение $k$ раз получаем  
$$\prod_{i=1}^n(x-\omega^i)=x^n-1.$$

Таким образом видно, что можно последовательно делить с остатком многочлен на многочлены $x^{2^{k-i}}-\omega^{j2^{k-i}}$. То есть на шаге $i$ необходимо будет $2^{i}$ многочленов специального вида. Чтобы понять, что это можно легко сделать докажем лемму. 

\lm Пусть многочлен $f(x)=\sum_{i=0}^{n-1} a_ix^i$. Тогда остаток от деления многочлена $f(x)$ на $x^{\frac{n}{2}}-c$ находится по формуле
$$r(x)=\sum_{i=0}^{\frac{n}{2}-1}(a_i+ca_{i+\frac{n}{2}})x^{i}. $$
В частности для вычисления указанного остатка необходимо $\frac{n}{2}$ умножений и сложений
\elm 
\proof Очевидно верна формула
$$f(x)=(x^{\frac{n}{2}}-c)\sum_{i=0}^{\frac{n}{2}} a_{\frac{n}{2}+i}x^i+r(x).$$
\endproof
 Итого в нашем случае необходимо 
$$n+2\frac{n}{2}+4\frac{n}{4}+\dots+2^k\frac{n}{2^k}=nk$$
умножений и сложений  в кольце $R$.
\endproof




\section{Локализация, поле частных и разложение на простейшие дроби}

Наша задача под конец этого раздела понять, как свести некоторые вопросы про общие кольца к вопросам о полях. Однако по пути мы захватим конструкцию, в некотором смысле противоположенную факторизации, которая позволяет <<упростить>> кольцо.

Все мы довольно хорошо знакомы с рациональными числами. Целые числа вкладываются в рациональные. Поэтому
многие вопросы про целые числа можно свести к рациональным. Например, допустим мы знаем, что многочлен
степени $n$ над $\mb Q$ имеет не более чем $n$ корней. Тогда мы автоматически знаем это и для целочисленных многочленов.
Достаточно просто проинтерпретировать их как многочлены с рациональными коэффициентами, а потом сказать, что
если в $\mb Q$ мало корней, то в $\mb Z$ и подавно.
Рациональные числа отличаются от целых тем, что необратимые элементы $\mb Z$ уже обратимы в $\mb Q$. Попробуем понять, можно
ли насильно обратить некоторое множество элементов. Представим себе, что мы насильно обратили два элемента $f$ и
$g$. Тогда мы так же обратили их произведение $fg$. Для простоты рассмотрим ситуацию над областью целостности, хотя разумный ответ есть и в общем случае. Далее в этом разделе $R$ --- область целостности.

\dfn[Мультипликативная система] Пусть $R$ --- область целостности. Мультипликативной системой  в $R$ называется
подмоноид $U$ в моноиде $(R\setminus\{0\},\cdot)$.
\edfn

\exm\\
1) Пусть $f\in R$. Тогда множество $\{1,f,f^2,f^3,\dots\}$ очевидно является мультипликативной системой.\\
2) Пусть $R$ --- область целостности. Тогда $R\setminus \{0\}$ является мультипликативной системой.\\
3) Более общо. Пусть дан простой идеал $p$. Тогда $U=R\setminus p$ есть мультипликативная система.\\

Дадим теперь следующее определение
\dfn[Локализация] Пусть $U$ --- мультипликативная система в $R$. Определим кольцо $R[U^{-1}]$ как
фактор множества дробей (формально --- пар)
$$ R[U^{-1}]=\{ \tfrac{a}{u}\,|\, a\in R, \, u\in U\}/\sim$$
профакторизованное по отношению эквивалентности $\sim$, заданного правилом
$$ \tfrac{a}{u}\sim \tfrac{b}{v}, \text{ если } av=bu.$$
Операции сложения и умножения введём подобно рациональным числам:
$$ \tfrac{a}{u}+\tfrac{b}{v}=\tfrac{av+bu}{uv} \text{ и } \tfrac{a}{u}\cdot\tfrac{b}{v}=\tfrac{ab}{uv}.$$
\edfn




\thrm[Конструкция работает] Пусть $U$ --- мультипликативная система в $R$. Тогда все операции на множестве $R[U^{-1}]$ корректно определены и вместе с ними $R[U^{-1}]$ становится кольцом.
\ethrm
\proof
Прежде всего необходимо проверить, что указанное отношение действительно есть отношение эквивалентности. Проверим транзитивность. Пусть $av=bu$ и $bw=cv$. Тогда $avbw=cvbu$. Сократим на $vb$. 

Теперь перейдём к корректности операций. Рассмотрим сумму. Пусть $\tfrac{a}{u}\sim \tfrac{a'}{u'}$, а  $\tfrac{b}{v}=\tfrac{b'}{v'}$. Тогда сумма 
$$\tfrac{a'v'+b'u'}{u'v'}\sim \tfrac{uva'v'+uvb'u'}{uvu'v'}= \tfrac{au'vv'+bv'u'u}{uvu'v'}\sim \tfrac{av+bu}{uv}.$$
Произведение --- ещё проще. 

Докажем ассоциативность сложения. Пусть даны дроби $\tfrac{a}{u}$, $\tfrac{b}{v}$, $\tfrac{c}{w}$. Приведём их к общему знаменателю. Тогда ассоциативность следует из ассоциативности для кольца $R$. Остальные свойства --- так же. 
\endproof



\lm[Область целостности вкладывается в свою локализацию] Пусть $U$ мультипликативная система в области целостности $R$. Отображение $i\colon R\to R[U^{-1}]$ заданное по правилу $a\to \tfrac{a}{1}$ является инъективным гомоморфизмом колец.
\elm
\proof Исходя из формул для локализации видно, что это гомоморфизм. Докажем инъективность. Пусть дробь $\tfrac{a}{1}\sim \tfrac{0}{r}$. Тогда $ra=0$. Так как $r\neq 0$, то $a=0$. чтд.
\endproof

%\rm Если $R$ область целостности $U\subseteq R\setminus \{0\}$, то в определении отношения эквивалентности условие $\exists s\in U sav=abu$  можно заменить просто на $av=bu$.
%\erm

%\lm[Область целостности вкладывается в свою локализацию] Пусть $R$ --- область целостности, $U$ --- 
%мультипликативная система в $R$, которая не содержит $0$. Тогда $i\colon R \to R[U^{-1}]$ является мономорфизмом.
%\elm

%\lm[Описание идеалов] Пусть $U$ --- мультипликативная система в $R$. Тогда имеет место взаимно-однозначное
%соответствие 
%$$\{I \leq R\, | \,\forall u\in U, \text{ $u$ не является делителем нуля в } R/I\} \cong \{I \leq R[U^{-1}]\}.$$
%\elm

\thrm[Универсальное свойство] Пусть $R,S$ кольца и $U$ --- мультипликативная система в $R$. Тогда для любого гомоморфизма $\psi \colon R\to S$, такого что $\forall u\in U \,\,\psi(u)$ обратим, существует единственный гомоморфизм $\phi\colon R[U^{-1} ] \to S$ такой, что треугольник коммутативен:
\begin{center}
\begin{tikzpicture}
\node (A) at (0, 0) {$R$};
\node (B) at (2.5, 0) {$S$};
\node (C) at (0, -1) {$R[U^{-1}]$};
\path[->,font=\scriptsize,>=angle 60]
(A) edge node[above]{$\psi$} (B)
(A) edge node[right]{$i$} (C);
\path[dashed,->,font=\scriptsize,>=angle 60]
(C) edge node[below]{$\exists !\, \phi$} (B);
\end{tikzpicture}
\end{center}
\ethrm
\proof
Как всегда начнём с единственности. Вместо дроби $\tfrac{a}{1}$ буду писать просто $a$. Рассмотрим дробь $\tfrac{a}{u}=au^{-1}$. Тогда $\phi(au^{-1})=\phi(a)\phi(u)^{-1}=\psi(a)\psi(u)^{-1}$. Значит вариантов нет.

Теперь надо показать, что отображение, заданное правилом
$$\phi(\tfrac{a}{u})=\psi(a)\psi(u)^{-1}$$
корректно задано и является гомоморфизмом. Проверка прямолинейна.
\endproof

\dfn[Поле частных] Пусть $R$ --- область целостности. Возьмём $U=R\setminus \{0\}$. Тогда кольцо $R[U^{-1}]$ является полем. Обозначим это поле $Q(R)$. Будем называть его полем частных $R$.
\edfn

Например $\mb Q$ --- поле частных $\mb Z$.

\lm Пусть $U$ --- мультипликативная система в области целостности $R$. Тогда $R[U^{-1}]$ вкладывается в $Q(R)$.
\elm
\proof
Из $R[U^{-1}]\to Q(R)$ есть единственный гомоморфизм по универсальному свойству. Пусть он переводит дробь $\frac{f}{g}$ в $0$. Тогда он переводит $f\in R$ в ноль. Тогда $f=0$ по лемме о вложении. Получили инъективность.
\endproof

\dfn[Локализация в простом идеале] Пусть $R$  --- область целостности, $p$ --- простой идеал. Определим кольцо $R_p= R[U^{-1}]$, где $U=R\setminus p$.
\edfn

Например множество всех рациональных чисел, знаменатель которых не делится на $p$, обозначается $\mb Z_{(p)}$ --- является локализацией кольца $\mb Z$ в идеале $(p)$. Из кольца $\mb Z_{(p)}$ всегда есть отображение в $\mb Z/p$ по универсальному свойству. Как это может пригодиться?

Рассмотрим задачу: дана сумма $1+\frac{1}{2}+\dots+\frac{1}{1200}$. Покажите, что числитель этой дроби делится на $1201$. Заметим, что $p=1201$ простое. Отправим эту сумму в $\mb Z/p$. Тогда это будет сумма всех обратных элементов, то есть просто сумма всех элементов кроме 0. Она 0. С другой стороны это дробь. Дробь 0, если числитель 0. Значит числитель делится на $p$.



Конструкция поля частных бывает полезна в теоретических построениях. Например, когда мы применяем приём <<замены коэффициентов>>.

\thrm У многочлена $f$ в области целостности не более чем $\deg f$ различных корней с учётом кратности. \ethrm 
\proof Пусть корни $f$ в $R$ это $x_0,\dots,x_k$ и их кратности это $\alpha_0,\dots,\alpha_k$. Вложим кольцо $R[x]$ в $Q(R)[x]$. Очевидно, что если $f\di (x-x_i)^{\alpha_i}$ над $R$, то $f\di (x-x_i)^{\alpha_i}$ над $Q(R)$. Но тогда $f\di \prod (x-x_i)^{\alpha_i}$ в $Q(R)[x]$. Тогда $  \sum \alpha_i \leq \deg f $, а степень очевидно не меняется.
\endproof



\dfn[Поле рациональных функций] Пусть $K$ --- поле. Тогда $Q(K[x])$ называется полем рациональных функций. Обозначается оно как $K(x)$.
\edfn

\dfn Пусть $R$ кольцо $0\neq f\in R$. Пусть $U=\{1,f,f^2,\dots\}$. Тогда $R[U^{-1}]$ обозначается $R[f^{-1}]$ и
называется локализацией $R$ по элементу  $f$.
\edfn

%\dfn[Многочлены Лорана] Пусть $K$ --- поле. Тогда $K[x][x^{-1}]$ называется кольцом многочленов Лорана. Обозначается как %$K[x,x^{-1}]$.
%\edfn

\dfn[Ряды Лорана] Пусть $K$ --- поле. Тогда $Q(K[[x]])=K[[x]][x^{-1}]$ называется полем рядов Лорана. Обозначается как $K((x))$.
\edfn

\rm Поле $K(x)$ естественным образом вкладывается в $K((x))$ по универсальному свойству.
\erm

Поговорим о специальных свойствах поля $K(x)$. Это поле в целом напоминает поле рациональных чисел, так как является полем частных евклидового кольца.

\lm Пусть $\frac{f}{g} \in K[x]$. Тогда существуют  единственные с точностью до константы многочлены  $h,r$, что $\Nod(h,r)=1$ и $\frac{f}{g}=\frac{h}{r}$. Такие дроби называются несократимыми.
\elm
\proof Возьмём какие-то $f,g$ и рассмотрим $d=\Nod(f,g)$. Тогда $h=\frac{f}{d}$, а $r=\frac{g}{d}$ подходят. Пусть есть две пары $h,r$ и $h',r'$ подходящие по условию. Тогда $hr'=h'r$. Так как $h$ и $r$ взаимно просты выполнено $h\di h'$. Симметрично $h'\di h$. Тогда $h=ch'$. Тогда $r'=cr$.
\endproof

\dfn Дробь $\frac{f}{g} \in K(x)$ называется правильной, если $\deg f< \deg g$. 
\edfn

\lm Любая дробь $\frac{h}{g}$ единственным образом представляется в виде суммы многочлена $f(x)\in K[x]$ и правильной дроби $\frac{h_1}{g_1}$. При этом можно считать, что $g_1=g$
\proof Покажем существование. Поделим с остатком $h(x)=q(x)g(x)+h_1(x)$, где $\deg h_1(x)<\deg g(x)$. Тогда 
$$\frac{h(x)}{g(x)} =\frac{q(x)g(x)+h_1(x)}{g(x)} =q(x)+\frac{h_1(x)}{g(x)}.$$
Покажем единственность. Пусть 
$$f_1(x)+\frac{h_1}{g_1}=f_2(x)+\frac{h_2}{g_2}.$$
Имеем равенство многочленов. 
$$f_1(x)f_2(x)g_1(x)g_2(x)=g_1(x)h_2(x)-h_1(x)g_2(x).$$
Если $f_1\neq f_2$, то степень многочленов справа строго меньше степени многочлена слева. Таким образом $f_1=f_2$, а $\frac{h_1}{g_1}=\frac{h_2}{g_2}$.
\endproof
\elm

\rm Сумма двух правильных дробей -- снова правильная дробь.
\erm

\dfn[Простейшие дроби] Пусть $K$ --- поле, $p\in K[x]$ --- неприводимый многочлен со страшим коэффициентом единица. Тогда дробь
$$\frac{f(x)}{p(x)^{k}} \text{ называется простейшей, если $f \neq 0$ и $\deg f < \deg p$}. $$
\edfn



\thrm[О разложении на простейшие] Пусть $K$ ---  поле. Тогда для любой несократимой дроби $\frac{f}{g} \in K(x)$ существуют единственные многочлен $h\in K[x]$, неприводимые многочлены $p_1, \dots, p_n$, натуральные числа $\alpha_1,\dots, \alpha_n$ и многочлены $h_{ij}$, где $i\in \ovl{1,n}$, и $j\in \ovl{0,\alpha_i}$, что дроби
$$ \frac{h_{ij}}{p_i^{j}} \text{ --- простейшие и } \frac{f}{g}=h+\sum_{i,j} \frac{h_{ij}}{p_i^{j}} .$$
При этом $g=\prod p_i^{\alpha_i}$.
\ethrm

\proof Прежде всего докажем существование. Поделим $f$ на $g$ с остатком $f=qg+r$. Итак $h=q$ найден. Разберёмся с $\tfrac{r}{g}$. Разложим $g=p_1^{\alpha_1}\cdots p_k^{\alpha_k}$. Можно считать, что старшие коэффициенты $p_i$ равны 1 поделив $r$ и $g$ на подходящие константы. Воспользуемся китайской теоремой об остатках. Тогда существуют единственные многочлены $r_i$, что $r_i\equiv r (\mod p_i^{\alpha_i})$, $r_i\equiv 0 (\mod p_j^{\alpha_j})$, где $j\neq i$ и $\deg r_i<\deg g$. Сумма $\sum r_i \equiv r (\mod g)$. С другой стороны их степени меньше $\deg g$. Значит они равны. 

Многочлены $r_i\di \prod_{j\neq i} p_j^{\alpha_j}$. Пусть $r_i=h_i\cdot \prod_{j\neq i} p_j^{\alpha_j}$. Тогда степень $\deg h_i< \deg p_i^{\alpha_i}$. 

$$\frac{r}{g}= \sum \frac{h_i}{p_i^{\alpha_i}}.$$ 

Осталось воспользоваться леммой.\\
Покажем единственность. Итак пусть
$$\frac{f}{g}=h+\sum_{i,j} \frac{h_{ij}}{p_i^{j}}$$

Прежде всего заметим, что $g=\prod p_i^{\alpha_i}$. Действительно, приведя всё выражение справа к общему знаменателю получим $\prod p_i^{\alpha_i}\di g$ из несократимости дроби. Если $g \ndi \prod p_i^{\alpha_i}$, то дробь справа сократима, что, очевидно не так.

Заметим, что если привести к общему знаменателю $$ \sum_j \frac{h_{ij}}{p_i^{j}}= \frac{h_i}{p_i^{\alpha_i}},$$ то  числитель $h_i$ будет многочленом степени меньше $\deg {p_i^{\alpha_i}}$. Так же степень числителя в 
$$\sum_{i,j} \frac{h_{ij}}{p_i^{j}}=\frac{r}{g}$$
меньше $\deg g$. Теперь заметим, что $r=\sum h_i\prod_{j\neq i} p_j^{\alpha_j}$. Тогда $h_i\prod_{j\neq i} p_j^{\alpha_j}=r_i$ из конструкции. Тогда $h_i$ определено однозначно. Теперь воспользуемся единственностью из леммы.
\endproof

\zd Какой аналог у последней теоремы в рациональных числах?
\ezd

Рассмотрим теперь конкретные поля $\mb C$ и $\mb R$. Так как поле $\mb C$ алгебраически замкнуто, то все неприводимые многочлены над $\mb C$ имеют степень 1. Это заметно упрощает жизнь, так как в числителе простейшей дроби могут стоять только константы. 

Самый стандартный способ нахождения разложения на простейшие --- метод неопределённых коэффициентов. Приведём пример нахождения некоторого разложения, которое использует конструкцию интерполяции.

Рассмотрим рациональную функцию $\frac{1}{x^{2n}-1}$. Я хочу найти её разложение на простейшие над $\mb C$ и над $\mb R$. Корни  многочлена $x^{2n}-1$ нам известны --- это $x_l=e^{\tfrac{i \pi l}{n}}$, $l\in \ovl{0,2n-1}$, они без кратностей. Многочлен $g(x)=1$ восстанавливается по своим значениям в точках  $e^{\tfrac{i \pi l}{n}}$ по формуле Лагранжа
$$1=\sum_{l=0}^{2n-1} \frac{ \prod_{i\neq l} (x-x_i)}{2nx_l^{2n-1}}.$$
Тогда 
$$\frac{1}{x^{2n}-1}=\frac{\sum_{l=0}^{2n-1} \frac{ x_l\cdot \prod_{i\neq l} (x-x_i)}{2n}}{x^{2n}-1}= \sum_{l=0}^{2n-1} \frac{x_l}{2n(x-x_l)}.$$
Допустим, что теперь мы хотим получить разложение над $\mb R$. Для этого надо сгруппировать слагаемые  с сопряжёнными корнями
$$
\begin{aligned}
\sum_{l=0}^{2n-1} \frac{x_l}{2n(x-x_l)}&= \frac{1}{2n(x-1)}-\frac{1}{2n(x+1)}+\sum_{l=1}^{n-1} \frac{x_l(x-x_{n-l})+x_{n-l}(x-x_l)}{2n(x^2-2x\cos\tfrac{\pi l}{n}+1)}= \\
&=\frac{1}{2n(x-1)}-\frac{1}{2n(x+1)}+\sum_{l=1}^{n-1} \frac{2x\cos\tfrac{\pi l}{n}-2}{2n(x^2-2x\cos\tfrac{\pi l}{n}+1)} \end{aligned} $$





\section{Степенные ряды как производящие функции}


\dfn[Линейное рекуррентное соотношение] Будем говорить, что последовательность $x_n$ удовлетворяет линейному рекуррентному соотношению $k$-го порядка, если существуют числа $a_0,\dots,a_{k}$, что $a_k,a_0\neq 0$ и 
$$a_k x_{n+k}+a_{k-1}x_{n+k-1}+\dots+a_0x_n=0$$
\edfn


\rm Вообще говоря ничто не мешает считать, что начальные коэффициенты $a_0,\dots,a_s=0$. Просто это означает, что до номера $k+s$ последовательность может быть любой, а после $k+s$ начинает удовлетворять соотношению с коэффициентами $a_{s+1},\dots,a_k$.
\erm

\dfn[Производящая функция] Пусть дана последовательность $a_n$, $n\geq 0$. Производящей функцией для последовательности $a_n$ назовём формальный степенной ряд $f(x)=\sum_{i=0}^{\infty} a_ix^i$.
\edfn



\thrm Ряд из $K[[x]]$ является рядом некоторой правильной дроби $\frac{f(x)}{g(x)}$, тогда и только тогда, когда его коэффициенты  удовлетворяют линейному рекуррентному соотношению. Более того, порядок наименьшего линейного рекуррентного соотношения, которому удовлетворяют коэффициенты, равен степени знаменателя в несократимой дроби.
\ethrm

\proof
Пусть $q(x)$ есть ряд правильной несократимой дроби $\frac{f(x)}{g(x)}$. Тогда $q(x)$ удовлетворяет соотношению $g(x)q(x)=f(x)$. Мы уже один раз выписывали соотношение на коэффициенты $g(x)$, когда $f(x)$ был равен 1. Поступим аналогично. Пусть $g(x)=b_nx^n+\dots +b_0$, $f(x)=a_mx^m+\dots +a_0$, а $q(x)=c_0+c_1x+\dots$. Тогда имеем уравнения на коэффициенты $q(x)$

$$ \sum_{j=0}^{n} b_j c_{i-j} =a_i .$$
Выражение справа равно 0 при $i>m$. Выражение слева при $i\geq n$ всегда имеет $n$ слагаемых. Функция $g(x)$ не может делиться на $x$ так как иначе мы не получили бы элемент из $K[[x]]$ или дробь была бы сократима. Тогда $b_0\neq 0$. Таким образом, при $i\geq n$ получаем рекуррентное соотношение на $c_j$

$$ b_0 c_{j+n}+b_1 c_{j+n-1}+\dots + b_n c_j=0.$$
Обратно, пусть $c_j$ удовлетворяют рекуррентному соотношению 
$$ b_0 c_{j+n}+b_1 c_{j+n-1}+\dots + b_n c_j=0, \text{ где } b_0,b_n \neq 0.$$

Тогда возьмём в качестве $g(x)= b_n x^n+\dots+b_0$. Как теперь найти $f(x)$? Доопределим $c_{-1}=\dots=c_{-n}=0$. Тогда, если начать последовательность с $c_{-n}$, то она вообще говоря не сразу начнёт удовлетворять рекуррентному соотношения. А именно, положим 
$$a_i= \sum_{j=0}^{n} b_{j} c_{i-j}, \text{ где } i\in \ovl{0,n}.$$
Это и есть коэффициенты $f(x)$. Допустим дробь $\frac{f}{g}$ сократима. Тогда по уже доказанному она удовлетворяет соотношению меньшего $\deg g$ порядка.
\endproof

Рассмотрим простейший пример. Какая рациональная функция соответствует последовательности удовлетворяющей соотношению $z_{n+1}=\lambda z_n$, $z_0=1$? Эта последовательность имеет вид $z_n=\lambda^n$. Ей соответствует ряд $$1+ \lambda x+\dots + \lambda^nx^n+\dots .$$  
Это ряд для функции 
$$\frac{1}{1-\lambda x}.$$
Значит функции 
$$\frac{1}{x-\lambda}=\frac{-1}{\lambda}\frac{1}{1-\frac{x}{\lambda}}$$
соответствует последовательность $z_n=-{\frac{1}{\lambda}^{n+1}}$, то есть некоторая геометрическая прогрессия. 

А что соответствует ${\frac{1}{(1-\lambda x)^k}}$, где $k\geq 2$? Вспомним про производную. Заметим, что $$\frac{d^{k-1}}{dx^{k-1}}\frac{1}{1-\lambda x}=\frac{\lambda^{k-1} (k-1)!}{(1-\lambda x)^k}.$$
Переписывая получаем
$$\frac{1}{(1-\lambda x)^k}= \frac{1}{\lambda^{k-1} (k-1)!}\frac{d^{k-1}}{dx^{k-1}}\frac{1}{1-\lambda x}=  \sum_{n=0}^{\infty} C_{n+k-1}^{k-1} \lambda^{n}x^{n}.$$

\crl Пусть последовательность комплексных чисел $z_n$ удовлетворяет соотношению $a_k z_{n+k}+a_{k-1}z_{n+k-1}+\dots+a_0z_n=0$. Пусть многочлен $p(x)=a_k x^k+\dots +a_0$ имеет корни $\lambda_1$ кратности $k_1$, $\ldots$, $\lambda_l$ кратности $k_l$. Тогда последовательность $z_n$ имеет вид 
$$ p_1(n)\lambda_1^n+\dots+p_l(n)\lambda_l^n,$$
где $p_i$ многочлен степени не выше $k_i$.
\proof
Рассмотрим многочлен $g(x)=a_0x^k+\dots+a_k$. Заметим, что $$g(x)=x^k p\left(\frac{1}{x}\right)= x^k\prod\left(\frac{1}{x}-\lambda_i\right)^{k_i}= \prod (1-\lambda_ix)^{k_i}.$$
Последовательность $z_n$ имеет производящую функцию вида
$$\frac{h(x)}{g(x)}.$$
Разложим её на простейшие над $\mb C$. Получим 
$$\frac{h(x)}{g(x)}=\sum_{i=1}^l \sum_{0\leq j < k_i} \frac{b_{ij}}{(1-\lambda_ix)^j}.$$
Каждое слагаемое является производящей функцией для последовательности вида $p_{ij}(n)\lambda_i^n$, $\deg p_i < k_i$. Осталось просуммировать при одинаковом $i$.
\endproof
\ecrl

\dfn Многочлен $a_kx^k+\dots +a_0$ называется характеристическим многочленом линейной рекуррентной последовательности.
\edfn

Рассмотрим пример: пусть $f_n$ --- последовательность чисел Фибоначчи. Она удовлетворяет рекуррентному соотношению $f_{n+2}-f_{n+1}-f_n=0.$ Такой последовательности соответствует многочлен $g(x)=-x^2-x+1$ и $f(x)=x$. Рассмотрим дробь $F(x)=\frac{x}{-x^2-x+1}$  и разложим её в сумму простейших. Корни знаменателя это $\ffi$ и $1-\ffi=\ovl{\ffi}$. Получим 
$$F(x)= \frac{\ffi}{\sqrt{5}(x+\ffi)}-\frac{\ovl{\ffi}}{\sqrt{5}(x+\ovl{\ffi})}.$$
Представим каждое слагаемое в виде ряда и получим формулу 
$$f_n= \frac{1}{\sqrt{5}}(\ffi^{n-1}-\ovl{\ffi}^{n-1}).$$

Пусть последовательность $a_{n+2}=4a_{n+1}-4a_n$ начинается с $a_1=2$, $a_0=0$. Найдём общую формулу. Рассмотрим дробь $$A(x)=\frac{2x}{4x^2-4x+1}=\frac{2x}{(2x-1)^2}.$$ 
Как найти разложение в ряд? Заметим, что $$\frac{2}{(2x-1)^2}= \frac{d}{dx}\frac{-1}{2x-1}.$$
Вспомним, как считается производная для рядов. Тогда
$$A(x)=\sum_{n=0} (n+1) 2^{n+1} x^{n+1}=\sum_{n=0} n2^nx^n.$$

 


Заметим, что если $z_n$ --- комплексная последовательность, удовлетворяющая линейному рекуррентному соотношению, то её производящая функция $f(x)=\frac{h(x)}{g(x)}$ имеет конечный набор комплексных точек, в которых она не определена. Более того, мы даже знаем эти комплексные точки --- это корни $g(x)$, то есть обратные к корням характеристического многочлена. Общая философия, которая за этим стоит такая --- поведение последовательности определяется типом <<особых точек>> её производящей функции, то точек на комплексной плоскости, куда эта  функция не может быть продолжена. В следующей части это замечание сыграет мотивирующую роль.




\section{Арифметические функции}
В теории чисел часто встречаются функции от натурального параметра $n$, которые выдают некоторое число, которое как-то завязано на свойствах кольца $\mb Z/n$. Это несколько загадочная часть теории чисел. Эта область выглядит скорее как техническое средство. Тем не менее обходить её стороной не стоит. Основной тип вопросов, которые будут рассматриваться -- это вопросы асимптотического поведения этих функций, что может понадобится при оценке сложности теоретико-числовых алгоритмов.

\dfn[Арифметические функции] Пусть $R$ --- кольцо. Арифметической функцией со значением в $R$ называется отображение $f\colon \mb N \to R$.
\edfn

Обычно в качестве $R$ берут комплексные числа. Однако, иногда бывает полезно взять в качестве $R$ кольцо каких-нибудь функций.

\exm
\begin{enumerate}
\item $1(n)=1$.
\item $e(n)=\begin{cases} 1, n=1 \\ 0, \text{ иначе}\end{cases}.$
\item $I_k(n)=n^k$.
\item $\varphi(n)$ --- функция Эйлера.
\item И вообще, $f(n)=|V_{g_1,\dots,g_n}(\mb Z/n)|$, где $g_1,\dots,g_n$ какие-то целочисленные многочлены от одинакового числа переменных.
\item $\sigma(n)=\sum_{d|n}d$
\item Более общо $\sigma_k(n)=\sum_{d|n}d^k$.
\item В частности $\sigma_0(n)=d(n)=\sum_{d|n} 1$ то есть число делителей.
\item $r(n)=|\{(x,y)\in \mb Z^2\,|\, x^2+y^2=n\}|$.
\end{enumerate}

Для последовательностей, удовлетворяющих линейным рекуррентным соотношением естественно в качестве производящей функции было взять степенную производящую функцию, так как они ведут себя как геометрическая прогрессия, то с арифметическими функциями дело обстоит иначе. Их величина обычно ограничена полиномом, а то и логарифмом $n$. Следовательно для их исследований пригодны другие производящие функции.

\dfn Пусть $a\colon \mb N\to \mb C$ --- арифметическая функция. Производящей функцией Дирихле или рядом Дирихле для $s$ называется следующее выражение
$$L(s)=\sum_{i=1}^{\infty} \frac{a(n)}{n^s}.$$ 
\edfn

\dfn В частности знаменитая дзета-функция Римана есть функция Дирихле для $1(n)$ то есть
$$\zeta(s)=\sum_{n=1}^{\infty}\frac{1}{n^s}.$$
\edfn

\rm Если последовательность $a(n)$ есть $O(n^{\alpha})$, то ряд Дирихле сходится при всех вещественных $s>\alpha$, а на самом деле и при всех комплексных $s$ c $\re s>\alpha$.
\erm

\fct Пусть $L_1(s)$ -- ряд Дирихле для $a$, а $L_2(s)$ -- ряд Дирихле для $b$. Если ряды $L_1$ и $L_2$ сходятся для всех $\re s>s_0$ и в этой области верно равенство $L_1=L_2$, то функции $a$ и $b$ равны.
\efct

Последние два факта говорят нам, что про ряды Дирихле действительно можно думать, как про честные функции комплексного аргумента. Однако нас больше будет интересовать формальная сторона дела. Тем не менее указанная картинка будет мотивировать нас к некоторым определениям.

Представим себе два ряда Дирихле $L_1(s)=\frac{a_1}{1^s}+\frac{a_2}{2^s}+\dots$ и $L_2=\frac{b_1}{1^s}+\frac{b_2}{2^s}+\dots$. Перемножим их. Получится выражение вида 
$$\sum_{n,m} \frac{a_nb_m}{(nm)^s}=\sum \frac{1}{n^s}\sum_{d|n}a_db_{\frac{n}{d}}.$$
Это даёт нам основание ввести на всех арифметических функциях структуру умножения не с помощью покомпонентного произведения, а при помощи полученной формулы.

\dfn[Свёртка Дирихле] Пусть $a,b\colon \mb N \to R$ -- арифметические функции. Определим их свёртку Дирихле при помощи формулы $$c_n=\sum_{d|n}a_db_{\frac{n}{d}}=\sum_{d_1d_2=n}a_{d_1}b_{d_2}.$$
\edfn

\lm Относительно свёртки Дирихле и поточечного сложения арифметические функции образуют кольцо. Единицей кольца является функция $e$.
\elm

Мы сконцентрируемся сейчас на функциях специального вида.

\dfn Арифметическая функция $f$ называется мультипликативной, если $f(1)=1$ и для любых двух взаимно простых $(n,m)=1$ 
$$f(nm)=f(n)f(m).$$ 
\edfn
Возможно вы удивитесь такому определению. Можно было бы ожидать каких-то других слов. Однако именно такая <<неполная>> мультипликативность встречается очень часто.

\exm\\
Функции примеров 1),2),3),4),5) очевидно или по Китайской теореме об остатках являются мультипликативными. На самом деле функции примеров 6),7),8) и, если чуть-чуть подправить, то 9) так же являются мультипликативными. Двинемся в сторону доказательства этих фактов.

Прежде всего заметим, что 
\lm Если функция $f$ мультипликативна, а $n=p_1^{\alpha_1}\dots p_k^{\alpha_k}$, то $f(n)=\prod f(p_i^{\alpha_i})$.
\elm

\lm Если функция $f$ мультипликативна, то её ряд Дирихле раскладывается в произведение
$$L(s)=\prod_{p \text{ простое}} (1+f(p)+f(p^2)+\dots).$$
\elm

\lm Свёртка двух мультипликативных функций снова мультипликативна.
\elm

\lm Обратная к мультипликативной функции снова мультипликативна.
\elm

\thrm Пусть $f\colon \mb N \to R$, тогда $f$ -- обратима тогда и только тогда, когда $f(1)\in R^*$ и обратная функция задаётся формулой
$$f^{-1}(n)=\frac{-1}{f(1)}\sum_{d|n,\, d<n} f(\frac{n}{d})g(d).$$
\ethrm

\lm Обратная к мультипликативной функции снова мультипликативна.
\elm

Наша задача сейчас описать обратную к функции $1(n)$. Для этого вспомним, что $$\zeta(s)=\prod\left(1+\frac{1}{p^s}+\frac{1}{p^{2s}}+\dots\right)= \prod \left(\frac{1}{1-p^{s}}\right).$$
Тогда $\zeta(s)^{-1}$ имеет вид
$$\zeta(s)^{-1}=\prod(1-p^{s}).$$
Если раскрыть скобки, то в получившейся сумме не нулевые слагаемые будут только для бесквадратных $n$, а коэффициент перед ними будет $(-1)^k$, где $k$ -- число простых сомножителей.

\dfn[Функция Мёбиуса] Определим функцию $\mu(n)$ по следующему правилу
$$\mu(n)=\begin{cases}
0, \text{ если существует простое $p$, что $p^2|n$}\\
(-1)^k, \text{ если $n=p_1\dots p_k$}
\end{cases}$$
\edfn

\crl Если $f(n)=\sum_{d|n} g(d)$, то $g(n)=\sum_{d|n} \mu(d)f(\frac{n}{d})$
\ecrl

\crl Равенство $f(n)=\sum_{d|n} g(d)$ верно для всех $n$, тогда и только тогда, когда верно $g(n)=\sum_{d|n} \mu(d)f(\frac{n}{d})$.
\ecrl

Не имея возможности заниматься комплексным анализом остановимся на простых асимптотических свойствах арифметических функций и просто каких-нибудь тождеств с ними.

Наша задача --- посчитать среднее значение функции Эйлера. Запишем сумму $S_n=\ffi(1)+\dots+\ffi(n)$ и посчитаем её асимптотику. Заметим, что $\phi(n)=\sum_{d|n}\mu(d)\frac{n}{d}$. Получаем 
$$\begin{aligned}
S_n=&\sum_{k=1}^n\sum_{d|k}\mu(d)\frac{k}{d}=\sum_{dd'\leq n} \mu(d)d'=\\
&=\sum_{d\leq n}\mu(d)\sum_{d'=1}^{[\frac{n}{d}]} d'=\frac{1}{2}\sum_{d\leq n}\mu(d)([\frac{n}{d}]^2+[\frac{n}{d}])=\\
&=\frac{1}{2}\sum_{d\leq n}\mu(d)(\frac{n^2}{d^2}+O(\frac{n}{d}))=\frac{1}{2}\sum_{d\leq n}\mu(d)\frac{n^2}{d^2}+O(n\sum \frac{1}{d})=\\
&=\frac{n^2}{2}\sum_{d\leq n}\frac{\mu(d)}{d^2}+O(n\log n)=\frac{n^2}{2}\sum_{d=1}^{\infty}\frac{\mu(d)}{d^2}+O(n)+O(n\log n)= \frac{3n^2}{\pi^2}+O(n\log n)
\end{aligned}$$

Заметим, что сумма $S_n$ это так же количество взаимно простых чисел $p,q$, что $1\leq p<q\leq n$. Количество вообще пар чисел, что  $1\leq p<q\leq n$ есть $\frac{1}{2}n(n+1)$. Отсюда получаем, что при больших $n$ вероятность выбрать два взаимно простых числа есть $\frac{6}{\pi^2}$.




\chapter{Линейная алгебра}

\setcounter{zad}{0}
\setcounter{lem}{0}
\setcounter{thm}{0}
\setcounter{defn}{0}
\setcounter{cor}{0}

\section{Системы линейных уравнений и метод Гаусса}

\dfn Пусть $R$ -- кольцо. Тогда системой $m$ линейных уравнений от $n$ неизвестных называется набор условий

$$\begin{cases}
a_{11}x_1+\dots + a_{1n}x_n=b_1\\
\vdots \\
a_{m1}x_1+\dots+a_{mn}x_n=b_m
\end{cases},$$
где $a_{ij}, b_i \in R$.
\edfn

 Совершенно понятно, что система линейных уравнений определяется однозначно числами $a_{ij}$ и $b_i$. Эти числа удобно организовывать в матрицы.

\dfn Матрица размера $m\times n$ над кольцом $R$ -- это набор чисел проиндексированных двумя индексами $a_{ij}$ $i\in \ovl{1,m}$, $j\in \ovl{1,n}$. Множество всех матриц размера $m\times n$ над кольцом $R$ обозначается как $M_{m\times n}(R)$. Обычно матрицы я буду обозначать заглавными буквами, например $A$. Тот факт, что матрица $A$ имеет размер $m\times n$ будем записывать как $A\in M_{m\times n}(R)$.
\edfn

\dfn Матрица системы линейных уравнений называется матрица $A\in M_{m\times n}$, заполненная коэффициентами этой системы -- то есть числами $a_{ij}$. Матрица размера $m\times n+1$ содержащая дополнительно столбец $b_1,\dots, b_m$ называется расширенной матрицей системы. Мы будём отчёркивать столбец $b$, чтобы подчеркнуть его особую роль и будем обозначать расширенную матрицу системы как $(A|b)$.
\edfn

От каждой системы нас прежде всего интересует множество её решений. Поэтому логично ввести определение:

\dfn Две системы линейных уравнений называются эквивалентными, если множества их решений совпадают.
\edfn

Как для данной системы линейных уравнений можно построить эквивалентную? Прежде всего заметим, что если есть два уравнения, то по ним можно построить много новых, а именно, пусть имеют $\lambda$ и $\mu$ из $R$. Тогда сложив два уравнения с коэффициентами $\lambda$ и $\mu$ получаем третье
$$\begin{cases}
a_1x_1+\dots+a_nx_n=c\\
b_1x_1+\dots+b_nx_n=d
\end{cases} \Rightarrow (\lambda a_1+\mu b_1)x_1+ \dots +(\lambda a_n+ \mu b_n)x_n= \lambda c+\mu d.$$
Понятно, что если набор $(x_1,\dots,x_n)$ -- решение первых двух, то и нового тоже.

Получать новые уравнения мы научились, остался вопрос про эквивалентные системы. Введём определение элементарных преобразований.

\dfn Пусть дана система уравнений
 $$\begin{cases}
a_{11}x_1+\dots + a_{1n}x_n=b_1\\
\vdots \\
a_{m1}x_1+\dots+a_{mn}x_n=b_m
\end{cases},$$
Элементарным преобразованием первого типа над этой системой линейных уравнений называется следующая операция. Рассмотрим уравнения с номерами $i$ и $j$, где $i\neq j$ и элемент $\lambda \in K$. Тогда прибавим  $i$-ое уравнение к $j$-ому с коэффициентом $\lambda$ и поместим результат на место $j$-го уравнения.
\edfn

\rm Очевидно, что решение новой системы содержит решения старой. Однако верно и наоборот, так как старая система получается из новой аналогичным прибавлением $i$-ого уравнения к $j$-ому, но с коэффициентом $-\lambda$.
\erm 

\dfn Элементарным преобразованием второго типа называется преобразование меняющее местами $i$-ое и $j$-ое уравнения местами. Элементарным преобразованием третьего типа называется преобразование, домножающие $i$-ое уравнение на коэффициент $\lambda \in R^*$.
\edfn

\rm Элементарное преобразование третьего типа приводит к эквивалентной системе так как есть обратное преобразование -- домножение на $\lambda^{-1}$. Для преобразования второго типа эквивалентность тривиальна.
\erm

Нам будет удобно вместо системы линейных уравнений работать с её упрощённой записью -- матрицей этой системы. Поэтому логично перевести понятия элементарных преобразований на язык матриц.

\dfn Элементарным преобразованием строк первого типа над матрицей $A$ называется прибавление к $j$-ой строчке матрицы $A$ её $i$ строки с некоторым коэффициентом $\lambda$. Элементарным преобразованием второго типа называется перестановка $i$-ой и $j$-ой строк в матрице $A$. Преобразованием третьего типа называется домножение $i$-ой строчки на обратимый элемент $\lambda \in R^*$.
\edfn

Нас в основном пока будет интересовать случай $R=K$ -- поле. Обсудим метод Гаусса решения систем линейных уравнений. Он заключается в том, чтобы с помощью элементарных преобразований перевести систему уравнений в эквивалентную, так, чтобы её вид был как можно более простым. Сформулируем это.

\dfn Будем говорить, что матрица $A$ имеет ступенчатый вид, если каждая новая строчка начинается с большего количества нулей, чем предыдущая. Говоря строго, для $i$-ой строки номер столбца в котором стоит первый ненулевой элемент строки строго больше, чем аналогичный  номер у $i-1$ строки, если только строка не целиком состоит из нулей.  
\edfn

Утверждение, которое стоит за методом Гаусса можно сформулировать следующим образом:

\thrm Любую матрицу над полем $K$ можно перевести элементарными преобразованиями к ступенчатому виду. Более того, можно считать, что для каждой строки первый её ненулевой элемент равен 1 и в столбце над ним стоят нули.
\ethrm
Предъявим индукционный алгоритм для получения ступенчатого вида:\\
{\bf Случай 1:} Элемент $a_{11}\neq 0$. Тогда прибавим ко всем остальным строкам первую с коэффициентами $-\frac{a_{i1}}{a_{11}}$. Получится матрица у которой в перво столбце стоят нули, кроме первой позиции. Вычеркнем первый столбик и первую строчку и продолжим по индукции.\\
{\bf Случай 2:} Элемент $a_{11}=0$, но в $i$-ой строчке стоит ненулевой элемент. Поменяем строку с номером $i$ с первой строкой и продолжим, как в случае 1.\\
{\bf Случай 3:} Весь первый столбец нулевой. Тогда вычеркнем первый столбец и продолжим по индукции.


Указанные преобразования очевидно приводят матрицу к ступенчатому виду. Способ добиться нулей над первыми не нулевыми элементами называется обратным ходом метода Гаусса. 


Прежде всего заработаем единицы в первых ненулевых элементах строк $a_i$ поделив на $a_i^{-1}$.

Затем посмотрим на последнюю ненулевую строку -- скажем строку $k$, первый  столбец с ненулевым элементом в которой имеет номер $j_k$, и прибавим её ко всем строкам выше с коэффициентом $-a_{lj_k}$ для $l$-ой строки. После чего перейдём к следующей строке.\\



\noindent {\bf Метод Гаусса}
Приступим к решению системы линейных уравнений. Приведём расширенную матрицу системы к ступенчатому виду. Рассмотрим последнюю ненулевую строчку. Если её ненулевой элемент находится в самом последнем отчёркнутом столбце, то решений нет, потому, что эта строчка соответствует уравнению $0x_1+\dots+0x_n=b_1\neq 0$, которое, как ни крути, решений не имеет. 

Если же такого не происходит, то разделим переменные на два класса -- те, в чьём столбце есть первый ненулевой элемент какой-то строки и те, в чьём столбце такого элемента нет -- обозначим последние за $x_{i_1},\dots,x_{i_n}$. Тогда выбрав любые значения для $x_{i_1},\dots,x_{i_n}$ из оставшихся уравнений мы однозначно восстановим значения всех остальных переменных. Более того, значения остальных переменных представляются в виде значений многочленов первой степени от  $x_{i_1},\dots,x_{i_n}$. Так выглядит стандартное описание всех решений линейного уравнения, которое выдаёт метод Гаусса. 

\rm Метод Гаусса подразумевает работу со строчками в определённой порядке, в частности, перестановка строк делается только в экстренных случаях. Но, в принципе, никто не запрещает для удобства переставлять строчки и прибавлять их друг к другу в произвольном порядке -- лишь бы вид системы в конце позволял проанализировать множество решений.
\erm




\section{Векторные пространства}

\dfn[Векторное пространство]
Векторным пространством над полем $K$ называется множество $V$ вместе с отображениями $+\colon V\times V \to V$ и $\cdot \colon K \times V \to V$. удовлетворяющие свойствам:\\
1) $V, +$ является абелевой группой\\
2) $\forall v \in V$ верно, что $1\cdot v=v$\\
3) $\forall v \in V$, $\forall \lambda, \mu \in K$ верно, что $(\lambda+\mu)\cdot v= \lambda\cdot v + \mu \cdot v$.\\
4) $\forall u,v \in V$, $\forall \lambda \in K$ верно, что $\lambda\cdot(u+v)= \lambda\cdot u + \lambda \cdot v$.\\
5) $\forall v \in V$ $\forall \lambda, \mu \in K$ верно, что $(\lambda\mu)\cdot v= \lambda\cdot(\mu \cdot v)$.
\edfn

\exm\\
0) Само поле $K$ вместе со сложением и умножением.\\
1) Пространство столбцов $K^n$. Умножение и сложение покомпонентное.\\
2) Обобщая. Пространство матриц $M_{m\times n}(K)$.\\

3) Пусть $X$ -- множество. Рассмотрим множество всех функций  из $K$ в $X$ , то есть $K^X$. Это векторное пространство над полем $K$ с поточечным сложением и умножением.\\
4) Рассмотрим множество непрерывных вещественнозначных функций на отрезке $[0,1]$. Это векторное пространство над $\mb R$.\\
5) Рассмотрим множество последовательностей над полем $K$, удовлетворяющих заданному линейному рекуррентному соотношению $a_k x_{n+k}+\dots+a_0x_n=0$. Это векторное пространство над $K$.\\
6) Рассмотрим множества всех многочленов $K[x_1,\dots,x_n]$, всех рациональных функций $K(x_1,\dots, x_n)$, рядов $K[[x_1,\dots,x_n]]$. Это векторное пространство относительно естественного сложения и умножения на элементы $K$.\\
7) Пусть $A$ -- абелева группа, такая, что любой ей элемент имеет порядок $p$, для фиксированного простого числа $p$. Тогда на $A$ существует и единственна структура векторного пространства над $\mb Z/p$.\\
8) Пусть $L$ -- расширение поля $K$. Тогда $L$ является векторным пространством над $K$.\\



Отметим простейшие свойства элементов векторных пространств.
\lm Пусть $V$ -- векторное пространство над полем $K$. Тогда выполнено:
1) $\forall v  \in V$ выполнено, что $0\cdot v =0$.\\
2) Если для некоторых $\lambda \in K$ и $v \in V$ верно равенство $\lambda v =0$, то либо $\lambda=0$, либо $v=0$.\\
3) $\forall v  \in V$ выполнено, что $(-1)\cdot v=-v$.\\
\elm









\dfn[Подпространство] Пусть $V$ -- векторное пространство над полем $K$. Подмножество $U\subseteq V$ называется подпространством $V$, если\\
1) $U$ -- подгруппа $V$.\\
2) $\forall \lambda \in K$, $\forall u \in U$ верно, что $\lambda u \in U$.\\
По другому говоря,  операции на $V$ можно сузить на $U$, с тем, чтобы $
U$ стало векторным пространством относительно этих операций.
\edfn

\exm\\ 
1) Рассмотрим множество столбцов из $K^n$, у которых первая координата равно 0. Это подпространство в пространстве столбцов.\\
2) Рассмотрим множество многочленов, которые делятся на данный многочлен $p(x)K[x]$. Это подпространство в $K[x]$. \\
3) Рассмотрим множество непрерывных на отрезке $[0,1]$ функций, принимающих значение $0$  в точках $0, \frac{1}{2}, 1$. Это подпространство в $C[0,1]$.\\
4) Рассмотрим множество многочленов степени не выше $n$ от одной переменной $$K[x_1,\dots, x_k]_{\leq n}=\{ f \in K[x_1,\dots, x_k]\,|\, \deg f\leq n\}.$$ Это подпространство в  $K[x_1,\dots,x_n]$.\\
5) Рассмотрим множество правильных дробей $\frac{f}{g}\in K(x)$. Это подпространство в $K(x)$.\\
6) Множество троек $(x,y,z) \in K^3$, удовлетворяющих уравнению $x+y+z=0$ является подпространством $K^3$.\\


\dfn[прямая сумма и прямое произведение] Рассмотрим набор векторных пространств $U_{\alpha}$ над полем $K$,  где элементы $\alpha$ пробегают множествво индексов $I$. Определим прямую сумму пространств из семейства $U_{\alpha}$, как множество
$$\prod_{\alpha \in I} U_{\alpha}$$
вместе с операциями $$(u_{\alpha})_{\alpha\in I}+ (v_{\alpha})_{\alpha\in I}=(u_{\alpha}+v_{\alpha})_{\alpha\in I},\,\,\, \lambda \cdot (u_{\alpha})_{\alpha\in I}= (\lambda \cdot u_{\alpha})_{\alpha\in I}.$$
То есть операции покомпонентные. Определим прямую сумму набора $U_{\alpha}$ как подпространство в $\prod_{\alpha \in I} U_{\alpha}$, заданное следующими условиями
$$\bigoplus_{\alpha \in I } U_{\alpha}=\left\{ (u_{\alpha})_{\alpha \in I} \,|\, \text{ все, кроме конечного числа компонент $u_{\alpha}$ равны 0}\right\}.$$
\edfn

\rm Прямая сумма конечного числа пространств совпадает с прямым произведением. Обычно мы будем использовать значок прямой суммы $V_1\oplus \dots \oplus V_n$.
\erm


Как и в жизни элементы пространства обычно не интересны сами по себе, а только во взаимоотношении с окружающей их действительностью.

\dfn Линейной комбинацией векторов $v_1,\dots, v_n$ с коэффициентами $\lambda_1, \dots, \lambda_n$, называется элемент $v\in V$ 
$$v=\lambda_1 v_1 +\dots + \lambda_n v_n.$$
Если хотя бы один из элементов $\lambda_1,\dots, \lambda_n $ не равен 0, то говорят, что линейная комбинация нетривиальна.
\edfn

\lm Рассмотрим набор $v_1,\dots,v_n \in V$. Пусть $w_1=\mu_{11}v_1+\dots+\mu_{1n}v_n$, $\dots$, $w_m= \mu_{m1}v_1+\dots+\mu_{mn}v_n$. Рассмотрим набор $\lambda_1,\dots, \lambda_m$. Тогда вектор $w=\sum \lambda_i w_i$ является линейной комбинацией набора $v_i$. 
\elm


\dfn[Линейная зависимость] Набор векторов $v_1,\dots,v_n$ называется линейно зависимым, если 0 является нетривиальной линейной комбинацией $v_1,\dots, v_n$, то есть существуют  $\lambda_1, \dots, \lambda_n \in K$ не все равные 0, что
$$0=\lambda_1v_1+\dots+\lambda_n v_n.$$
\edfn

\dfn[Линейная независимость] Набор векторов $v_1,\dots,v_n$ называется линейно независимым, если он не является линейно зависимым, то есть если $\lambda_1, \dots, \lambda_n \in K$ такие, что $$0=\lambda_1v_1+\dots+\lambda_n v_n, \text{ то $\lambda_1=\dots=\lambda_n=0$}.$$ 
\edfn



\rm Будем говорить, что набор линейно независим, если независим каждый его конечный поднабор. 
\erm

\exm \\
0) Набор из одного нуля линейно зависим.\\
1) Пусть $v_1$ и $v_2$ два вектора из $V$. Они линейно зависимы тогда и только тогда, когда они пропорциональны.\\
2) Рассмотрим пространство $K^n$ и набор столбцов 
$$e_1=\pmat 1\\0\\ \vdots\\ 0\epmat,\, \dots, e_n=\pmat 0\\ 0 \\ \vdots \\ 1 \epmat.$$
Это линейно независимая система векторов.\\
3) Аналогично в пространстве матриц $M_{m \times n}(K)$ имеется набор матриц $e_{ij}$ вида
$$ e_{ij}= 
\bordermatrix{
 & &j&& \cr
 &0&\cdots&\cdots&0\cr
 &\vdots&\ddots && \vdots\cr
i&\vdots& 1 & \ddots& \vdots\cr
 &0&\cdots& \cdots&0
}
$$\\
4) Все мономы $x^{\alpha}$ в кольце  $K[x_1,\dots,x_n]$ линейно независимы\\
5) Набор  $\frac{1}{x-\lambda}$ линейно независим.\\
6) Любой поднабор линейно независимого набора линейно независим.\\


\thrm[О линейной зависимости линейных комбинаций.] Пусть $u_1,\dots,u_m$ и $v_1,\dots,v_n$ два набора векторов. При этом все вектора $u_i$ являются линейными комбинациями $v_j$, то есть $u_i=\sum_{j=1}^n \lambda_{ij}v_j$. Тогда, если $m>n$, то $u_i$ обязательно линейно зависимы. 
\ethrm
\proof Индукция по $n$. $n=1$. Все вектора $u_i$ кратны $v_1$ и пропорциональны друг другу.

Будем поступать как в методе Гаусса. Запишем $u_i$ в виде 
$u_i=\sum_{j=1}^n \lambda_{ij}v_j$. Если для некоторого индекса $j$ все $\lambda_{ij}=0$, то можно воспользоваться предположением индукции.

Рассмотрим вектор $u_i$, что $\lambda_{in}\neq 0$. Тогда перейдём к набору $$u_s'=u_s - \frac{\lambda_{sn}}{\lambda_{in}}u_i= \sum_{j=1}^{n-1} \mu_{sj} v_j, \,\,\,\, s\neq i.$$
Это набор из $m-1$ элемента, которые суть линейные комбинации $v_1,\dots,v_{n-1}$. Этот набор линейно зависим по индукционному предположению, то есть существуют $\nu_{s}$ не все равные нулю, что
$$0=\sum \nu_s u_{s}'= \left(\sum\nu_s\frac{\lambda_{sn}}{\lambda_{in}}\right)u_i +\sum \nu_s u_s.$$
Заметим, что не все коэффициенты при $u_s$ равны нулю. Таким образом мы получили нетривиальную линейную зависимость.
\endproof




\dfn Пусть $X$ подмножество векторного пространства $V$. Тогда подпространство, порожденное $X$ -- это наименьшее подпространство, содержащее $X$. Обозначается оно $\lan X \ran$. Это подпространство так же называют линейной оболочкой $X$.
\edfn

 
\lm Пусть $X\subseteq V$. Тогда линейная оболочка $\lan X \ran$ существует и описывается как множество всех линейных комбинаций элементов из $X$.
$$\lan X \ran = \{ v\in V\,|\, \exists x_1, \dots,x_n \in X, \text{ и } \lambda_1,\dots,\lambda_n \in K, \text{ что } v=\lambda_1x_1+\dots+\lambda_nx_n\}$$
\proof Аналогично лемме про идеалы.
\endproof
\elm

\dfn Будем говорить, что набор $v_{\alpha} \in V$ $\alpha \in I$ является порождающим для $V$, если $\lan \{v_{\alpha}\}_{\alpha \in I}\ran= V$. Иными словами, для любого $v \in V$ существуют $v_{\alpha_1},\dots,v_{\alpha_n}$  и $\lambda_1,\dots,\lambda_n$, что $v=\sum \lambda_i v_{\alpha_i} $.
\edfn

\dfn[Базис] Набор векторов $v_{\alpha}$, $\alpha \in I$ называется базисом пространства $V$, если он является порождающей и линейно независимой системой векторов в $V$. \edfn

\exm\\
1) Набор векторов $e_i \in K^n$ является базисом. Этот базис называют стандартным.\\
2) Набор $e_{ij}$ является базисом $M_{m\times n}(K)$.\\
3) Мономы $x^{\alpha}$ являются базисом $K[x_1,\dots,x_n]$.\\
4) Элементы $1,x, \dots, x^n, \dots$ и $\frac{1}{(x-\lambda)^n}$ по всем $\lambda \in \mb C$ являются базисом в $\mb C(x)$.\\
5) 






\lm[Переформулировки] Пусть $v_1,\dots,v_n$ -- набор элементов пространства $V$.
Тогда следующие свойства эквивалентны: \\
1) $v_1,\dots,v_n$ -- базис $V$.\\
2) $v_1,\dots,v_n$ -- минимальный по включению порождающий набор векторов в $V$.\\
3) $v_1,\dots,v_n$ -- максимальный по включению набор линейно независимых векторов в $V$.\\
4) Для любого $v\in V$ существуют единственные $\lambda_1,\dots,\lambda_n \in K$, что $v=\lambda_1v_1+\dots+\lambda_nv_n$.
\proof 
\endproof
\elm

\dfn Пространство называется конечно порождённым, если существует конечная порождающая система $v_1,\dots,v_n$ для $V$.
\edfn

\thrm[Теорема о дополнении до базиса] Пусть $V$ -- конечно порождённое векторное пространство. Тогда любой набор линейно независимых векторов $(u_{\alpha})_{\alpha \in I}$ можно дополнить до базиса при помощи элементов заданного конечного порождающего множества $v_1,\dots,v_n$.
\proof Будем добавлять элементы из порождающего множества к линейно независимой системе до тех пор, пока полученный набор будет оставаться линейно независимым.
Индукция по числу не задействованных элементов из порождающего множества. Если все элементы задействованы, то линейно независимая система является порождающей, так как содержит таковую, то есть, является базисом. 

Рассмотрим порождающий набор $v_1,\dots,v_n$. Пусть первые $k$ его элементов не задействованы, а остальные вместе с $u_{\alpha}$ образуют линейно независимую систему. Тогда возьмём вектор $v_1$ -- он либо линейно зависим с $v_{k+1},\dots,v_n, u_{\alpha}$ либо нет. Если нет, то добавим его и получим линейно независимую систему с большим числом векторов из $v_i$. В противном случае $v_1 \in \lan v_{k+1},\dots,v_n, u_{\alpha} \ran$. Тогда посмотрим на $v_2$ и поступим для него аналогично. 

Мы не смогли воспользоваться предположением индукции только в одном случае -- когда все $v_1,\dots,v_k\in \lan v_{k+1},\dots,v_n, u_{\alpha} \ran$. Но тогда
$$V=\lan v_1,\dots,v_n \ran \subseteq
\lan v_1,\dots,v_k, v_{k+1},\dots,v_n, u_{\alpha} \ran=\lan v_{k+1},\dots,v_n, u_{\alpha} \ran.$$
Тогда $v_{k+1},\dots,v_n, u_{\alpha}$ является линейно независимой и порождающей системой.
\endproof
\ethrm

\crl В любом конечно-порождённом пространстве есть конечный базис.
\proof Пустое множество линейно независимо. Дополним его до базиса.
\endproof
\ecrl


\thrm[Теорема о равномощности базисов] Пусть $V$ -- конечно-порождённое пространство. Тогда любые два базиса $V$ конечны и равномощны.
\proof Можно считать, что один базис $v_1,\dots,v_n$ конечен. Рассмотрим другой базис $u_{\alpha}$. Тогда по теореме о линейной зависимости линейных комбинаций число независимых элементов в $u_{\alpha}$ не более $n$. Пусть их $m\leq n$. Тогда заметим, что $v_j$ выражаются через $u_i$. Тогда $n\leq m$.
\endproof
\ethrm

\dfn[Размерность] Пусть $V$ -- конечно-порождённое пространство. Размерностью $V$ называется количество элементов в базисе $V$.
\edfn


\rm Верны бесконечномерные версии этих теорем. А именно, любую линейно независимую систему можно дополнить до базиса при помощи элементов любой порождающей системы. Любое пространство имеет базис и два разных базиса одного и того же пространства равномощны.
\erm



\section{Линейные отображения}

\dfn[Линейное отображение] Пусть $U,V$ -- два векторных пространства над полем $K$. Отображение $L\colon U \to V$ называется линейным, если\\
1) $\forall a,b \in U$ верно, что $L(a+b)=L(a)+L(b)$.\\
2) $\forall a \in U$, $\lambda \in K$ верно, что $L(\lambda a)=\lambda L(a)$.
\edfn

\exm\\
1) 


На паре мы обсудили понятие линейного отображения между векторными пространствами. Линейное отображение называется изоморфизмом, если оно биекция. Бывают ещё эпи-, моно-, эндо- и автоморфизмы. Их определения так же стандартны. Часто вместо слов эндоморфизм пространства $V$ говорят оператор на пространстве $V$.

Основная теорема, которая говорит про устройство линейных отображений, следующая:
\begin{thm}
Пусть $V_1$, $V_2$ --- векторные пространства над полем $K$. Пусть $e_1,\dots,e_n$ - базис $V_1$, а $f_1,\dots,f_n$ --- набор каких-то векторов из $V_2$. Тогда существует единственное отображение $L\colon V_1 \to V_2$, что $L(e_i)=f_i$. Пусть вектор $v\in V_1$ раскладывается по базису $v=\sum \lambda_i e_i$, то $L(v)=\sum \lambda_i f_i$.
\end{thm}

Это позволило нам установить следующие 

\begin{fact}
Задание базиса в пространстве $V$ размерности $n$ равносильно заданию изоморфизма $V\to K^n$. А именно надо базис $V$ отправить в стандартный(обратно --- взять прообраз стандартного базиса при указанном изоморфизме). Произвольному вектору  указанный изоморфизм сопоставляет столбик координат этого вектора в базисе $V$.
\end{fact}

\begin{fact}
Все линейные отображения $L\colon K^n \to K^m$ имеют вид $L(x)=Ax$, где $A$ --- матрица $m\times n$ (определяется однозначно, составлена из столбцов $L(e_i)$, $e_i$ -- стандартный базис $K^n$).
\end{fact}

Сведём задачу про линейные отображения к матрицам.
\begin{defn}
Пусть $V_1$, $V_2$ - векторные пространства над полем $K$ с базисами $e_1,\dots, e_n$ и $f_1,\dots, f_m$ соответственно. Пусть $L\colon V_1\to V_2$ - линейное отображение. Рассмотрим диаграмму:

\begin{center}
\begin{tikzpicture}
\node (A) at (1, 1) {$V_1$};
\node (B) at (0, 0) {$K^n$};
\node (C) at (3, 1) {$V_2$};
\node (D) at (4, 0) {$K^m$};
\path[->,font=\scriptsize,>=angle 60]
(A) edge node[above]{$L$} (C)
(A) edge node[above,rotate=45]{$\sim$} (B)
(C) edge node[above,rotate=-45]{$\sim$} (D);
\path[->,font=\scriptsize,>=angle 45]
(B) [bend left] edge node[below]{$A$}  (D);
\end{tikzpicture}
\end{center}

Сквозная композиция задаёт линейное отображение из $K^n\to K^m$, то есть матрицу $A$. Матрица $A$ называется матрицей линейного отображения $L$ в базисах $e_1,\dots, e_n$ и $f_1,\dots, f_m$. $i$-ый столбец матрицы $A$ состоит из координат $L(e_i)$ в базисе $f_1,\dots, f_m$.
\end{defn}

\begin{rem}
Пусть $L\colon V_1 \to V_2$ - линейное отображение. Тогда $\Ker L$ подпространство $V_1$, а $\im L$ подпространство $V_2$. Коль скоро мы научились строить матрицу отображения, то видимо мы умеем искать базисы ядра и образа $L$ (всё это про решение системы $Ax=0$). 
\end{rem}

С линейными отображениями можно производить следующие операции:\\
а) поточечная сумма,\\
б) поточечное домножение на $\lambda\in K$,\\
в) композиция линейных отображений.

\begin{fact}
Множество $\Hom_K(V_1,V_2)$ (все линейные отображения из $V_1$ в $V_2$) естественным образом оснащается структурой векторного пространства используя операции а)б). Множество всех эндоморфизмов $\End_K(V)=\Hom_K(V,V)$ является ассоциативной алгеброй с единицей над полем $K$ благодаря а)б)в).
\end{fact}

Несложно проверить, что сумме отображений соответствует сумма матриц, а домножение на элемент $\lambda\in K$ --- покомпонентное домножение всех элементов матрицы на $\lambda$.
Пусть есть две матрицы $A\in M_{m\times n}(K)$ и $B\in M_{l\times m}(K)$. Какая матрица соответствует композиции линейных отображений, построенных по $A$ и $B$?

\begin{defn}
Определим произведение $C=A\cdot B$ следующим образом: 
$$C_{ij}= \sum_{1\leq k\leq m} A_{ik} B_{kj}$$
Иными словами надо взять $i$-ую строку $A$, $j$-ый столбец $B$, покомпонентно их перемножить, а потом результаты сложить.
\end{defn}

Матрица произведения и задаёт композицию линейных отображений. Обратимому линейному отображению соответствует обратимая матрица, то есть такая матрица $A$, что существует $B$, что $AB=E$, $BA=E$ ($E$ - единичная матрица подходящего размера для каждого из произведений). Видно, однако, что так как изоморфизм сохраняет размерность, то обратимые матрицы всегда квадратные. Матрица $B$ называется обратной к $A$ и обозначается $A^{-1}$.


Теперь можно разобраться с ситуацией про замену базиса. Пусть даны пространства $V_1$, $V_2$ и линейное отображение $L\colon V_1\to V_2$. Рассмотрим в пространстве $V_1$ два базиса $e_1,\dots, e_n$ (старый) и $e_1',\dots, e_n'$ (новый). Аналогично в $V_2$ --- $f_1,\dots, f_m$ (старый) и $f_1',\dots, f_m'$ (новый). Нарисуем диаграмму


\begin{center}
\begin{tikzpicture}
\node (A) at (1, 1) {$V_1$};
\node (B) at (0, 0) {$K^n$};
\node (C) at (3, 1) {$V_2$};
\node (D) at (4, 0) {$K^m$};
\node (E) at (-1, 1) {$K^n$};
\node (F) at (5, 1) {$K^m$};
\path[->,font=\scriptsize,>=angle 60]
(A) edge node[above]{$\color{red} L$} (C)
(A) edge node[above left]{ $e'$} (B)
(C) edge node[above right]{$f'$} (D)
(A) edge node[above]{ $e$} (E)
(C) edge node[above]{ $f$} (F);
\path[->,font=\scriptsize,>=angle 45]
(B) [bend left] edge node[below]{$\color{red} {A'}$}  (D)
(E) [bend left] edge node[above]{$\color{red}{A}$ } (F)
(E) [bend left] edge node[below left]{$\color{red}{C}$ } (B)
(F) [bend right] edge node[below right]{$\color{red}{D}$}  (D);
\end{tikzpicture}
\end{center}

{\color{red} Внимание!!!} Именно указанные матрицы $C$ и $D$ называются матрицами замены базиса из $e$ в $e'$ и из $f$ в $f'$. Они решают следующую задачу: координаты вектора в старом базисе переводят в координаты вектора в новом базисе.
Нас интересует следующее соотношение, позволяющее выразить матрицу в новых базисах, через матрицы замены базисов и старую матрицу:
$$A'=DAC^{-1}.$$
Для вычисления, например, матрицы $C$ необходимо векторы старого базиса $e$ выразить через векторы нового базиса $e'$ и записать коэффициенты в матрицу. Замечу, что матрицу $C^{-1}$, которая, видимо, является матрицей замены в обратном направлении часто вычислить проще. 


В самом конце мы рассмотрели алгоритм для обращения матрицы $A$ --- надо сформировать матрицу $(A|E)$ и преобразовать её методом Гаусса к виду $(E|B)$. Матрица $B$ и будет равна $A^{-1}$.


Так же сформулируем полезную теорему, которую мы ещё не обсуждали:
\begin{thm}
Пусть $L\colon V_1 \to V_2$ --- линейное отображение. Тогда 
$$\dim V_1= \dim \Ker L +  \dim \im L.$$
\end{thm}


Было дано определение группы $\GL(V)$ --- общей линейной группы, то есть группы всех изоморфизмов из $V\to V$. Если $V=K^n$, то для $\GL(K^n)$ имеется специальное обозначение: $\GL_n(K)$. Был доказан факт

\begin{fact}
Группа $\GL_n(K)$ транзитивно(с одной орбитой) действует на всех $k$-мерных подпространствах в $K^n$. Матрица стабилизатора подпространства $e_1,\dots, e_k$ имеет блочный вид
$$\left(\begin{matrix}A & B\\
0 & C \\
\end{matrix}\right),$$
где $A$ и $C$ обратимые матрицы размера $k\times k$ и $n-k\times n-k$.
\end{fact}


Мы ввели обозначения 

\begin{defn} Пусть $V$ векторное пространство над полем $K$. Обозначим за $V^{*}=\Hom(V,K)$. Это пространство называется пространством линейных функционалов на $V$ или просто двойственным пространством к $V$. 
\end{defn}

Мы выяснили, что для конечномерных пространств $\dim V = \dim V^{*} $ и что имеет место следующий естественный изоморфизм $V \to V^{**} $, который переводит $x \to (f\to f(x))$.

Каждому подпространству $W\leq V$ мы сопоставили пространство $W^{\bot}\leq V^{*}$  $W^{\bot}=\{f\in V^{*}\,|\, \forall\, w\in W\,\, f(w)=0\}$.

Было дано определение прямой суммы пространств. После чего было показано, как вычислять отображения из прямой суммы и в прямую сумму.

\begin{fact}
Рассмотрим пространство $U\oplus V$. Рассмотрим отображения проекции на $U$, и $V$ компоненты ($pr_U$, $pr_V$ сответственно) и отображения вложения $i_U(u)=(u,0)$ $i_V(v)=(0,v)$

\begin{center}
\begin{tikzpicture}
\node (A) at (0, 0) {$U$};
\node (B) at (2, 0) {$U\oplus V$};
\node (C) at (4, 0) {$V.$};

\path[->,font=\scriptsize,>=angle 60]
(B) edge node[above]{$pr_U$} (A)
(B) edge node[above]{$pr_V$} (C)
(C) [bend left] edge node[below]{$i_V$} (B)
(A) [bend right] edge node[below]{$i_U$} (B);
\end{tikzpicture}
\end{center}


С их помощью можно задать естественные изоморфизмы
$$\Hom(U\oplus V, W)\cong \Hom(U,W)\oplus \Hom(V,W),$$
$$\Hom(W, U\oplus V)\cong \Hom(W,U)\oplus \Hom(W,V).$$
\end{fact}

Под конец мы определили сумму подпространств и рассмотрели последовательность ($U$, $V\leq W$)
$$U\cap V \to U\oplus V \to U+V \leq W$$
которая дала формулу
$$\dim U +\dim V = \dim U\cap V + \dim (U+V).$$

В завершение мы поняли как искать элементы в пересечении, а именно, если $U=\lan u_1,\dots, u_l \ran$, $V=\lan v_1, \dots, v_k\ran$ то надо составить матрицу $A=(u_1, \dots, u_l, v_1, \dots, v_k)$, решить однородное уравнение с матрицей $A$, найти базис решений, а затем у базисных векторов взять последние $k$ координат  $\lambda_1,\dots, \lambda_k $. Вектор $\sum \lambda_i v_i$ будет базисным в пересечении.



\lm[Формула Грассмана]
\elm


\section{Определитель}

А именно, мы стартовали с понятия объёма параллелепипеда в $n$-мерном пространстве и показали, что есть некий ряд аксиом, которым это понятие должно удовлетворять. Эти аксиомы имеют смысл над любым полем и даже однозначно задают некоторый объект. 


\begin{defn}
Отображение $\mu \colon  V^n\to K $ называется полилинейным, если для любого $1\leq i\leq n$ 
$$\mu(v_1,\dots,v_i+\lambda u_i,\dots, v_n)= \mu(v_1,\dots,v_i,\dots, v_n)+\lambda\mu(v_1,\dots,u_i,\dots, v_n).$$
\end{defn}

\begin{defn}
Полилинейное отображение $\mu \colon V^n\to K $ называется антисимметричным или кососимметриеским, если 
$$\mu(v_1,\dots,v,\dots,v,\dots, v_n)=0.$$
\end{defn}

Мы обсудили, что условие антисимметричности можно заменить на следующее естественное условие 
$$\mu(v_1,\dots,v_i,\dots,v_j,\dots, v_n)=-\mu(v_1,\dots,v_j,\dots,v_i,\dots, v_n)$$
над полем характеристики $\ k\neq 2$. Дадим похожее не менее важное определение, которое пока нам не понадобится.

\begin{defn}
Полилинейное отображение $\mu \colon  V^n \to K $ называется симметричным, если 
$$\mu(v_1,\dots,v_i,\dots,v_j,\dots, v_n)= \mu(v_1,\dots,v_j,\dots,v_i,\dots, v_n).$$
\end{defn}

Все полилинейные отображения называются ещё полилинейными формами. Перейдем теперь к понятию формы объема.

\begin{defn}
Пусть $n=\dim V$. Ненулевая антисимметричная форма $\mu \colon V^n \to K $ называется формой объёма.
\end{defn}


\begin{defn}
Пусть $V=K^n$. Определителем $\det$ называется форма объёма на $V$, такая что $\det(e_1,\dots, e_n)=1$, где $e_i$ --- стандартный базис.
\end{defn}

Пространство $(K^n)^n$ естественно отождествляется с множеством матриц $M_n(K)$, поэтому можно считать, что определитель задан на множестве всех матриц, и его образ $\det(E)=1$.

Подводя итоги видно, что по определению отображение $\det$ должно удовлетворять условиям \\
0) $\det(E)=1$\\
1) $\det(\dots,v,\dots,v,\dots)=0$\\
2) $\det(\dots,\lambda v,\dots)=\lambda\det(\dots,v,\dots)$\\
3) $\det(\dots,v+u,\dots)=\det(\dots,v,\dots)+\det(\dots,u,\dots)$\\

С другой стороны отображение типа объёма естественно удовлетворяет другим свойствам...\\
0) $\Vol(E)=1$\\
$1'$) $\Vol(\dots,v,\dots,u,\dots)=\Vol(\dots,v,\dots,u+\lambda v,\dots)$\\
2) $\Vol(\dots,\lambda v,\dots)=\lambda\det(\dots,v,\dots)$\\
В принципе геометрически можно понять и свойство 3 (для векторов, чьи проекции на подходящую ось сонаправлены)\\
3) $\Vol(\dots,v+u,\dots)=\Vol(\dots,v,\dots)+\Vol(\dots,u,\dots)$\\

Видно, что хотя мы желаем совпадения понятия определителя и понятия объёма параллелепипеда, набор тождеств (которые на самом деле их и определяют) несколько отличается. Для практических целей стоит получить свойство $1'$) для $\det$. Это просто. Раскроем в выражении $\det(\dots,v,\dots,u+\lambda v,\dots)$ скобки и вынесем $\lambda$ (по свойствам 2) и 3)). Ненужное слагаемое равно 0 по свойству 1).

На самом деле тождеств 0) $1'$) 2)  тоже достаточно, потому что они позволяют работать с помощью метода Гаусса для столбцов (и говорят, что если есть нулевой столбец, то определитель обнуляется).



\begin{thm} Форма объема на $V$ существует и единственна с точностью до множителя из $k$. В частности определитель однозначно определён и на матрице $A$ задаётся формулой $$\det(A)=\sum_{\sigma \in S_n} (-1)^{\sgn(\sigma)} \prod_{1\leq i\leq n} a_{i\sigma(i)}.$$
\proof
Формула для определителя очевидно удовлетворяет нужным аксиомам. Единственность следует из того, что метод Гаусса однозначно позволяет посчитать определитель
\end{thm}

С вычислительной точки зрения эта формула бесполезна, но она даёт некоторые важные следствия. Например, то, что определитель есть многочлен степени $n$ с целыми коэффициентами от элементов матрицы (следовательно, понятие определителя можно ввести над любым коммутативным кольцом).

Ещё одно следствие можно получить из этой теоремы: определитель не меняется при элементарном преобразовании для строк 1 типа. Надо определить отображение $\det_{new} (A)=\det(CA)$, где $C$ --- матрица элементарного преобразования. Это отображение удовлетворяет всем свойствам по столбцам и следовательно совпадает с исходным. Аналогично можно разобраться с преобразованиями остальных типов. 

Следовательно можно использовать преобразования строк, а не столбцов (что мы с успехом и делали на паре).

Выпишем несколько свойств определителей:

\begin{fact}
1) $\det(AB)=\det(A)\det(B)$\\
2) $\det(A)=\det(A^{T})$\\
3) $\det \left(\begin{matrix}A & B\\
0 & C \\
\end{matrix}\right)= \det(A)\det(C)$\\
4) Определитель верхнетреугольной или нижнетреугольной матрицы равен произведению диагональных элементов. 
5) При смене строк местами знак определителя меняется.
\end{fact}


Было сформулировано несколько фактов касательно многочленов от нескольких переменных, которые помогают при угадывании (вычислении) определителей (ведь определитель --- многочлен).
\begin{fact}
Пусть $K$ поле. Тогда любой элемент  $f\in K[x_1,\dots,x_n]$  $f\neq 0$ однозначно раскладывается на неприводимые множители с точность до обратимых элементов поля $K$.
\end{fact}

Следующий факт был сформулирован неверно на паре. Найдите два отличия.

\begin{fact}
Пусть $K$ алгебраически замкнутое поле. Тогда если  $f,g\in K[x_1,\dots,x_n]$, $f$ неприводим, и из того, что $f(\lambda_1,\dots, \lambda_n)=0$ следует, что $g(\lambda_1,\dots, \lambda_n)=0$, то $f$ делит $g$.
\end{fact}


Последнее, что мы обсудили было разложение матрицы по строке или столбцу.

\begin{fact} При разложении по $j$-ому столбцу формула даёт $\det(A)=\sum_{i=1}^n (-1)^{i+j} a_{ij}\det( A^{ij})$, где $A^{ij}$ матрица $A$ без $j$-ого столбца и $i$-ой строки.
\end{fact}



А ещё мы обсудили, что бывает гомоморфизм групп из $S_n\to GL_n(K)$, образ которого состоит из матриц у которых в любом столбце и в любой строке по одной единице.

А еще мы поняли, что два базиса $v_1,\dots, v_n$ $u_1,\dots, u_n$ в $\mb R^n$ могут быть непрерывно продеформированы внутри пространства всех базисов тогда и только тогда, когда соответствующие определители имеют одинаковый знак (надо было разложить всё на элементарные преобразования и разобраться с ними по отдельности).

Когда у нас есть произвольное пространство $V$ над $\mb R^n$, то все базисы в нём тоже разбиваются на две кучки. Однако какую из них выбрать неясно. Выбор одной из этих кучек (классов эквивалентности базисов) называется заданием ориентации на пространстве $V$ над $\mb R$.


\section{Модули или линейная алгебра над кольцами}

\begin{defn}
Пусть $R$ --- ассоциативное кольцо с единицей. Абелева группа $M$ вместе с операцией $\cdot R\times M \to M$ называется  левым $R$-модулем , если 
Ассоциативность для умножения\\
1) $\forall a \in M,\, \forall r,s\in R$ выполнено $r\cdot(s\cdot a)=(rs)\cdot a$\\
Дистрибутивность \\
2) $\forall a,b \in M,\, \forall r\in R$ выполнено $r\cdot(a+b)=r\cdot a+ r\cdot b$\\
3) $\forall a \in M,\, \forall r,s\in R$ выполнено $(r+s)\cdot b=r\cdot b + s\cdot b$
очень хочется, чтобы единичка действовала как тождественное отображение\\
4) $\forall a \in M$ выполнено $1\cdot a=a$ .\\
\end{defn}

\begin{defn}
Пусть $R$ --- ассоциативное кольцо с единицей, а $M$, $N$ --- левые $R$-модули.  Гомоморфизмом левых $R$-модулей называется гомоморфизм абелевых групп $f\colon M \to N$ удовлетворяющий свойству $f(ra)=rf(a)$ для любого $r\in R$ и любого $a\in M$.
\end{defn}

\begin{defn}
Пусть $R$ --- ассоциативное кольцо с единицей, а $M$, -- левый $R$-модули. Подгруппа $N\leq M$ называется подмодулем, если $\forall r\in R$ $\forall n\in N$ верно, что $rn \in N$.
\end{defn}

Все модули будут левыми. Более того, в случае коммутативных колец принято говорить просто про модули, так как по левому модулю автоматически можно  получить правый модуль ($m*r:=r\cdot m$) и наоборот.


\exm\\
\enm
\item Абелева группа $M$  единственным образом снабжается структурой $\mb Z$ модуля. 
\item Пусть $R$ --- коммутативное кольцо. Задать структуру $R[t]$-модуля на $M$   эквивалентно заданию структуры $R$-модуля и гомоморфизма модулей $L\colon M \to M$. В частности, если $R=K$ --- поле, то $K[t]$ модули это операторы на векторных пространствах над $K$.
\item Над произвольным ассоциативным кольцом с единицей $R$ есть левый модуль $R$. Такой модуль иногда называют регулярным или свободным модулем ранга 1.
\item Пусть $N$ и $M$ --- левые $R$-модули, тогда $N\oplus M$ снабжается естественной структурой левого $R$-модуля.
\item Пусть задано множество индексов $I$ и для каждого $i\in I$  задан левый модуль $M_i$. Тогда прямой суммой семейства $M_i$ называется подмодуль в прямом произведении $\prod_{i\in I} M_i$ (домножение покомпонентное)

$$\bigoplus_{i\in I} M_i = \left\{\{u_i\}_{i\in I} \,|\,  u_i \in M_i,  \text{ где все кроме конечного числа $u_i$ равны 0  } \right\}.$$
\item Пусть $I$ --- множество индексов. Модуль $R^{\oplus I}= \bigoplus_{i\in I} R$ называется свободным модулем ранга $|I|$ (все изоморфные таким тоже называют свободными). Для конечного множества индексов это определение совпадает с прямым произведением.
\item Пусть $N\leq M$ подмодуль. Тогда фактор $M/N$ единственным образом снабжается структурой левого $R$-модуля.
\item Левые идеалы  внутри кольца $R$ однозначно соответствуют подмодулям $R$, как левого модуля над собой.
\item Пусть $I\leq R$ --- левый идеал. Тогда модуль $R/I$ называется циклическим.
\eenm




\begin{defn}
Пусть $M$ --- $R$-модуль. Будем говорить, что подмножество $X\subseteq M$ порождает подмодуль $\langle X \rangle=\{u\in M \,|\, u=\sum r_ix_i\}$.
\end{defn}


\begin{thm} Пусть $M$ модуль над $R$. Тогда для всякого множества $I$ имеет место  соответствие:
$$\Hom(R^I,M)\cong \{ \{u_i\}_{i\in I} \,|\, u_i\in M  \}$$
Иными словами гомоморфизм однозначно задаётся образами стандартных базисных.
\end{thm}

\begin{cor}
Любой модуль есть фактор какого-то свободного (надо воспользоваться первой теоремой о гомоморфизме).
\end{cor}

\begin{defn}
Базисом модуля $M$ называется набор $\{v_i\}_{i\in I}$, что для любого $v\in M$ $\exists r_i\in R$, что  $v=\sum r_i v_i$, причём все, кроме конечного числа $v_i=0$ (т.е. сумма конечная).
\end{defn}

\begin{cor}
Выбор базиса задаёт изоморфизм со свободным модулем и наоборот, изоморфизм со свободным модулем задаёт базис. Модули довольно редко имеют базис и бывают свободными...
\end{cor}

\begin{defn}
Модуль $M$ называется конечно порождённым, если существует конечное  $X \subseteq M$ $\langle X \rangle = M$. Эквивалентно, если существует сюръективный гомоморфизм  $R^n \to M$
\end{defn}

\begin{defn}
Кольцо $R$ называется нётеровым, если любой подмодуль конечно порождённого модуля конечно порождён.
 \end{defn}

Для коммутативных колец верно следующее:

\begin{thm} Область главных идеалов нётерова. Кольцо многочленов от $n$ переменных над нётеровым кольцом нётерово. Фактор нётерого кольца по любому  идеалу --- нётерово кольцо.
\end{thm}

Рассмотрим конечно порождённый модуль $M$ над кольцом $R$. Тогда есть сюръективное отображение $f\colon R^m\to M$. Пусть  $K$ -- ядро $f$ (этот подмодуль $R^m$ называется модулем соотношений, подумайте почему). Тогда, если кольцо $R$ нётерово, то  $K$ --- конечно порожден и есть отображение $R^n \to K$. Имеем:
\begin{center}
\begin{tikzpicture}
\node (A) at (-2, 0) {$R^n$};
\node (B) at (0, 0) {$R^m$};
\node (C) at (1.5, 0) {$M$};
\node (D) at (-1, -1) {$K$};

\path[->>,font=\scriptsize,>=angle 60]
(A) edge  (D)
(B) edge (C);

\path[right hook->,font=\scriptsize,>=angle 60]
(D) edge  (B);

\path[dashed, ->,font=\scriptsize,>=angle 60]
(A) edge  (B);

\end{tikzpicture}
\end{center}

Таким образом классификация модулей с точностью до изоморфизма приводит к классификации отображений из $R^n\to R^m$, то есть матриц.




\section{Немножко о полиномиальных тождествах}

Начнём с того, что не смогли довести до конца, а именно с вычисления определителя
 $$\Delta =\left(\begin{matrix} 
1 & 1 & 1 & \dots & 1\\
1 & \eps  & \eps^2 & \dots&  \eps^{n-1}\\
1 & \eps^2 & \eps^4 & \dots & \eps^{2(n-1)}\\
\vdots & \vdots  &  \vdots   & \ddots   & \vdots \\
1 & \eps^{n-1} & \eps^{2(n-1)} & \dots  & \eps^{(n-1)^2}
\end{matrix}\right),$$
где $\eps$ --- первообразный корень степени $n$ из единицы.
Прежде всего $\Delta= \prod_{n-1\geq i> j\geq 0}(\eps^i-\eps^j)$. Печаль состоит в том, что посчитать это выражение не легко, но можно посчитать его квадрат. А именно
$$\Delta^2=(-1)^{\tfrac{n(n-1)}{2}}\prod_{i\neq j}(\eps^i-\eps^j)= (-1)^{\tfrac{n(n-1)}{2}} \prod_{i} \varphi'(\eps^i)=n^n (-1)^{\tfrac{n(n-1)}{2}}\prod_{i} \eps^{i(n-1)}=\pm n^n,$$
где $\varphi(x)=x^n-1$.
Теперь фиксируем конкретный первообразный корень $\eps=\cos(\tfrac{2\pi}{n})+i\sin(\tfrac{2\pi}{n})$. Мы хотим добиться положительности какого-то выражения от $\eps$, чтобы установить, каким конкретно образом извлечь корень из $\Delta^2$. Рассмотрим элемент $\eps_1=\cos(\tfrac{\pi}{n})+i\sin(\tfrac{\pi}{n})$ --- конкретный корень из $\eps$. Тогда
$$\Delta= \prod_{n-1\geq i> j\geq 0}(\eps^i-\eps^j)= \prod_{i> j}(\eps_1^{2i}-\eps_1^{2j})=\prod_{i>j}\eps_1^{i+j}\prod_{i> j}(\eps_1^{i-j}-\eps_1^{j-i})=\eps_1^{\tfrac{n(n-1)^2}{2}} i^{\tfrac{n(n-1)}{2}}\prod_{i> j}2\sin \tfrac{\pi(i-j)}{n}.$$
Последнее произведение положительно и следовательно равно $\sqrt{|\Delta^2|}=n^{\tfrac{n}{2}}$.

$$\Delta=n^{\tfrac{n}{2}}\eps_1^{\tfrac{n(n-1)^2}{2}} i^{\tfrac{n(n-1)}{2}}=n^{\tfrac{n}{2}} i^{(n-1)^2+\tfrac{n(n-1)}{2}}=n^{\tfrac{n}{2}} i^{\tfrac{(n-1)(3n-1)}{2}}.$$

Вот такое вот вычисление. Из него, например, видно, что возможность извлечения корня из $n$  зависит от наличия корней из единицы.




Теперь перейдём к новой теме, которую мы обсудили. Она называется принцип продолжения алгебраических тождеств. Тип задач, которые указанные методы позволяют решить следующий:\\
Пусть дано некоторое полиномиальное равенство вида $p(x_1,\dots, x_n)=0$, которое можно доказать для достаточно большого числа значений $x_1,\dots,x_n$ из некоторого (коммутативного, как и везде) кольца $K$. Для каких ещё колец и каких $x_1,\dots, x_n$ справедливо это равенство?\\
Ответ на этот нечёткий вопрос такой же нечёткий: обычно равенство справедливо везде, где оно имеет смысл.

Особую тонкость составляет вопрос, когда равенство $p(x_1,\dots, x_n)=0$ доказывалось при предположении о выполнимости некоторых тождеств для $x_1,\dots,x_n$. С каждой такой ситуацией приходится разбираться отдельно.

Техника доказательства таких тождеств лежит на трёх китах:
\begin{kit}
Пусть $K$ --- бесконечное или просто достаточно большое поле. Тогда, если многочлен $p(x_1,\dots,x_n)=0$ для всех $x_1,\dots,x_n$, то он равен 0 в $K[x_1,\dots,x_n]$. На самом деле достаточно проверять для определённого конечного набора значений переменных. 
\end{kit}

\begin{kit}
Пусть $R$ подкольцо в $S$. Тогда равенство $p(x_1,\dots,x_n)=0$ для некоторых элементов $x_1,\dots,x_n\in R$ можно доказывать, как равенство  для элементов из $S$. В частности, если $R$ --- область целостности, то в качестве $S$ можно взять поле частных $Q(R)$ и применять все факты верные над полем. В частности, если $R=K[x_1,\dots,x_n]$ то при доказательстве тождества можно перейти к полю $K(t_1,\dots,t_n)$.
\end{kit}


\begin{kit}
Если верно тождество $p(x_1,\dots,x_n)=0$, как равенство внутри $R[x_1,\dots,x_n]$, то оно верно как тождество для любых элементов $x_1,\dots, x_n\in S$, где $S$ --- какая-то $R$-алгебра (при подходящей интерпретации коэффициентов $p$ в $S$). 
\\

В частности, если верно $p(x_1,\dots,x_n)=0$ для $p(x_1,\dots,x_n)\in \mb Z[x_1,\dots,x_n]$, то оно верно для любого кольца.
\end{kit}

Приведём пример: 
\prdl
Пусть $R$ --- произвольное кольцо. Пусть $A,B$ матрицы $n\times n$ над кольцом $R$. Тогда $\det(AB)=\det(A)\det(B)$.
\proof
Заметим, что тождество $\det(AB)=\det(A)\det(B)$  полиномиально по элементам матриц $a_{ij}, b_{ij}$ и у этого многочлена целые коэффициенты. То есть его можно проинтерпретировать как тождество в кольце $\mb Z[a_{11},\dots,a_{nn},b_{11},\dots,b_{nn}]$. Для его доказательства перейдём к полю частных. Там оно очевидно верно(это поле). Тогда оно верно в $\mb Z[a_{11},\dots,a_{nn},b_{11},\dots,b_{nn}]$, тогда оно верно в любой $\mb Z$ алгебре, то есть в любом кольце.
\eprdl

Нам понадобится формула Крамера и её частный случай --- формула для присоединённой матрицы.

\begin{fact}
Пусть дана система лин. уравнений $Ax=b$ с квадратной матрицей $A$ над полем $K$. Если матрица $A$ --- обратима, то единственное решение этой системы имеет вид $x_i=\frac{\Delta_i}{\Delta}$, где $\Delta=\det A$, а $\Delta_i$ --- определитель матрицы, полученной из  $A$ заменой $i$-го столбца на столбец $b$.
\end{fact}

\begin{defn}
Присоединённой матрицей к матрице $A$ называется матрица $\Adj A_{ij}= A_{ji}$ где $A_{ij}$ --- алгебраическое дополнение элемента $a_{ij}$.
\end{defn}

\begin{fact}
Верен факт $\Adj A \cdot A= A\cdot \Adj A= \det(A)\cdot E$. В частности, есть формула (рациональная функция от коэффициентов A) для обратной матрицы.
\end{fact}

\prdl
Пусть $R$ --- произвольное кольцо. Пусть $A$ матрица $n\times n$ над кольцом $R$. Тогда матрица $A$ обратима тогда и только тогда , когда $\det(A)\in R^*$ --- обратимый элемент.
\proof
Заметим, что по предыдущему предложению $1= \det(E)=\det(A A^{-1})=\det(A)\det(A^{-1})$. Следовательно, если матрица обратима, то и определитель обратим. Обратно --- рассмотрим тождества $\Adj A \cdot A= A\cdot \Adj A= \det(A)\cdot E$. Они верны в кольце $\mb Z[a_{11},\dots, a_{nn}]$, потому что верны в его поле частных. Следовательно верны в любом кольце. Остаётся только поделить на определитель $A$.
\eprdl

\begin{cor}
Матрица $A$ из $M_n(\mb Z)$ обратима тогда и только тогда, когда  $\det(A)=\pm 1$.
\end{cor}

Теперь пусть у нас ситуация посложнее.
\prdl
Пусть квадратные матрицы $A$ и $B$ над полем $K$  коммутируют. Тогда
$$\det\left(\begin{matrix} 
A & B \\
C & D\\
\end{matrix}\right) = \det(DA-CB).$$
\proof Здесь видны проблемы уже над полем. Для начала покажем, когда  это тождество заведомо верно. Предположим, что матрица $A$ обратима. Домножим матрицу 
$$\left(\begin{matrix} 
A & B \\
C & D\\
\end{matrix}\right) \text{ слева на матрицу } \left(\begin{matrix} 
E & 0 \\
-CA^{-1} & E\\
\end{matrix}\right)$$

Определитель от этого не изменится. Получится матрица $$\left(\begin{matrix} 
A & B \\
0 & D - CA^{-1}B\\
\end{matrix}\right) .$$
С другой стороны определитель этой матрицы равен 
$$\det(A) \det(D-CA^{-1}B)= \det(DA-CA^{-1}BA)=\det(DA-CB).$$
Осталось понять, что тождество верно для действительно достаточно большого числа матриц $A$ и $B$. Хотелось бы сказать, что мы доказали тождество в поле частных кольца $\mb Z[a_{ij},b_{ij},c_{ij},d_{ij}]$. Однако это не так, ведь мы использовали тот факт, что $AB=BA$, то есть работали в кольце $\mb Z[a_{ij},b_{ij},c_{ij},d_{ij}]/AB=BA$. Cовершенно не очевидно, что это кольцо есть область целостности (на самом деле нам нужно меньше --- только то, что элемент $\det A$ не делитель 0, тогда его можно формально обратить, но это тоже не очевидно). 

Поступим по другому --- введём дополнительный параметр $\lambda$ и рассмотрим при фиксированных $A,B,C,D\in M_n(K)$ семейство 
$$\left(\begin{matrix} 
A-\lambda E & B \\
C & D -\lambda E\\
\end{matrix}\right).$$
При любом $\lambda$ в верхней строке стоят коммутирующие матрицы. Тогда заметим, что оба определителя есть многочлены от $\lambda$, которые совпадают почти везде (везде кроме корней уравнения $\det(A-\lambda E)=0$). Этого может оказаться мало, если базовое поле $K$ - конечно. Вместо $K$ можно рассмотреть поле $K(\lambda)$, которое уже бесконечно (определитель --- многочлен ненулевой степени, следовательно обратим, как элемент $K(\lambda)$). Тогда имеет место равенство многочленов от $\lambda$. Осталось подставить $\lambda=0$. Для полей разобрались. 

\eprdl










\section{Строение модулей над ОГИ}

 Теперь докажем основную лемму.

\begin{lem}
Пусть $R$ --- область главных идеалов. Тогда для любой матрицы $A\in M_{n\times m} (R)$ существуют матрицы $B\in GL_n(R)$ и $C\in GL_m(R)$, что 

$$BAC=\begin{pmatrix}
\eps_1& & & & & \\
& \ddots& & & &\\
& &  \eps_l& & & \\
&  & & 0& & \\
&& & &\ddots & \\
& & & & & 0\\
\end{pmatrix}.$$

При этом можно добиться, чтобы $\eps_{i+1} \di \eps_i$.


\proof
Найдём такие матрицы $B$ и $C$, что у матрицы $BAC$ в левом верхнем углу будет стоять наибольший общий делитель всех элементов из первой строки и первого столбца. Рассмотрим первые два элемента $a=a_{11}$ $b=a_{21}$. Пусть $d=\Nod(a,b)$. Тогда существуют $x$ и $y$ из $R$, что $ax+by=d$. Тогда матрица 
$$ B= \begin{pmatrix}
x & y & & &  \\
-\frac{b}{d}  & \frac{a}{d}& & & \\
& &  1& &  \\
&  & & \ddots&  \\
&& & &1
\end{pmatrix} $$
 обратима и 

$$BA= \begin{pmatrix}
x & y & & &  \\
-\frac{b}{d}  & \frac{a}{d}& & & \\
& &  1& &  \\
&  & & \ddots&  \\
&& & &1
\end{pmatrix}\begin{pmatrix}
a& *&\dots & * \\
b& *&\dots & * \\
*& &  & *\\
\vdots &  & &   \vdots\\
*&*& \dots &   *\\
\end{pmatrix} =
\begin{pmatrix}
\Nod(a,b) & *&\dots & * \\
*& *&\dots & * \\
*& &  & *\\
\vdots &  & &   \vdots\\
*&*& \dots &   *\\
\end{pmatrix}. $$
Домножая на аналогичные матрицы справа и слева получим требуемое. Дальше --- вычтем все из всех строк первую строку, так чтобы коэффициент в столбце был равен нулю. Аналогично по столбцу. Далее --- индукция.
\endproof
\end{lem}

\begin{thmm}
Пусть $R$ --- кольцо главных идеалов. Тогда для любого гомоморфизма $f\colon R^m\to R^n$ существует базисы $v_1, \dots, v_n$ $u_1,\dots, u_m$, что матрица отображения в этом базисе имеет вид
$$\begin{pmatrix}
\eps_1& & & & & \\
& \ddots& & & &\\
& &  \eps_l& & & \\
&  & & 0& & \\
&& & &\ddots & \\
& & & & & 0\\
\end{pmatrix}.$$
В частности, так как любой подмодуль свободного модуля есть образ какого-то такого отображения, то подмодуль свободного модуля свободен.
\end{thmm}

\begin{thmm}
Пусть $R$ --- кольцо главных идеалов, а $M$ --- конечно порождённый модуль над $R$.  Тогда модуль $M$ имеет вид 
$$M=\bigoplus_{i=1}^r R/(\eps_i)\oplus R^{l}$$
для некоторых $r,l\in \mb N$ и $\eps_i\in R$, $\eps_i$ --- степень какого-то неприводимого элемента.
\end{thmm}

\begin{cor}
Если $R=K[t]$, то получаем теорию про жорданову (или фробениусову, см. предыдущие ДЗ) форму. Если $R=\mb Z$, то получается теорема о классификации конечно порождённых абелевых групп.
\end{cor}








\section{Конечно порождённые абелевы группы}

\begin{zad} Покажите, что любой вектор из $x\in \mb Z^n$, такой, что наибольший общий делитель его координат равен 1, может быть дополнен до базиса в $\mb Z^n$.
\end{zad}

\begin{zad} Пусть $L\colon \mb Z^n \to \mb Z^n$ --- гомоморфизм абелевых групп. Пусть $A\in M_n(\mb Z)$ --- матрица $L$ в стандартном базисе . Покажите, что 
$$|\det A|= |\mb Z^n/L(\mb Z^n)|.$$
(Покажите, что модуль определителя не меняется при замене базиса с каждой стороны).
\end{zad}





\section{Линейные операторы}


\section{Жорданова форма}

Теория, связанная с жордановой формой, основывается на предположении, что все корни характеристического
многочлена оператора лежат в базовом поле $K$. Поэтому при построении теории часто используется предположение,
что поле $K$ алгебраически замкнуто. Итого, все поля, если не оговорено противное, алгебраически замкнуты.

\dfn
Матрица $k\times k$
$$J_k(\lambda) = \begin{pmatrix}
\lambda& 1&& \\
& \lambda &1& \\
&&\ddots &\ddots& \\
&  && \lambda & 1\\
&  &&& \lambda
\end{pmatrix}
$$
называется жордановой клеткой размера $k$ с собственным числом $\lambda$.
\edfn

\thrm Пусть $A\colon V \to V$ --- оператор на конечномерном пространстве над алгебраически замкнутым полем $K$.
Тогда существует базис $e_1,\dots, e_n$ в котором матрица $A$ имеет вид
$$A=\begin{pmatrix}
J_{k_1}(\lambda_1) &&&\\
& J_{k_2}(\lambda_2) &&\\
&& \ddots& \\
&&& J_{k_s}(\lambda_s)

\end{pmatrix}.
$$

Собственные числа в клетках и их размеры могут повторяться. Число клеток данного размера с данным собственным
числом $\lambda$ определено оператором $A$ однозначно. Такая матрица называется матрицей оператора $A$ в форме Жордана.
Соответствующий базис называется жордановым базисом.
\ethrm


Как понять сколько клеток какого размера?

Прежде всего стоит найти характеристический многочлен  оператора $A$ 
$$\chi_A(t)=\det (A-tE)$$

Его корни и встречаются на диагонали в жордановой форме. Это собственные числа оператора $A$.


\begin{fact} Кратность собственного числа $\lambda$ (как корня характеристического многочлена) равна сумме размеров жордановых клеток с
собственным числом $\lambda$.
\end{fact}

Рассмотрим оператор $A-\lambda E$. Понятно, что сколько клеток с $\lambda$ было у $A$, столько же леток с с.ч. 0 будет у $A-\lambda E$ и они будут такого же размера.
Заметим, что жордановы клетки с собственным числом 0 являются нильпотентными матрицами.
Итак, пусть кратность собственного числа $\lambda$ равна $k$. Тогда оператор $A$ задаёт разбиение $k$ на ненулевые слагаемые,
соответствующие размерам жордановых клеток с собственным числом $\lambda$. Любое разбиение числа $k$ на слагаемые можно (единственным образом) представить в виде следующей картинки:


\begin{figure}[hhh]
\begin{center}
\begin{tikzpicture}[xscale=0.7, yscale=0.7]
\draw (1,0) -- (1,3) -- (0,3) -- (0,0) -- (4,0) -- (4,1) -- (0,1);
\draw (0,2) -- (3,2) -- (3,0);
\draw (2,0) -- (2,2);


\end{tikzpicture}
\end{center}
\caption{$8=3+2+2+1$, соответствует одной клетке размера 3, двум клеткам размера 2, одной клетке размера 1}
\end{figure}

Такие картинки (или перевёрнутые) называются диаграммами Юнга. Будем считать, что каждому столбику соответствует клетка. При таком соглашении верен 


\begin{fact} Количество ячеек в диаграмме Юнга для собственного числа $\lambda$ оператора $A$ на высоте не более $s$ равно $\dim \Ker(A - \lambda E)^s $.

Это  позволяет однозначно восстановить разбиение числа и, следовательно, конфигурацию клеток, если мы знаем числа $\dim \Ker(A - \lambda E)^s $.
\end{fact}





Допустим мы нашли характеристический многочлен, всё собственные числа. Теперь необходимо найти жорданов базис, а заодно и жорданову форму. Зафиксируем собственное число $\lambda$. Пусть размер самой большой клетки равен с собственным числом $\lambda$ равен $k$.

Будем заполнять столбики диаграммы Юнга базисными векторами в порядке их убывания сверху вниз. Прежде всего заметим, что если у нас уже известен вектор самой высокой ячейки столбика, то все векторы внизу это просто его образы относительно оператора $(A-\lambda E)^k$. 

\begin{figure}[hhh]
\begin{center}
\begin{tikzpicture}[xscale=0.7, yscale=0.7]
\draw (1,0) -- (1,3) -- (0,3) -- (0,0) -- (4,0) -- (4,1) -- (0,1);
\draw (0,2) -- (3,2) -- (3,0);
\draw (2,0) -- (2,2);
\draw[->] ( -0.5, 2.5) -- (-0.5, 0.5);
\node at (0.5, 2.5) {$v_3$};
\node at (0.5, 1.5) {$v_2$};
\node at (0.5, 0.5) {$v_1$};
\node at (1.5, 1.5) {$v_5$};
\node at (1.5, 0.5) {$v_4$};
\node at (2.5, 1.5) {$v_7$};
\node at (2.5, 0.5) {$v_6$};
\node at (3.5, 0.5) {$v_8$};
\node at (-1.7, 1.5) {$A-\lambda E$};
\end{tikzpicture}
\end{center}
\caption{$8=3+2+2+1$, расставляем базисные вектора}
\end{figure}

Как расставить векторы в верхней строке диаграммы? Векторы $v_{i_1}, \dots, v_{i_s}$  в верхней строке определяются тем, что их образы при $(A-\lambda E)^{k-1}$ линейно независимы (в частности, не лежат в ядре). Или, (что эквивалентно) система $v_{i_1}, \dots, v_{i_s}$ вместе с базисом(любым) $\Ker (A-\lambda E)^{k-1}$ образуют линейно независимую систему. Напомню, что их число равно $s=\dim \Ker (A-\lambda E)^k - \dim \Ker (A-\lambda E)^{k-1}$.



Что делать с теми клетками, чьи столбики в диаграмме Юнга начинаются не на самом верху? Пусть мы уже заполнили все строки на высоте больше $i+1$. Заполним остаток строки на высоте $i$.  Очевидно, что оставшиеся векторы лежат в ядре $(A-\lambda E)^{i}$ и при этом их образы при $(A-\lambda E)^{i-1}$ линейно независимы. Однако вектора из уже заполненных клеток на уровне $i$ тоже подходят под это описание. Можно однако заметить, что образы системы <<старые вектора на уровне $i$>>, <<новые вектора на уровне $i$>> при $(A-\lambda E)^{i-1}$ линейно независимы все вместе. Это даёт необходимые условия на оставшиеся вектора в строке $i$.  











\section{Функции от операторов и их приложения}


\begin{defn}
Пусть $K$ --- некоторое поле.  Минимальным многочленом оператора $A$ на векторном пространстве над полем $K$ называется многочлен $\mu(x)$, имеющий старший коэффициент 1 и порождающий идеал $$\lan \mu(x) \ran =\{ p(x)\in K[x] \, | \, p(A)=0\}.$$
Минимальный многочлен так же называют минимальным аннулятором.
\end{defn}


Если привести матрицу к жордановой форме, то станет видно, что:

\begin{fact}
Минимальный многочлен делит характеристический многочлен (теорема Гамильтона-Кэли). Корни характеристического многочлена являются корнями минимального. Кратность множителя $x-\lambda$ в минимальном многочлене равна наибольшему размеру клетки с собственным числом $\lambda$.
\end{fact}

Перейдём к понятию аналитической функции. 

\begin{defn}
Пусть $K$ - полное нормированное поле (для нас пока что это $\mb R$ или $\mb C$). Пусть $B\subseteq K$ - открытое подмножество в $K$. Функция $f\colon B \to K$ называется аналитической, если для любой точки $x_0\in B$ шарик $U$ с центром в точке $x_0$ и  набор $a_i$, что $f(x)=\sum_{i=0}^{\infty} a_i x^i$ на  $U$. Иными словами функция в окрестности каждой точки задаётся в виде суммы ряда.
\end{defn}

\begin{defn}
Пусть дан набор чисел $a_i\in K$. Радиусом сходимости ряда $\sum a_i x^i$ будем называть вещественное (какое бы ни было поле $K$) число $\rho \in \mb R$, такое, что $\frac{1}{\rho}=\varlimsup \sqrt[n]{|a_n|}$. Конечно, иногда $\rho$ бывает бесконечным.
\end{defn}

Следующие факты говорят про устройство и способы построения аналитических функций.
\begin{fact}
Пусть ряд $\sum a_i x^i$ имеет радиус сходимости $\rho$. Тогда для всех $x\in K$, таких что $|x|<\rho$ ряд $\sum a_i x^i$ сходится (даже абсолютно). А при всех $|x|>\rho$ ряд расходится.
\end{fact}

\begin{fact}
Пусть $K=\mb R ,\, \mb C$. Рассмотрим функцию  $f(x)=\sum a_i x^i$ заданную на открытом шарике радиуса $\rho$. Тогда функция $f$ диффиренцируема (в подходящем смысле над $\mb C$) и её производная равна $f'(x)=\sum i a_i x^{i-1}$ всюду на том же шаре.
\end{fact}

\begin{fact}
Более того для всякой точки $|x_0|<\rho$, если переписать выражение $\sum a_i x^i$ в виде $\sum b_i (x-x_0)^i$, где $b_i$ сами по себе какие-то ряды (с коэффициентами $a_i$ от $x_0$), то $b_i$ сходятся и ряд $\sum b_i y^i$ имеет радиус сходимости
$$\rho' \geq \rho - |x_0| \text{ \quad и \quad} \sum a_i x^i=\sum b_i (x-x_0)^i.$$ 
На самом деле эти $b_i$ просто значения $i$-ой производной $f$ с подходящим коэффициентом в точке $x_0$.
\end{fact}

\begin{fact}
В частности, функция $f(x)=\sum a_i x^i$ аналитична на открытом шарике радиуса $\rho$. 
\end{fact}


\begin{fact}
Произведение и сумма двух аналитических в одной и той же области функций --- снова аналитическая функция.
\end{fact}

\begin{fact}
Если $K=\mb C$, то условие аналитичности эквивалентно условию наличия комплексной производной. Поэтому, если вы видите, что производная какой-то функции имеет смысл для комплексных значений значит эта функция доопределяется до аналитической в этой точке. Например функция $\frac{1}{x-\lambda}$ является аналитической везде, кроме точки $\lambda$, где она не определена.
\end{fact}

Описанная конструкция позволяет доопределить функцию  $f(x)=\sum a_i x^i$ на открытое множество, большее, чем изначальная область с помощью <<переразложения>> этой функции. Однако есть точки в которых функция не может быть доопределена до аналитичной. Такие точки называют особыми (точное определение я не дам). Верно утверждение, что на окружности $|x|=\rho$, где $\rho$ - радиус сходимости ряда есть по крайней мере одна особая точка. Типичным примером особой точки являются:\\
а) точка $\lambda$ для функции $\frac{1}{x-\lambda}$;\\
б) точка $0$ для функции $\sqrt[\alpha]{x}$;\\
в) точка $0$ для функции $\ln(x)$;\\
г) точка $0$ для функции $e^{\frac{1}{x}}$.



Как видно из определения аналитическая функция задаётся как предел многочленов от одной переменной. Таким образом в любой алгебре $R$, где есть понятие сходимости можно попытаться определить значение аналитической функции на элементе $a\in R$, как предел многочленов от $a$. Нас будет интересовать случай $R=M_n(K)$.

\begin{defn}
Пусть $A\in M_n(K)$ некий элемент, а $f(x)=\sum a_i (x-x_0)^i$ аналитическая функция (в круге радиуса $\rho$ с центром в $x_0$). Положим   $$f(A)=\lim_{n\to \infty} \sum_{i=0}^n a_i (A-x_0E)^i$$
если этот предел определён. 
\end{defn}

Если мы научимся хорошо считать выражения вида $p(A)$, где $p$ --- многочлен, то посчитаем и значение аналитической функции.

\begin{fact}
Пусть $A=CBC^{-1}$. Тогда $p(A)=Cp(B)C^{-1}$.
\end{fact}

Это позволяет свести все вычисления к случаю, когда $A$ --- жорданова клетка (для алгебраически замкнутого поля). 

\begin{fact}
Пусть $A=J_k(\lambda)$, $p\in K[x]$. Тогда
$$p(A)=\begin{pmatrix*}[c]
p(\lambda)& p'(\lambda) &  & &\frac{1}{k!}p^{(k)}(\lambda)\\
 & p(\lambda) & p'(\lambda)& & \\
 &  &\ddots &\ddots  &  \\
 & & & p(\lambda) & p'(\lambda)\\
&  & && p(\lambda) \\
\end{pmatrix*}.$$
Это утверждение верно над любым полем.
\end{fact}

Ясно, что теперь мы умеем вычислять функцию от любой матрицы (оператора).

\begin{thmm}
Рассмотрим функцию заданную рядом $\sum a_i x^i$  с радиусом сходимости $\rho$. Пусть собственные числа $\lambda_i$ оператора $A$ по модулю $|\lambda_i|<\rho$. Тогда ряд $\sum a_i A^i$ сходится.
\proof Отображение $A\to C A C^{-1}$ непрерывно по $A$ для фиксированного $C$ (можно в это поверить, а при наличии определений и проверить). Выберем в качестве $C^{-1}$ матрицу перехода в жорданов базис матрицы $A$. Тогда ясно, что  ряд $\sum a_i A^i$ сходится тогда и только тогда, когда он сходится для жордановой формы $A$. Для жордановой формы он сходится т.к. он сходится покоэффициентно (исходя из явной формулы). 
\end{thmm}

\begin{rem}
Можно построить теорию для вычисления не только аналитических, но и непрерывных (и некоторых разрывных) функций на вещественной прямой от операторов. Но там нет красивого явного ответа, так как непрерывные функции не так просто приблизить многочленами.
\end{rem}











\chapter{Полилинейная алгебра}

\section{Билинейные и квадратичные формы}

Последние занятия были посвящены в основном понятию билинейной формы, связанной с этим понятие квадратичной формы и частному случаю билинейной формы -- скалярному произведению.

Всюду далее -- $K$ -- поле характеристики, отличной от 2.

\dfn Пусть $V$ -- векторное пространство над $K$. Отображение $h\colon V\times V \to K$ называется билинейной формой, если\\
1) $\forall \lambda \in K$ $\forall u,v,w \in V$ верно, что $h(u+\lambda v, w) = h(u,w)+\lambda h(v,w)$,\\
2) и по второй координате: $h( w, u+\lambda v) = h(w,u)+\lambda h(w,v)$.
\edfn

\dfn Квадратичная форма -- это отображение $q\colon V \to K$, что в некоторой линейной сиcтеме координат это отображение есть однородный многочлен степени 2.
\edfn

\fct Пусть $h$ -- билинейная форма на $V$. Тогда $q(v)=h(v,v)$ -- это квадратичная форма.
\efct

\dfn Билинейная форма называется симметричной, если $h(u,v)=h(v,u)$.
\edfn

\fct
Пусть $q$ -- квадратичная форма. Тогда форма $h(u,v)=\frac{q(u+v)-q(u)-q(v)}{2}$ -- симметричная билинейная. Эта конструкция обратна к конструкции из предыдущего факта, если форма $h$ -- симметрическая. Таким образом имеется взаимно однозначное соответствие между симметрическими и билинейными формами.
\efct 

\dfn Пусть $e_1, \dots, e_n$ базис $V$, а $h$ -- билинейная форма на $V$. Тогда матрица $A$ составленная из элементов $h(e_i,e_j)$ называется матрицей билинейной формы.
Если вектор $v$ имеет столбец координат $x$, а вектор $u$ -- $y$, то значение $h(u,v)$ можно найти по формуле $y^{\top}Ax$.
\edfn


\dfn Пусть $q$ -- квадратичная форма на $V$, $e_1,\dots, e_n$ -- базис $V$. Рассмотрим соответствующую симметриную билинейную форму $h$. Тогда матрица формы $h$ называется матрицей квадратичной формы $q$ в базисе $e$. Значение формы $q$ воосстанавливается по следующей формуле $q(x)=x^{\top}Ax$.  
\edfn

\dfn Билинейная форма $h$ называется невырожденной, если для любого $v\in V$ не равного 0 существует $u\in V$, что $h(u,v)\neq 0$. Квадратичная форма невырождена, если соответствующая ей симметричная билинейная форма невырождена.
\edfn

\dfn Ранг билинейной формы -- это ранг её матрицы.
\edfn

\fct Форма $h$ невырождена тогда и только тогда, когда матрица $h$ невырождена. Форма $h$ симметрична тогда и только тогда, когда её матрица симметрична, то есть $A^{\top}=A$.
\efct


Вопрос: как меняется матрица билинейной (и квадратичной формы) при переходе от одного базиса к другому?

\fct Пусть при замене базиса  координаты вектора $v$ в старом базисе $x$ связаны с координатами в новом базисе $y$  соотношением $x=Cy$. Тогда  матрица квадратичной формы в новом базисе будет иметь вид 
$$A_{new}=C^{T}AC.$$
\efct




\section{Метод Лапласа, критерий Сильвестра}

Вопрос: можно ли выбрать координаты так, чтобы упростить вид матрицы квадратичной формы? Можно. Нам удобнее всего будет представлять форму $q$ в виде однородного многочлена второй степени. После чего наш метод можно будет условно назвать выделением полного квадрата.

Пусть форма $q(x)$ в координатах имеет вид
$$q(x)= a_{11}x_1^2+ 2a_{12}x_1x_2 + \dots 2a_{1n}x_1x_n  + q'(x_2, \dots, x_n).$$

\noindent{\bf Первый случай} Предположим, что $a_{11}\neq 0$. Тогда представим $q(x)$ в виде, выделив полный квадрат 
$$q(x)= a_{11}\left(x_1+\frac{a_{12}}{a_{11}}x_2 + \dots +\frac{a_{1n}}{a_{11}}x_n\right)^2 - \frac{a_{12}^2}{a_{11}}x_2^2 - 2\frac{a_{12}a_{13}}{a_{11}}x_2x_3 - \cdots - \frac{a_{1n}^2}{a_{11}}x_n^2 + q'(x_2,\dots,x_n).$$

Новые переменные выглядят следующим образом:
\begin{align*}
y_1&=x_1+\frac{a_{12}}{a_{11}}x_2 + \dots +\frac{a_{1n}}{a_{11}}x_n,\\
 y_2&=x_2, \\
&\vdots\\
 y_n&=x_n.
\end{align*}

Видно, что кроме формы $q'$ возникает ещё поправка, которая содержит слагаемые $\lambda x_ix_j$ $i,j\geq 2$.\\




\noindent{\bf Второй случай.} $a_{11}=0$. Если $a_{ii}\neq 0$, то меняем первую и $i$-ую координаты местами  и продолжаем как раньше. \\


\noindent{\bf Третий случай.} Все $a_{ii}=0$.
Пусть $a_{12}\neq 0$. Тогда сделаем замену $x_1=y_1+y_2$, $x_2=y_1-y_2$, $y_i=x_i$, $i\geq 3$. Получим $2a_{12}$ при $y_1^2$ и $-2a_{12}$ при $y_2^2$. Теперь находимся в ситуации первого случая.\\


\noindent{\bf Четвёртый случай.} Все $a_{ii}=0$. Все $a_{1i}=0$. Тогда форма не зависит от первой переменной и можно смело переходить к следующей переменной.\\ 



Сформулируем теперь факт.

\fct Пусть $K$ -- поле, $V$ -- векторное пространство над $K$, $q$ -- квадратичная форма на $V$. Тогда существует базис $V$ в котором матрица формы $q$ диагональна, или, что тоже самое, в указанных координатах форма $q$ есть сумма квадратов. 
\efct


Рассмотрим теперь случай конкретного поля -- поля $\mb R$. К какому виду можно привести форму над $\mb R$? 

\fct Пусть $q$ -- форма над $\mb R$. Тогда существует базис в котором форма имеет вид $$q(x)= x_1^2+\dots + x_l^2 - x_{l+1}^2-\dots-x_{l+k}^2 $$.
\efct

\dfn Сигнатурой формы над $\mb R$ называется разность $l-k$ -- числа плюсов и числа минусов.
\edfn

\fct Сигнатура формы не зависит от способа приведения формы к диагональному виду. 
\efct

\fct Пусть $q$ -- форма на $V$. $\dim V =n $. Тогда вид $q$ однозначно определяется её рангом и сигнатурой. 
\efct

Можно ли как-то ещё найти сигнатуру не приводя форму, а воспользовавшись другими знаниями? Ответ: да, можно. А именно

\thrm[Критерий Сильвестра]
Пусть $V$ -- векторное пространство над $\mb R$, $q$ -- форма, $A$ -- её матрица в некотором базисе. Пусть числа $d_i=\det A_i$ все не равны $0$, где $A_i$ -- подматрица $A$ составленная из элементов первых $i$ строк и столбцов. Тогда матрица $A$ -- невырожденная и число перемен знака в последовательности $d_i$ равно числу отрицательных квадратов в диагональном виде.
\ethrm

\dfn Квадратичная форма называется положительно определённой, если $\forall v\neq 0 q(v)>0$. Симметричная билинейная форма называется положительно определённой, если соответствующая форма $q(v)=h(v,v)$ положительно определена. Симметричная матрица называется положительно определённой, если соответсвующая форма положительно определена.
\edfn

\fct Положительно определённая форма всегда невырождена.
\efct










\section{Евклидовы и унитарные пространства}


\dfn Векторное пространство $V$ над $\mb R$ вместе с заданным на нём билинейной симметричной формой $\lan\cdot \, , \cdot \ran$ называется евклидовым пространством. Форма $\lan\cdot \, , \cdot \ran$ называется скалярным произведением. 
\edfn

\dfn Определим  норму на евклидовом пространстве как $\|v\|=\sqrt{\lan v , v\ran }$. Норма задаёт расстояние по правилу $\rho(u,v)=\|u-v\|$. Будем говорить, что два вектора ортогональны, если $\lan u,v \ran =0$.
\edfn

\dfn Пусть $U$ -- подпространство $V$, а $h$ -- билинейная форма на $V$, тогда ортогональным дополнением к $U$ называется подпространство 
$$U^{\bot}=\{ v\in V\,|\, \forall u \in U \text{ выполнено, что } \lan u, v \ran =0\}$$
\edfn
 
\fct Пусть $V$ -- евклидово пространство. Тогда для всякого подпространства $U$ выполнено $V=U\oplus U^{\bot}$. Если есть такое разложение, то оператор проекции на $U$ называется ортогональной проекцией.
\efct




\section{Ортогонализация Грамма-Шмидта}



Как найти проекцию вектора на подпространство? В этом нам поможет ортогонализация Грамма-Шмидта. Пусть дан набор векторов $e_1,\dots, e_n$. Задача состоит в том, чтобы найти набор векторов $f_1,\dots,f_n$ такой, что\\
1) $f_i \bot f_j$, если $i\neq j$\\
2) $\lan e_1,\dots,e_k\ran=\lan f_1,\dots,f_k\ran$\\
3) Так же можно потребовать, чтобы $\|f_i\|=1$.

\dfn Набор векторов со свойством 1) называется ортогональным, со свойствами 1),3) -- ортонормированным. Если этот набор базис, то он называется ортогональным или ортонормированным соответственно.
\edfn 

\rm Заметим, что если мы нашли набор векторов со свойствами 1) и 2), то несложно сделать из него нормированный набор, взяв вектора $\frac{f_i}{\|f_i\|}$. 
\erm

Перейдём к решению задачи добиваясь только условий 1) и 2). Будем последовательно искать вектора $f_i$ в виде $f_i=e_i+\lambda_1 f_1 +\dots + \lambda_{i-1} f_{i-1}$. Этот подход приводит к ответу
$$f_i=e_i-\sum_{j<i} \frac{\lan f_j,e_i\ran}{\lan f_j,f_j\ran}f_j.$$

Попутно отметим следующий факт

\fct Пусть набор $e_i$ --- ортогональный базис $V$. Тогда для любого $x\in V$ 
$$\|x\|^2= \sum \frac{\lan x, e_i\ran^2}{\lan e_i, e_i\ran},$$
причём $\frac{\lan x, e_i\ran}{\lan e_i, e_i\ran}$ --- это $i$-ая координата вектора $x$ в базисе $e_i$. В случае нормированного базиса формула упрощается -- исчезает знаменатель.
\efct

Перейдем к применениям процесса ортогонализации:
\fct В любом евклидовом пространстве существует ортонормированный базис.
\efct

\lm Пусть $ e_1,\dots, e_k$ --- ортогональный базис $U$ -- подпространства $V$. Тогда для проекции $x$ на $U$ имеет место формула:
$$ pr_U(x)= \sum \frac{\lan x,e_i\ran}{\lan e_i,e_i\ran} e_i.$$
Заметим так же, что
$$pr_U^{\bot}(x)=x-pr_U(x).$$
\elm


\dfn Пусть $V$ -- векторное пространство над $K$. Тогда аффинным подпространством $V$ называется подмножество вида $x_0+L$, где $L$ -- линейное подпространство в $V$.
\edfn

Задача --- научиться считать расстояние между аффинными подпространствами $A_1$ и $A_2$ в евклидовом пространстве. Попробуем это сделать. Представим $A_1=L_1+x$ и $A_2=L_2+y$. 

Прежде всего отметим:
\fct Пусть $U \leq V$ подпространство, $x_0 \in V$. Тогда расстояние $\rho(x_0,U)$ достигается на проекции  $pr_U(x)$ и равно $\|x-pr_U(x)\|=\|pr_{U^{\bot}}(x)\|$.
\efct

\rm Если размерность $U^{\bot}$ мала, то может быть легче найти проекцию на $U^{\bot}$, найдя базис $U^{\bot}$.
\erm

Всё это немедленно приводит к решению общей задачи.
\fct Пусть  $A_1=L_1+x$ и $A_2=L_2+y$ -- аффинные подпространства. Тогда $\rho(A_1,A_2)=\rho(x-y, L_1+L_2)$. То есть задача сводится к ранее разобранной.
\efct



\fct В евклидовом пространстве выполнено неравенство
$$ \lan u,v\ran \leq \|u\|\|v\|.$$
\efct
Называется неравенство Коши-Буняковского. Это неравенство даёт возможность ввести понятие угла между подпространствами.

\dfn $V$ --- евклидово пространство $U$ -- его подпространство, а $x_0$ вектор из $V$. Определим косинус угла $\angle x_0,U$ как 
$$\cos \angle x_0,U= \sup_{0\neq y\in U} \frac{\lan x_0,y\ran }{\|x_0\|\|y\|}.$$  
То есть мы ищем минимальный угол из отрезка $[0,\pi]$.
\edfn

\fct Наименьший угол достигается между $x_0$ и его проекцией на $U$ и его косинус равен $\frac{\|pr_{U}x_0\|}{\|x_0\|}$.  
\efct










\section{Ортогональные и унитарные отображения}

Прежде, чем мы к этому приступим, напомню, что основным отличием евклидового пространства от просто векторного пространства является понятие расстояние и поэтому некоторое время мы посвятим преобразованиям это расстояние сохраняющим -- ортогональным преобразованиям.

\dfn Пусть $V$ --- евклидово пространство. Ортогональным оператором на $V$ называется такой линейный оператор $L \colon V \to V$, что $||Lx||=
||x||$.
\edfn

\rm В определении мы видим равенство двух квадратичных форм $\|Lx\|^2=\|x\|^2$, значит равны соответствующие симметрические билинейные формы $\lan Lx,Ly\ran = \lan x,y\ran$.  Расписав это равенство в ортонормированном базисе получаем для соотношение для матрицы $B$ ортогонального оператора   $B^{\top} B=E$.
\erm

\lm Пусть $e_1,\dots,e_n$ --- ортонормированный базис $V$. Линейный оператор $L$, который в базисе $e_i$ имеет матрицу, составленную из столбцов $v_1,\dots,v_n$, является ортогональным тогда и только тогда, когда $v_1,\dots,v_n$ --- ортонормированный базис $K^n$. 
\proof
Пусть $B$ -- матрица $L$, составлена из столбцов $v_i$. Тогда соотношение $B^{\top}B=E$ эквивалентно ортогональности и нормированности $v_i$.
\endproof
\elm



\dfn Пусть $A$ --- оператор на евклидовом пространстве $V$. Сопряжённым оператором к $A$ называется единственный такой оператор $A^*\colon V \to V$, что $\lan A^*x,y\ran=\lan x,Ay\ran$ для всех $x,y \in V$.
\edfn

\rm
В ортонормированном базисе его матрица сопряжённого оператора --- это $A^{\top}$. 
\erm

\rm Условие ортогональности оператора можно переписать в виде $L^*L=1$ или $L^*=L^{-1}$.
\erm






\section{Комплексификация}

\section{Сопряжённые операторы}

Теория самосопряжённых операторов развивается параллельно в евклидовых и унитарных пространствах. Я буду формулировать все факты так, чтобы они были верны и в том и в другом контексте.

\dfn Пусть $A$ --- оператор на евклидовом пространстве $V$. Сопряжённым оператором к $A$ называется единственный такой оператор $A^*\colon V \to V$, что $\lan A^*x,y\ran=\lan x,Ay\ran$ для всех $x,y \in V$.
\edfn


\fct[Общие свойства]
$(A+B)^*=A^*+B^*$\\
$(AB)^*=A^*B^*$\\
$(\lambda A)^*=\ovl{\lambda}A^*$.\\
$(A^{-1})^*=(A^*)^{-1}$.\\
${A^*}^*=A$.
\efct

\dfn Пусть $A$ оператор на евклидовом или унитарном пространстве $V$ называется самосопряжённым, если $A^*=A$.
\edfn

\fct Пусть $e_1,\dots e_n$ ортонормированный базис, тогда оператор $A$ cамосопряжён тогда и только тогда, когда его матрица в этом базисе удовлетворяет условию $\ovl{A}^{\top}=A$.
\efct

\thrm Пусть $A$ -- оператор в евклидовом (унитарном) пространстве $V$. Тогда $A$ -- самосопряжённый тогда и только тогда, когда существует ортонормированный базис $V$ состоящий из собственных векторов оператора $A$ и все собственные числа $A$ -- вещественны.
\ethrm







\section{Спектральные теоремы}

Итак, мы попробовали решить в прошлый раз мы дали определение нормального оператора.
А именно, 
\dfn Пусть $A$ оператор на евклидовом или унитарном пространстве $V$. Оператор $A$ называется нормальным, если $AA^*=A^*A$.
\edfn

\dfn Пусть $A$ оператор на евклидовом или унитарном пространстве $V$ называется кососимметрическим (косоэрмитовым), если $A^*=-A$.
\edfn

Мы остановились на том, что хотим показать, что инвариантные пространства относительно $A$ инварианты относительно $A^*$. Какой бы ни был оператор верен

\fct Если подпространство $U$ инвариантно относительно $A$, то $U^{\bot}$ инвариантно относительно $A^{*}$.
\efct

Таким образом поступать прямо как для самосопряжённых операторов нельзя. Но можно заметить следующее: у $A$ и $A^*$ есть собственный вектор, так как они коммутируют.

Возьмём к нему ортогональное дополнение. Это будет инвариантное подпространство. Поступая так далее получаем ортонормированный базис из собственных векторов $A$. Итого мы показали
\thrm Пусть $A$ -- нормальный оператор в унитарном пространстве $V$. Тогда существует ортонормированный базис $V$ состоящий из собственных векторов оператора $A$. Очевидно, что в этом базисе матрица $A$ будет иметь вид 
$$ \begin{pmatrix}
\lambda_1 &&\\
&\ddots&\\
&&\lambda_n
 \end{pmatrix}, \text{ а матрица $A^*$ --- }  \begin{pmatrix}
\ovl{\lambda_1} &&\\
&\ddots&\\
&&\ovl{\lambda_n}
 \end{pmatrix}, $$
где $\lambda_i$ --- собственные числа $A$.
\ethrm

\crl Существует многочлен $p\in \mb C[x]$, что $A^*=p(A)$.
\ecrl

\crl У $A$ и $A^*$ все инвариантные подпространства общие.
\ecrl

Теперь можно получить характеризацию унитарных, вещественных ортогональных, и кососимметрических операторов.

\thrm Оператор $A$ -- унитарный тогда и только тогда, когда его собственные числа по модулю равны 1 и существует ортонормированный базис из собственных векторов. 
\ethrm

\thrm Оператор $A$ на унитарном пространстве $V$ кососимметрический  тогда и только тогда, когда его собственные числа чисто мнимые ( или 0 ) и существует ортонормированный базис из собственных векторов. 
\ethrm

\thrm Оператор $A$ на евклидовом пространстве $V$ ортогональный  тогда и только тогда, существует ортонормированный базис в котором матрица $A$ блочно-диагональная, при этом блоки имеют размер $1$ или $2$ и блоки размера $1$ состоят из $\pm 1$, а блоки размера 2 имеют вид
$$\begin{pmatrix}
\cos \varphi & -\sin \varphi\\

\sin \varphi &\cos \varphi
\end{pmatrix}$$

\ethrm





\section{Задачи на максимизацию}

\section*{Приведение гиперповерхности второго порядка к каноническому виду.}

Рассмотрим одну геометрическую задачу. В геометрии фигуры равны, если существует изометрия пространства, переводящая одну в другую. Или, что эквивалентно, если в некоторой новой декартовой системе координат уравнение одной фигуры преобразуется в уравнение для другой фигуры. 

Эквивалентность этих подходов опирается, в частности, на теорему:
\thrm Пусть $V$ евклидово пространство и отображение $U\colon V\to V$, не обязательно линейное, является изометрией. Тогда существует единственный вектор $v$ и ортогональный оператор $L$, что $U$ имеет вид $Ux=Lx+v$. 
\ethrm

Рассмотрим гиперповерхность в $\mb R^n$, заданную уравнением  
$$x^{\top} Ax+B^{\top}x +C=0.$$
Вопрос состоит в том, как бы найти координаты, чтобы вид уравнения был попроще. Однако хочется, чтобы и расстояние при таком преобразовании не менялось.

Заметим, прежде всего, что нам годятся в сущности только два типа преобразования -- параллельный перенос и ортогональная замена. Рассмотрим сначала, как ортогональное преобразование координат $D$ влияет на это уравнение. Подставим $x=Dy$ и получим 
$$ x^{\top} Ax+B^{\top}x +C=0= y^{\top} D^{\top}ADy +B^{\top}Dy +C=0.$$
То есть квадратичная часть, как и ожидалось меняется, как соответствующая квадратичная форма, линейная часть особенно не упрощается, с константой ничего не происходит. Из спектральной теоремы мы знаем, что есть ортонормированный базис из собственных векторов $v_1,\dots, v_n $ для матрицы $A$. Возьмём систему координат связанную с этим набором векторов. Столбцы матрицы  $D$, что $x=Dy$  -- это в точности  вектора $v_1,\dots,v_n$. В новом базисе матрица $A$ имеет диагональный вид, с $a_{ii}=\lambda_i$. Наше квадратичное уравнение приняло вид 
$$\lambda_1y_1^2+\dots+ \lambda_n y_n^2 + b'_1y_1+\dots +b'_ny_n +C =0.$$

Теперь попробуем сделать сдвиг, так, чтобы линейное слагаемое умерло. Если какое-то $\lambda_k$ оказалось равно 0, то от линейного слагаемого его содержащего нельзя избавится. А вот от остальных можно. Действительно, если $\lambda_k\neq 0$, то сделаем замену  $z_k=y_k-\frac{b_k}{2\lambda_k}$. При этом константа $C$ поменятется на $-\frac{b^2_k}{4\lambda_k}$ Пусть  $I_1$ -- это множество индексов переменных, что $\lambda_k \neq 0$, а $I_2$ наоборот. Тогда уравнение гиперповерхности примет вид 
$$\sum_{k\in I_1} \lambda_kz_k^2+ \sum_{k\in I_2}\lambda_k z_k + C'=0.$$


Построение системы координат, в которой матрица уравнение гиперповерхности имеет такой вид называется приведением уравнения поверхности к каноническому виду. Если речь идёт только о квадратичной форме, то говорят, что её приводят к главным осям.


\section*{Поиск угла между подпространствами}
Попробуем решить несколько другую задачу -- найти угол между подпространствами. 

\dfn
Пусть $U$ и $W$ два подпространства  евклидового пространства. Определим косинус угла между ними как 
$$\cos \angle U,W= \sup_{\substack{ x\in U\\ y\in V}} \frac{\lan x,y\ran}{||x|| ||y||}.$$
\edfn

\rm Если два подпространства пересекаются, то угол между ними по этому определению равен 0. Если хочется, чтобы угол не был равен 0 для неравных пространств, то разумно посмотреть ортогональные дополнения $U$ и $W$ к пересечению $U\cap W$ и посчитать угол между ортогональными дополнениями. 
\erm

\rm Можно переписать выражение для косинуса как $$\cos \angle U,W= \sup_{ x\in U} \cos \angle x, V = \sup_{x\in U} \frac{||pr_V x||}{||x||}= \sqrt{ \sup_{\substack{x\in U\\ ||x||=1}} ||pr_V x||^2} .$$
\erm

С последним выражением легко работать, потому что $||pr_V x||^2$ -- это квадратичная форма на $U$.

Допустим мы хотим максимизировать указанное выражение. Выберем на $U$ ортонормированный базис. Посчитаем матрицу формы $||pr_V x||^2$ по формуле 
$$a_{ij}= \lan pr_V u_i, pr_V u_j\ran.$$

Тогда максимум выражения под корнем равен $\lambda_{max}$ -- максимальному собственному числу $A$ и достигается на соответствующем векторе $v_{max}$. Ответ: $\sqrt{\lambda_{max}}$





\section*{Метод главных компонент}

Рассмотрим следующую задачу: имеется массив данных --- набор векторов $x_1,\dots,x_s \in V$, где $V$ -- это евклидово пространство размерности $n$. Подразумевается, что точек очень много. Предположим, что при идеальных измерениях между координатами этих векторов есть линейные зависимости. Все отклонения от этой погрешности вызваны небольшими погрешностями. Задача состоит в том, чтобы восстановить линейную зависимость. 


Переформулируем задачу геометрически. Пусть наши вектора удовлетворяют линейным условиям $Ax_i=b$ для некоторой матрицы $A$ ранга $n-k$. Это значит, что они лежат в аффинном подпространстве $\Ker A + a_0$ размерности $k$. Если же нам даны вектора с погрешностями, то задачу таким образом можно поставить в виде: найти аффинное подпространство размерности $k$ наиболее близкое к данным точкам $x_1,\dots,x_s$. Понятие <<Наиболее близкое>> требует конкретизации. Вообще говоря, тут есть выбор. Мы будем считать, что подходящее пространство $W=L+a_0$ должно давать минимум следующего выражения:
$$\sqrt{\sum_{i=1}^s \rho(x_i,W)^2} \to \min.$$
Совершенно ясно, что корень квадратный тут для красоты, и минимизировать нужно $\sum_{i=1}^s \rho(x_i,W)^2$.

Прежде всего установим, что какой бы <<минимайзер>> $W=L+a_0$ мы не нашли, в $W$ всегда будет лежать среднее $\frac{1}{s}\sum_{i=1}^s x_i$ и, следовательно, в качестве $a_0$ всегда можно взять среднее.

Действительно, выпишем условие $\sum_{i=1}^s \rho(x_i-a_0, L)^2=\sum ||pr_{L^{\bot}} (x_i-a_0)||^2$  минимально.  Продифференцируем по координатам $a_0$. Получим $$\sum -2pr_{L^{\bot}} x_i + 2 pr_{L^{\bot}} a_0=0$$
 Это условие означает, что проекции $a_0$ и среднего $\frac{1}{s}\sum x_i$ на подпространство $L$ совпадают. То есть эти две величины отличаются на элемент $L$. Тогда среднее лежит в $W$. 

Итак, вычтя из всех $x_i$ их среднее можно считать $a_0=0$, а все точки $x_i$ удовлетовряют равенству $\sum_{i=1}^s x_i=0$. Замечу, что это равенство нигде в дальнейшем не будет использовано. Благодаря такой замене мы свели задачу к поиску подпространства $L$ размерности $k$, которое минимизирует 
$$\sum_{i=1}^s \rho(x_i, L)^2=\sum_{i=1}^s ||pr_{L^{\bot}} (x_i)||^2.$$

Воспользуемся тем, что $||x||^2=||pr_L x||^2+||pr_{L^{\bot}} x||^2$ или $||x||^2-||pr_L x||^2=||pr_{L^{\bot}} x||^2$. Тогда получаем, что
$$\sum_{i=1}^s ||pr_{L^{\bot}}(x_i)||^2=\sum_{i=1}^s ||x_i||^2-||pr_L x_i||^2$$
должно быть минимально. Тогда сумма $\sum_i ||pr_L x_i||^2$ должна быть максимальна.


Для того чтобы посчитать проекцию выберем в $L$ ортонормированный базис $u_1,\dots,u_k$. Тогда перепишем
$$\sum_{i=1}^s ||pr_L x_i||^2=\sum_{i=1}^s\sum_{j=1}^k \lan x_i,u_j\ran^2=\sum_{j=1}^k \sum_{i=1}^s \lan x_i,u_j\ran^2.$$

Внутренняя сумма теперь есть значение некоторой квадратичной формы на векторе $u_j$. Разберёмся какой. Рассмотрим матрицу $X$ размера $s\times n$, чьи строки это  вектора $x_i$ $i\in\ovl{1,s}$. Тогда вектор $d=Xu_j$ состоит из скалярных произведений  $\lan v_i, u_j\ran$. Тогда выражение $\lan d,d\ran = (u_jX^{\top})Xu_j = \sum_{i=1}^s \lan x_i,u_j\ran^2$, то есть как раз тому, что участвует в нашей сумме. Рассмотрим симметричную матрицу $A=X^{\top}X$ и обозначим соответствующую ей форму за $q$. Тогда нам надо минимизировать выражение
$$\sum_{j=1}^k q(u_j).$$

Введём определение:
\dfn
Пусть $q$ -- квадратичная форма на евклидовом пространстве. Рассмотрим ортонормированный базиc $u_i$ пространства $V$. Тогда положим 
$$\Tr q= \sum q(u_i).$$ Если в базисе $u_i$ форме $q(x)=x^{\top} Ax $ соответствует симметричная матрица $A$, то $\Tr q(x)=\Tr(A)$.
\edfn

\rm Определение не зависит от выбора ортонормированного базиса. Действительно, если замена координат ортогональна, то матрица $q$ в новой системе координат имеет вид $C^{\top}AC=C^{-1}AC$. Осталось заметить, что след последней матрицы очевидно равен следу $A$.
\erm

\rm Если форме $q$ соответствует самосопряжённый оператор $A$, то $\Tr q=\sum \lambda_i$, где $\lambda_i$ -- собственные числа $A$.
\erm

Таким образом мы ищем максимум $\Tr q_{L}$ по всем подпространствам $L$ размерности $k$, где форма $q$ соответствует матрице $X^{\top} X$. 
Сформулируем теперь ответ. 


\thrm  Пусть есть набор векторов $x_1,\dots,x_s \in V$. Определим симметричную, положительно определённую матрицу $A$, как $A=X^{\top}X$, где строчки матрицы $X$ -- это вектора $x_i$. Тогда минимум по всем аффинным подпространствам $V$ размерности $k$ выражения $\sum_{i=1}^s \rho(x_i,W)^2$ достигается при $a_0=\frac{1}{s}\sum x_i$  и $L=\lan v_1,\dots,v_k\ran$, где $v_i$ --- собственные вектора $A$, причём соответствующие собственные числа упорядочены по убыванию. 
\ethrm




\section*{Доказательство корректности метода главных компонент}

Прежде всего напомним основополагающий факт 

\thrm Пусть $V$ -- евклидово пространство, $A$ -- самосопряжённый оператор на $V$, а $q(x)=\lan x,Ax\ran$ -- соответствующая квадратичная форма. Тогда 
$$\max_{ x\in V } \frac{q(x)}{||x||^2}=\max_{\substack{ x\in V \\ ||x||=1}} q(x)=\lambda_1,$$
 где $\lambda_1$ - наибольшее собственное число оператора $A$ и достигается на собственном векторе $v_1$, соответствующему $\lambda_1$. Аналогично минимум равен минимальному собственному числу $A$. 
\ethrm


\thrm[Куранта-Фишера] Пусть $q(x)=\lan x, Ax\ran$. Тогда $k$-ое по убыванию собственное число $\lambda_k$ для $A$ есть 
$$ \lambda_k=\max_{\dim L=k} \min_{\substack{ x\in L \\ ||x||=1}} q(x) = \min_{\dim L=n-k+1} \max_{\substack{ x\in L \\ ||x||=1}} q(x).$$
Причем максимум достигается на инвариантном подпространстве, содержащем собственные вектора для $\lambda_1,\dots,\lambda_k$.
\ethrm
\proof Пусть $U$ --- подпространство на котором достигается максимум, причём допустим, что максимум больше $\lambda_k$. Тогда рассмотрим подпространство $W=\lan v_k,\dots,v_n\ran$, где $v_i$ --- собственный вектор соответствующий $i$-ому по убыванию собственному числу. Заметим, что $U\cap W=\{0\}$, так как на $W$ форма принимает значения меньше или равные $\lambda_k$, а на $U$ -- строго большие. Однако $\dim W=n-k+1$. Приходим к противоречию с подсчётом размерности пересечения. 
\endproof

\crl Пусть $U$ некоторое подпространство, а $q(x)=x^{\top} Ax$. Пусть собственные числа $A$ --- это $\lambda_i$, а собственные числа оператора, соответствующего $q(x)|_U$ -- это $\mu_i$ упорядоченные по убыванию. Тогда 
$$\lambda_{i+n-m}\leq \mu_i\leq \lambda_i.$$  
\proof Заметим, что
 $$\mu_i=\max_{\substack{L\leq U\\ \dim L=i}} \min_{\substack{ x\in L \\ ||x||=1}} q(x),$$
что очевидно меньше, чем 
$$\max_{\dim L=i} \max_{\substack{L\leq V\\ \dim L=i}} q(x)=\lambda_i.$$ Неравенство в другую сторону получается из второго описания в теореме Куранта-Фишера.
\endproof
\ecrl




\crl Пусть $q(x)=x^{\top} Ax$, $U$ --- некоторое подпространство, $\dim U=k$. Пусть собственные числа $A$ --- это $\lambda_i$. Тогда $$\Tr q|_U\leq \sum_{i=1}^k \lambda_i= \Tr q|_{V_k},$$
где $V_k$ подпространство натянутое на первые $k$ собственных векторов $q$.
\proof Нам известны неравенства на собственные числа $\mu_i$, ограничения $q|_U$. А именно $\mu_i\leq \lambda_i$. Но тогда и $$\sum_{i=1}^k \mu_i \leq \sum_{i=1}^k \lambda_i.$$
\endproof
\ecrl

\rm Последнее следствие и даёт обоснование для метода главных компонент.
\erm 








\section{Самосопряжённые операторы в теории графов}

Для каждого графа $G$ мы определили его матрицу смежности $A(G)$, матрицу инцидентности $B(G)$ (в том числе и когда задана ориентация), матрицу оператора Лапласа $L(G)$, матрицу случайного блуждания $P(G)$. Основным инструментом для нас была матрица смежности, конкретнее -- её собственные значения. Однако часто нам помогала матрица инцидентности.

В самом начале мы получили следующий результат. 

\fct Размерность ядра матрицы инцидентности с одной стороны равна $m-n+c$, где $m$ -- количество рёбер, $n$ -- количество вершин, $c$ -- число компонент связности. С другой стороны -- это размерность пространтсва циклов.
\efct

\crl Граф $G$ содержит $2^{m-n+c}$ эйлеровых подграфов, то есть таких графов, что степень любой вершины чётна (графов, чья компонента связности имеет эйлеров цикл). 
\ecrl

\fct Матрица оператора Лапласа имеет вид $L=BB^{\top}$, где $B$ -- это матрица инцидентности. В частности, размерность её ядра равна размерности ядра $B^{\top}$ и равна количеству компонент связности.
\efct

\dfn Спектр графа -- это спектр его матрицы смежности.
\edfn

\exm \\
1) Спектр полного графа $K_n$ равен $n-1$ , $-1, \dots,-1$.\\
2) Спектр цикла длины $n$ равен $2\cos(\frac{2\pi l}{n})$.\\


\rm Спектр пути равен $2\cos \frac{\pi k}{n+1}$, надо показать, что характеристический многочлен -- это многочлен Чебышёва.
\erm

\fct Все элементы спектра графа по модулю меньше чем максимальная степень $d_{max}$. Если $d_{max}$ -- это собственное число графа, то тогда этот граф регулярный.
\efct

\fct  След степени матрицы смежности считает количество циклов (возможно с пересечениями). Например, $\frac{1}{6}\Tr A^3$ -- это в точности число треугольников в графе. След всегда можно посчитать  через спектр. Из этого следует, что граф двудольный тогда и только тогда, когда его спектр симметричен. 
\efct 





Попробуем понять, какую ещё информацию даёт спектр. Воспользовавшись следствием из теоремы Куранта-Фишера получаем:

\fct Пусть $G$ -- граф на $n$ вершинах. Пусть $A$ -- симметричная матрица $n\times n$, такая, что $A_{ij}= 0$, если вершины не соединены ребром. Пусть $n_{+}$ и $n_{-}$ количество положительных и отрицательных собственных чисел $A$. Тогда размер независимого множества в $G$ не превосходит $\min(n-n_{+},n-n_{-})$.
\efct

\dfn Сильно регулярный граф с параметрами $k$, $\lambda$ и $\mu$ это $k$-регулярный граф, такой что любые две смежные вершины имеют $\lambda$ соседей, а любые две несмежные -- $\mu$ соседей.
\edfn

\thrm Матрица сильно $k$-регулярного графа удовлетворяет соотношению $A^2+(\mu-\lambda)A + (\mu-k)E=\mu J$, где $J$ -- это матрица из одних единиц.
\ethrm

Эта теорема позволяет легко посчитать спектры 
\fct 
 Граф Петерсена сильно регулярный. Его спектр 3, 1, 1, 1, 1, 1, -2, -2, -2, -2.
\efct




Под конец мы показали:

\fct Пусть $D$ -- это рёберный граф $G$. Тогда матрица смежности $D$ имеет вид $B^{\top}B -2I$, где $B$ это матрица инцидентности(без знаков). 
\efct

Рёберный граф связан с понятием гамильтоновости. А именно, если исходный граф $G$ гамильтонов, то в его рёберном графе $D$ есть индуцированный подграф вида $C_n$, где $n$ -- число вершин в $G$. Если мы сможем в каком-то случае вычислить спектр рёберного графа, то сможем показать, что граф $G$ не гамильтонов.







\section{Кватернионы}

\section{Тензорное произведение}

\dfn Пусть есть два пространства $V$ и $W$ над полем $K$. Тогда их тензорным произведением называется пространство 
$$K\lan v\otimes w \,|\, v\in V,\, w\in W \ran / Rel,$$
где $Rel$ -- это подпространство порождённое 
$$(\lambda v_1+v_2)\otimes w - \lambda v_1\otimes w - v_2 \otimes w \text{ и } v\otimes(\lambda w_1+ w_2) - \lambda v\otimes w_1 - v\otimes w_2.$$ 
\edfn 

У тензорного произведения есть и другое категорное определение. 
\dfn  Пусть есть два пространства $V$ и $W$ над полем $K$. Тогда их тензорным произведением называется пространство $V\otimes W$ удовлетворяющее условию, что для любого билинейного отображения из $h\colon V\times W \to U$ существует единственное линейное отображение $\hat{h}\colon V\otimes W \to U$, что $\hat{h}\circ i=h$, где $i$ -- это <<универсальное>> билинейное отображение $i\colon V\times W \to V\otimes W$, заданное правилом $(v,w) \to v\otimes w$.
\edfn

Основной факт про тензорное произведение состоит в том, что для этого пространства несложно построить базис.
\fct Пусть $e_1,\dots,e_n$ базис $V$, а $f_1,\dots, f_m $ базис $W$. Тогда $e_i\otimes f_j$ базис $V\otimes W$.
\efct

Однако тензорное произведение -- это не просто конструкция для нового векторного пространства. Это функтор. Точнее

\dfn Для того, чтобы задать категорию $\mc C$, необходимо определить класс объектов $Ob \mc C$ и морфизмов $Morph \mc C$ вместе с парой отображений $dom, codom \colon Morph \mc C \to Ob \mc C$. Отображение $dom$ стоит считать сопоставлением стрелки её области определения, $codom$ -- её множеству прибытия (значений). Такой набор данных позволяет определить $\Hom (A,B)$ для пары объектов из $Ob \mc C$, как множество всех стрелок с началом в $A$ и концом в $B$. Теперь, для завершения понятия категории стоит определить композицию морфизмов, то есть набор отображений
$$ \circ \colon \Hom(A,B) \times \Hom(B,C) \to \Hom(A,C),$$
со свойствами \\
1) $\forall A \in Ob \mc C $ существует $id_A \in \Hom(A,A)$, что для всех $f \in Hom(A,B)$ и $g \in Hom(B,A)$ выполнено $f\circ id_A=f$ и $id_A \circ g=g$.\\
2) $(f\circ g) \circ h = f \circ (g \circ h)$. 
\edfn 

\noindent {\bf Примеры категорий:}\\
1) Категория множеств (и отображений). Обозначается $Set$.\\
2) Категория частично упорядоченных множеств и монотонных отображений. Часто обозначают $Poset$.\\
3) Категория групп и гомоморфизмов групп. Обозначают $Grp$.\\
4) Категория колец и гомоморфизмов колец. Обозначается $Ring$.\\
5) Категория алгебр над полем $K$. Обозначается $Alg_K$.\\
6) Категория модулей над кольцом $R$ и гомоморфизмов колец. Обозначается $Mod-R$.\\
7) Частный случай -- пусть $K$ -- поле, тогда определена категория векторных пространств над $K$. Обозначается $Vect_K$.\\

Теория категорий может служить как каркас для построения теории. Например, оказывается, что если вы определили категорию, то в ней можно автоматически определить понятие изоморфизма, эпиморфизма, мономорфизма, произведения, и ещё много чего.
\dfn Пусть $A,B$ два объекта категории $\mc C$. Тогда их произведение это некоторый объект $D$ и пара отображений $pr_A \colon D \to A$ и $pr_B \colon D \to B$, удовлетворяющие свойству:\\
$\forall D'$, $f\colon D' \to A$, $g \colon D' \to B$ существует единственный морфизм $f \times g \colon D' \to D$, что $pr_A \circ (f\times g)=f$ и $pr_B \circ (f\times g)=g$.
\edfn

Категории могут быть связаны между собой с помощью чего-то, напоминающего отображения. А именно, с помощью функторов.

\dfn
Пусть $\mc C$ и $\mc D$ -- категории. Тогда функтор $F\colon \mc C \to \mc D$ это\\
1) Отображение на объектах $F \colon Ob \mc C \to Ob \mc D$.\\
2) Для любой пары объектов $A,B$ отображение на морфизмах $F=F_{A,B} \colon \Hom(A,B) \to \Hom(F(A),F(B))$,\\
так что:
$$F(f \circ g)=F(f)\circ F(g) \text{ и } F(id_A)=id_{F(A)}.$$
\edfn

Пример:\\
Рассмотрим категорию колец $Ring$. Тогда есть два функтора из  $Ring \to Grp$ -- $\mb G_a$ -- сопоставление аддитивной группы кольца, и функтор $\mb G_m$ -- сопоставление мультипликативной группы кольца.\\

\rm Под действием функтора изоморфизм переходит в изоморфизм. Поэтому любая функториальная конструкция не меняется при изоморфизмах. \erm

Надо поговорить про тензорное произведение. Оно определено для пары пространств. Таким образом нам надо определить произведение категорий.

\dfn Пусть $\mc C$ и $\mc D$ -- категории. Определим категорию $\mc C \times \mc D$ следующим образом:\\
1) $Ob \mc C \times \mc D = Ob \mc C \times Ob \mc D$.\\
2) $ \Hom((A,C), (B,D))= \Hom(A,B) \times \Hom(C,D)$. Композиция покомпонентная.
\edfn

\dfn Определим функтор 
$$\otimes \colon Vect \times Vect \to Vect,$$
задав на объектах как $(V,W) \to V \otimes W$. А на морфизмах $(f \colon A \to B$,  $g \colon C \to D $, то $f\otimes g \colon A\otimes C \to B \otimes C $ задано правилом $(f\otimes g) (x\otimes y) = f(x)\otimes f(y)$.
\edfn

\rm Если есть операторы $A\colon V \to V$ и $B \colon W \to W$. То есть оператор $A\otimes B$ на $V\otimes W$. \erm

\fct У оператора $A\otimes B$ собственные числа -- это попарные произведения с.ч. для $A$ и $B$. \efct

\fct Пусть $e_1,\dots, e_n$ базис $V$ и $f_1,\dots, f_m$ -- базис $W$. Тогда матрица  $A\otimes B$ строится следующим образом -- надо упорядочить базис в обратном лексикографическом порядке (первая координата менее важная). Тогда матрица разобьётся на $m^2$ блоков в каждом из которых будет стоять $b_{ij} A$, где $i,j$ -- номер блока.
\efct 

\fct Матрица произведения графов -- это тензорное произведение матриц. \efct

С точки зрения физики -- тензорное произведение -- это способ из понятных типов тензоров -- касательных полей, скаляров, дифференциальных форм и т.д. -- конструировать новые типы тензоров. Например, билинейная форма на $V$ -- это элемент $V^* \otimes V^*$. Структура алгебры на $V$ это элемент $V^*\otimes V^* \otimes V$.



\zd Найдите координаты тензора $e^1\otimes e^2 \otimes(e_1+e_2) \in V^*\otimes V^*\otimes V$ в базисе 
$$(\hat{e}_1, \hat{e}_2) = (e_1,e_2) \begin{pmatrix}1& 1\\
2& 3 \end{pmatrix}.$$
\ezd 

\dfn Копроизведением набора $A_{\alpha}$ объектов в категории $\mc C$ называется объект $D$, вместе с набором отображений $i_{\alpha} \colon A_{\alpha} \to D  $, что для любого объекта $D'$, вместе с набором отображений $j_{\alpha} \colon A_{\alpha} \to D' $ существует единственное $j\colon D \to D'$, что  $j\circ i_{\alpha}=j_{\alpha}$

\begin{center}
\begin{tikzpicture}
\node (A) at (1, 1) {$D$};
\node (B) at (-1, 1) {$A_{\alpha}$};
\node (C) at (1, 0) {$D'$};
\path[->,font=\scriptsize,>=angle 60]
(B) edge node[above]{$i_{\alpha}$} (A)
(B) edge node[below]{$j_{\alpha}$} (C)
(A) edge node[right]{$\exists !j$} (C);
\end{tikzpicture}
\end{center}
\edfn




\section{Внешняя и симметрическая алгебры}

Вернёмся к вопросам, связанным с теорией категорий. А именно, пусть $K$--поле. Рассмотрим категорию $K-Alg$ -- коммутативных алгебр над полем $K$. Наш текущий вопрос -- как описать копроизведение в этой категории (и понять, что оно есть). Поступим следующим образом: для привычности ограничимся только конечнопорождёнными алгебрами. И, для начала, рассмотрим случай, когда обе алгебры это кольца многочленов $A=K[x]$ и $B=K[y]$. Итак, я должен построить алгебру $R$ и пару гомомморфизмов $i_1\colon A \to R$ и $i_2\colon B \to R$, так, что задание пары гомоморфизмов $K[x] \to D$ и $K[y] \to D$ однозначно определяет $R \to D$. Заметим, что каждый гомоморфизм $K[x] \to D$ однозначно задаётся элементом из $D$. Таким образом нам необходимо найти алгебру, гомоморфизм из которой задаётся парой элементов. Это, конечно, $K[x,y]$. 


Аналогично $$K[x_1,\dots, x_n] \coprod K[y_1,\dots,y_m]= K[x_1,\dots, x_n, y_1, \dots, y_m].$$
Теперь, что же делать с произвольной конечно порождённой алгеброй? Любая такая алгебра задаётся как фактор $A=K[x_1,\dots,x_n]/(f_1,\dots,f_l)$. Для того, чтобы задать гомоморфизмы из такой алгебры надо отправить образующие в корни системы $f_1=\dots=f_l=0$. Теперь, если есть алгебра $B=K[x_1,\dots,x_m]/(g_1,\dots,g_k)$, то $A\coprod B = K[x_1,\dots,x_n,y_1,\dots,y_m]/(f_1,\dots,f_l, g_1,\dots,g_k)$.


Это вычисление использовало какой-то выбор системы образующих. Предъявим конструкцию, которая не обладает этим недостатком и работает <<бескоординатно>>. Пусть есть две алгебры $A$ и $B$, то подходит $$A\otimes B \text{ с умножением } a_1\otimes b_1 \cdot a_2\otimes b_2 =a_1a_2\otimes b_1b_2.$$

Вложение  $i_1\colon A \to A\otimes B$ устроено как $a \to a\otimes 1$. Если есть пара гомоморфизмов $f\colon A\to D$ и $g\colon B \to D$, то есть отображение заданное на тензорах как $a\otimes b \to f(a)\cdot g(b)$. 


Таким образом у нас есть конструкция -- тензорное произведение алгебр и благодаря тому, что у нас есть первое вычисление, мы умеем его считать, если представим наши алгебры, как факторы кольца многочленов.

Например, $$\mb Q [i] \otimes  \mb Q[i] \cong \mb Q[x,y]/(x^2+1, y^2+1) \cong \mb Q[i][y]/(y^2+1)= \mb Q[i] \times \mb Q[i].$$
Последнее вычисление следует из китайской теоремы об остатках. В общем, есть ещё одно важное замечание:
\fct Пусть $A$ и $B$ -- алгебры над полем $K$. предположим, что $A$ -- само по себе поле (тензорное произведение вообще определено не обязательно над полем, но у нас было только такое определение). На тензоном произведении $A\otimes B$ есть структура $A$-алгебры. Вот подходящее описание для структуры $A$-алгебры  
$$ K[x_1,\dots,x_n]/(f_1,\dots,f_l) \otimes A\cong A[x_1,\dots,x_n]/(f_1,\dots,f_l).$$
Здесь, конечно, многочлены $f_1,\dots,f_l$ интерпретируются как многочлены с коэффициентами в $A$.
\efct

\noindent Например,
$$\mb Q[x]/(x^2-2) \otimes \mb R\cong \mb R[x]/(x^2-2) \cong \mb R\times \mb R.$$

Теперь немного фактов о внешней степени и симметрической степени. Пусть есть $V$ векторное пространство над полем характеристики $0$ (можно и не 0, но сложнее). Определим пространство $\Lambda^k V$ как подпространство $V^{\otimes k}$. Это подпространство выделяется следующими условиями -- для любой перестановки из $\sigma \in S_k$ и любого тензора $a\in \Lambda^k V$ верно, что $a^{\sigma}=\sgn(\sigma)a$. Под $a^{\sigma}$ подразумевается действие перестановки $\sigma$ на тензор $a$ перестановкой его компонент. Аналогично определяется подпространство $\Sym^k V \leq V^{\otimes^k}$, чьи элементы удовлетворяют свойству: $a^{\sigma}=a$.

\fct Имеет место проектор $V^{\otimes k} \to \Lambda^k$ заданный формулой 
$$a \to \frac{1}{k!} \sum_{\sigma \in S_k} \sgn (\sigma) a^{\sigma}.$$
Аналогично отображение  
$$a \to \frac{1}{k!} \sum_{\sigma \in S_k} a^{\sigma}$$
есть проектор на подпространство $\Sym^k V$.
\efct 

\dfn Пусть $e_1,\dots, e_k$ набор элементов из $V$. Определим элементы $e_1\wedge \dots \wedge e_k \in \Lambda^k V$ как образы при проекции $e_1\otimes \dots \otimes e_k$.
\edfn

\fct Пусть $e_1,\dots, e_n$ базис пространства $V$. Тогда элементы $e_{i_1}\wedge \dots \wedge e_{i_k}$, где $i_1<i_2< \dots < i_k$ образуют базис пространства $\Lambda^k V$. В частности размерность $\dim \Lambda^k V = C^k_n$.
\efct 

\fct Аналогично, пусть $e_1,\dots, e_n$ базис пространства $V$. Тогда элементы образы тензоров $e_{i_1}\otimes \dots \otimes e_{i_k}$, где $i_1\leq \dots \leq i_k$ образуют базис пространства $\Lambda^k V$.
\efct

\fct Определим функтор из категории векторных пространств в себя, который пространству $V$ сопоставляет пространство $\Lambda^k V$, а линейному отображению $f\colon V \to W$ -- отображение $A^{\wedge k} = \Lambda^k (A) \colon \Lambda^k V \to \Lambda^k W$ заданное по правилу $v_1\wedge \dots \wedge v_k \to A v_1 \wedge \dots \wedge A v_k$. 
\efct 

\rm Это просто ограничение отображения $V^{\otimes k} \to W^{\otimes k}$  на кососимметрические тензоры -- так проще всего понять, что композиция переходит в композицию. Аналогично определяется отображение $\Sym^k V \to \Sym^k W$, и, следовательно, задаётся функтор $\Sym^k$.
\erm


\fct Пусть $A$ --- оператор на $V$. Тогда собственные числа $A^{\wedge k}$ можно описать так. Пусть $I\subseteq \{1,\dots,n\}$, такое что $|I|=k$. Любому такому подмножеству можно сопоставить собственное число $A^{\wedge k}$ равное $\prod_{i \in I}\lambda_i$, где $\lambda_i$ -- собственные числа $A$.
\efct

И напоследок ещё набор полезных фактов.

\fct Полезно смотреть не на пространства $\Lambda^k (V)$ и $\Sym^k V$, а на пространства $\Lambda^k(V^*)$ и $\Sym^k(V^*)$, потому что они допускают привычную и наглядную интерпретацию --- их элементы это полилинейные функции со специальными свойствами.
\efct


\exm \\
1) Элемент $\Lambda^2(V^*)$ --- это просто кососимметрическая билинейная форма.\\
2) А элемент $\Sym^2 V^*$ -- это симметрическая билинейная форма или просто квадратичная форма.\\
3) Элемент $\Lambda^{\dim V} V^*$ -- это просто форма объёма на $V$.\\
4) Заметим, что продолжая аналогию с квадратичными формами, выбор базиса задаёт изоморфизм 
$$\Sym^k V^* \cong K[x_1,\dots, x_n]_{\deg =k}$$
с пространством однородных многочленов степени $k$ ($n$ -- размерность пространства). Последнее отображение устроено следующим образом -- элементу $a \in \Sym^k V^* $ сопоставим отображение, которое на векторе $v=x_1e_1+\dots+x_ne_n $ выдаёт $a(v,\dots,v)$. То есть 
$$a \to (v \to a(v,\dots,v)).$$
 Это будет однородный многочлен от координатных функций $x_1, \dots, x_n$. Осталось заметить, что проекция тензора $e^{i_1}\otimes \dots \otimes e^{i_k}$ после применения такой операции --- это многочлен $x_{i_1}\dots x_{i_k}$.

\fct Так же полезно помнить интерпретацию разных обычных тензоров. Например, линейный оператор -- это тензор из $V \otimes V^* = V^{1,1}$, а структура алгебры  на $V$ -- это тензор из $V^*\otimes V^* \otimes V=V^{2,1}$.  
\efct







\end{document}